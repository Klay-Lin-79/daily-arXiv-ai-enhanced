<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 37]
- [cs.CL](#cs.CL) [Total: 22]
- [cs.LG](#cs.LG) [Total: 61]
- [cs.IR](#cs.IR) [Total: 7]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.CC](#cs.CC) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [KPM-Bench: A Kinematic Parsing Motion Benchmark for Fine-grained Motion-centric Video Understanding](https://arxiv.org/abs/2602.17768)
*Boda Lin,Yongjie Zhu,Xiaocheng Gong,Wenyu Qin,Meng Wang*

Main category: cs.CV

TL;DR: 该论文针对视频字幕生成模型在描述精细运动细节和幻觉问题上的局限性，提出了KPM-Bench数据集和MoPE算法，通过运动解析和提取技术改善运动中心视频的字幕生成可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前视频字幕生成模型在描述精细运动细节方面存在显著限制，特别是在运动中心视频中，对复杂动作和肢体动态的精确描述往往被忽视，同时存在严重的幻觉问题。

Method: 1. 开发自动化标注流程，整合基于运动学的运动计算和语言解析；2. 构建KPM-Bench数据集，包含精细视频-字幕对、运动理解问答对和幻觉评估集；3. 提出MoPE算法，从文本字幕中准确提取运动特定属性；4. 将MoPE集成到GRPO后训练框架中。

Result: 1. 创建了KPM-Bench开源数据集，支持精细运动理解；2. 开发了独立于大规模视觉-语言或纯语言模型的精确幻觉评估指标；3. 有效缓解了幻觉问题，显著提高了运动中心视频字幕生成模型的可靠性。

Conclusion: 该研究通过创新的数据集构建和算法设计，系统解决了视频字幕生成中的精细运动描述和幻觉问题，为运动中心视频理解提供了有效的工具和方法。

Abstract: Despite recent advancements, video captioning models still face significant limitations in accurately describing fine-grained motion details and suffer from severe hallucination issues. These challenges become particularly prominent when generating captions for motion-centric videos, where precise depiction of intricate movements and limb dynamics is crucial yet often neglected. To alleviate this gap, we introduce an automated annotation pipeline that integrates kinematic-based motion computation with linguistic parsing, enabling detailed decomposition and description of complex human motions. Based on this pipeline, we construct and release the Kinematic Parsing Motion Benchmark (KPM-Bench), a novel open-source dataset designed to facilitate fine-grained motion understanding. KPM-Bench consists of (i) fine-grained video-caption pairs that comprehensively illustrate limb-level dynamics in complex actions, (ii) diverse and challenging question-answer pairs focusing specifically on motion understanding, and (iii) a meticulously curated evaluation set specifically designed to assess hallucination phenomena associated with motion descriptions. Furthermore, to address hallucination issues systematically, we propose the linguistically grounded Motion Parsing and Extraction (MoPE) algorithm, capable of accurately extracting motion-specific attributes directly from textual captions. Leveraging MoPE, we introduce a precise hallucination evaluation metric that functions independently of large-scale vision-language or language-only models. By integrating MoPE into the GRPO post-training framework, we effectively mitigate hallucination problems, significantly improving the reliability of motion-centric video captioning models.

</details>


### [2] [CLUTCH: Contextualized Language model for Unlocking Text-Conditioned Hand motion modelling in the wild](https://arxiv.org/abs/2602.17770)
*Balamurugan Thambiraja,Omid Taheri,Radek Danecek,Giorgio Becherini,Gerard Pons-Moll,Justus Thies*

Main category: cs.CV

TL;DR: 该论文提出了3D-HIW数据集和CLUTCH系统，用于解决野外环境下3D手部动作建模的挑战，在文本到动作和动作到文本任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 手部在日常生活中扮演核心角色，但现有方法依赖工作室采集的数据集，动作和上下文有限，难以扩展到野外环境。当前模型在动画保真度和文本-动作对齐方面存在不足。

Method: 1) 构建3D-HIW数据集：结合视觉语言模型和先进3D手部跟踪器，从大量第一人称动作视频中提取32K个3D手部动作序列和对应文本；2) 提出CLUTCH系统：包含SHIFT（一种部分模态分解的VQ-VAE架构）用于手部动作标记化，以及几何精炼阶段来微调LLM。

Result: 实验表明，该方法在文本到动作和动作到文本任务上实现了最先进的性能，为可扩展的野外手部动作建模建立了首个基准。

Conclusion: 该研究通过构建大规模野外数据集和创新的模型架构，成功解决了手部动作建模在真实环境中的扩展问题，为手部动画生成和理解提供了新的解决方案。

Abstract: Hands play a central role in daily life, yet modeling natural hand motions remains underexplored. Existing methods that tackle text-to-hand-motion generation or hand animation captioning rely on studio-captured datasets with limited actions and contexts, making them costly to scale to "in-the-wild" settings. Further, contemporary models and their training schemes struggle to capture animation fidelity with text-motion alignment. To address this, we (1) introduce '3D Hands in the Wild' (3D-HIW), a dataset of 32K 3D hand-motion sequences and aligned text, and (2) propose CLUTCH, an LLM-based hand animation system with two critical innovations: (a) SHIFT, a novel VQ-VAE architecture to tokenize hand motion, and (b) a geometric refinement stage to finetune the LLM. To build 3D-HIW, we propose a data annotation pipeline that combines vision-language models (VLMs) and state-of-the-art 3D hand trackers, and apply it to a large corpus of egocentric action videos covering a wide range of scenarios. To fully capture motion in-the-wild, CLUTCH employs SHIFT, a part-modality decomposed VQ-VAE, which improves generalization and reconstruction fidelity. Finally, to improve animation quality, we introduce a geometric refinement stage, where CLUTCH is co-supervised with a reconstruction loss applied directly to decoded hand motion parameters. Experiments demonstrate state-of-the-art performance on text-to-motion and motion-to-text tasks, establishing the first benchmark for scalable in-the-wild hand motion modelling. Code, data and models will be released.

</details>


### [3] [LGD-Net: Latent-Guided Dual-Stream Network for HER2 Scoring with Task-Specific Domain Knowledge](https://arxiv.org/abs/2602.17793)
*Peide Zhu,Linbin Lu,Zhiqin Chen,Xiong Chen*

Main category: cs.CV

TL;DR: 提出LGD-Net框架，通过跨模态特征幻觉而非像素级图像生成，从H&E切片直接预测HER2表达水平，避免虚拟染色方法的计算开销和重建伪影


<details>
  <summary>Details</summary>
Motivation: 传统IHC染色评估HER2表达水平资源密集、昂贵且耗时，在许多地区不可用。现有基于H&E切片的虚拟IHC图像生成方法计算昂贵且易产生重建伪影，可能传播诊断错误

Method: 提出Latent-Guided Dual-Stream Network (LGD-Net)，采用跨模态特征幻觉而非显式像素级图像生成。学习将形态学H&E特征直接映射到分子潜在空间，通过教师IHC编码器指导训练。使用轻量级辅助正则化任务，通过核分布和膜染色强度等任务特定领域知识正则化模型训练

Result: 在公开BCI数据集上的广泛实验表明，LGD-Net达到最先进性能，显著优于基线方法，同时支持使用单模态H&E输入进行高效推理

Conclusion: LGD-Net通过特征级跨模态映射和领域知识正则化，提供了一种高效准确的HER2表达预测方法，避免了虚拟染色方法的计算负担和伪影问题

Abstract: It is a critical task to evalaute HER2 expression level accurately for breast cancer evaluation and targeted treatment therapy selection. However, the standard multi-step Immunohistochemistry (IHC) staining is resource-intensive, expensive, and time-consuming, which is also often unavailable in many areas. Consequently, predicting HER2 levels directly from H&E slides has emerged as a potential alternative solution. It has been shown to be effective to use virtual IHC images from H&E images for automatic HER2 scoring. However, the pixel-level virtual staining methods are computationally expensive and prone to reconstruction artifacts that can propagate diagnostic errors. To address these limitations, we propose the Latent-Guided Dual-Stream Network (LGD-Net), a novel framework that employes cross-modal feature hallucination instead of explicit pixel-level image generation. LGD-Net learns to map morphological H&E features directly to the molecular latent space, guided by a teacher IHC encoder during training. To ensure the hallucinated features capture clinically relevant phenotypes, we explicitly regularize the model training with task-specific domain knowledge, specifically nuclei distribution and membrane staining intensity, via lightweight auxiliary regularization tasks. Extensive experiments on the public BCI dataset demonstrate that LGD-Net achieves state-of-the-art performance, significantly outperforming baseline methods while enabling efficient inference using single-modality H&E inputs.

</details>


### [4] [Enabling Training-Free Text-Based Remote Sensing Segmentation](https://arxiv.org/abs/2602.17799)
*Jose Sosa,Danila Rukhovich,Anis Kacem,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出一种无需额外训练即可实现遥感图像文本引导分割的方法，结合对比式和生成式视觉语言模型与SAM，在19个遥感基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型和视觉基础模型为零样本遥感图像分割提供了新机会，但大多数方法仍依赖额外的可训练组件，限制了泛化能力和实际应用性。本研究旨在探索在不进行额外训练的情况下，仅依靠现有基础模型实现基于文本的遥感分割。

Method: 提出简单有效的方法，将对比式和生成式视觉语言模型与SAM集成：1）对比式方法使用CLIP作为SAM网格提案的掩码选择器；2）生成式方法使用GPT-5（零样本）和LoRA调优的Qwen-VL模型生成点击提示给SAM。支持完全零样本或轻量级LoRA调优流程。

Result: 在19个遥感基准测试（包括开放词汇、指代和基于推理的任务）上进行广泛实验：对比式方法在完全零样本设置下实现了最先进的开放词汇语义分割；生成式方法中，LoRA调优的Qwen-VL模型表现最佳。

Conclusion: 该方法展示了仅使用现有基础模型实现文本引导遥感分割的可行性，无需额外训练或仅需轻量调优，在多个任务上表现出强大能力，具有实际应用价值。

Abstract: Recent advances in Vision Language Models (VLMs) and Vision Foundation Models (VFMs) have opened new opportunities for zero-shot text-guided segmentation of remote sensing imagery. However, most existing approaches still rely on additional trainable components, limiting their generalisation and practical applicability. In this work, we investigate to what extent text-based remote sensing segmentation can be achieved without additional training, by relying solely on existing foundation models. We propose a simple yet effective approach that integrates contrastive and generative VLMs with the Segment Anything Model (SAM), enabling a fully training-free or lightweight LoRA-tuned pipeline. Our contrastive approach employs CLIP as mask selector for SAM's grid-based proposals, achieving state-of-the-art open-vocabulary semantic segmentation (OVSS) in a completely zero-shot setting. In parallel, our generative approach enables reasoning and referring segmentation by generating click prompts for SAM using GPT-5 in a zero-shot setting and a LoRA-tuned Qwen-VL model, with the latter yielding the best results. Extensive experiments across 19 remote sensing benchmarks, including open-vocabulary, referring, and reasoning-based tasks, demonstrate the strong capabilities of our approach. Code will be released at https://github.com/josesosajs/trainfree-rs-segmentation.

</details>


### [5] [VQPP: Video Query Performance Prediction Benchmark](https://arxiv.org/abs/2602.17814)
*Adrian Catalin Lutu,Eduard Poesina,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 本文提出了首个视频查询性能预测（VQPP）基准，包含两个文本到视频检索数据集和两个CBVR系统，共56K文本查询和51K视频，为视频领域的QPP研究提供了标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 查询性能预测（QPP）在信息检索中很重要，但在基于内容的视频检索（CBVR）领域研究不足，缺乏标准化基准，需要建立视频领域的QPP评估框架。

Method: 构建了VQPP基准，包含两个文本到视频检索数据集和两个CBVR系统，探索了多种检索前和检索后性能预测器，并使用最佳检索前预测器作为奖励模型，通过直接偏好优化训练LLM进行查询重写。

Result: 检索前预测器取得了有竞争力的性能，能够在检索步骤之前实现应用；VQPP基准为视频领域的QPP研究提供了可复现的比较基础。

Conclusion: VQPP是首个视频查询性能预测基准，填补了CBVR领域QPP研究的空白，为未来视频检索性能预测研究提供了标准化平台，并展示了在查询重写等实际应用中的潜力。

Abstract: Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.

</details>


### [6] [On the Evaluation Protocol of Gesture Recognition for UAV-based Rescue Operation based on Deep Learning: A Subject-Independence Perspective](https://arxiv.org/abs/2602.17854)
*Domonkos Varga*

Main category: cs.CV

TL;DR: 该论文对Liu和Szirányi的手势识别方法进行了方法学分析，指出其评估协议存在严重的数据泄漏问题，导致报告的高准确率指标无效。


<details>
  <summary>Details</summary>
Motivation: 本文旨在分析Liu和Szirányi手势识别方法的评估协议有效性，特别关注其是否存在数据泄漏问题，以强调在基于视觉的手势识别研究中，尤其是对于需要识别未见个体手势的应用（如无人机-人交互），主体独立数据划分的重要性。

Method: 通过分析已发表的混淆矩阵、学习曲线和数据集构建方式，检查了帧级随机训练-测试分割是否混合了同一受试者的样本，从而识别数据泄漏问题。

Result: 研究发现，报告的接近完美的准确率指标源于帧级随机训练-测试分割，这种分割不可避免地混合了同一受试者在训练集和测试集中的样本，导致严重的数据泄漏。评估并未测量对未见个体的泛化能力。

Conclusion: 该分析强调了在基于视觉的手势识别研究中，特别是对于需要可靠识别未见个体手势的应用，主体独立数据划分的重要性。研究结果对现有评估协议的有效性提出了质疑，并呼吁采用更严格的评估标准。

Abstract: This paper presents a methodological analysis of the gesture-recognition approach proposed by Liu and Szirányi, with a particular focus on the validity of their evaluation protocol. We show that the reported near-perfect accuracy metrics result from a frame-level random train-test split that inevitably mixes samples from the same subjects across both sets, causing severe data leakage. By examining the published confusion matrix, learning curves, and dataset construction, we demonstrate that the evaluation does not measure generalization to unseen individuals. Our findings underscore the importance of subject-independent data partitioning in vision-based gesture-recognition research, especially for applications - such as UAV-human interaction - that require reliable recognition of gestures performed by previously unseen people.

</details>


### [7] [Learning Compact Video Representations for Efficient Long-form Video Understanding in Large Multimodal Models](https://arxiv.org/abs/2602.17869)
*Yuxiao Chen,Jue Wang,Zhikang Zhang,Jingru Yi,Xu Zhang,Yang Zou,Zhaowei Cai,Jianbo Yuan,Xinyu Li,Hao Yang,Davide Modolo*

Main category: cs.CV

TL;DR: 提出一种用于长视频理解的新端到端框架，包含基于信息密度的自适应视频采样器和基于自动编码器的时空视频压缩器，结合多模态大语言模型，有效处理长视频冗余问题。


<details>
  <summary>Details</summary>
Motivation: 随着视频骨干架构和大语言模型的发展，分析长达数十分钟的长视频变得可行且普遍。然而，视频序列固有的冗余性给现有模型带来两大挑战：1) 在内存限制内高效处理更多帧；2) 从大量输入数据中提取判别性信息。

Method: 提出端到端的长视频理解框架，包含：1) 基于信息密度的自适应视频采样器(AVS)，根据视频内容重要性自适应采样；2) 基于自动编码器的时空视频压缩器(SVC)，实现高压缩率同时保留关键信息；3) 与多模态大语言模型(MLLM)集成。

Result: 该框架在多个基准测试中表现出色，在长视频理解任务和标准视频理解基准上都取得了优异性能，证明了其处理长视频复杂性的有效性和通用性。

Conclusion: 提出的框架能够自适应有效地从不同时长视频序列中捕获关键信息，实现高压缩率同时保留重要判别信息，为解决长视频理解中的冗余问题提供了有效方案。

Abstract: With recent advancements in video backbone architectures, combined with the remarkable achievements of large language models (LLMs), the analysis of long-form videos spanning tens of minutes has become both feasible and increasingly prevalent. However, the inherently redundant nature of video sequences poses significant challenges for contemporary state-of-the-art models. These challenges stem from two primary aspects: 1) efficiently incorporating a larger number of frames within memory constraints, and 2) extracting discriminative information from the vast volume of input data. In this paper, we introduce a novel end-to-end schema for long-form video understanding, which includes an information-density-based adaptive video sampler (AVS) and an autoencoder-based spatiotemporal video compressor (SVC) integrated with a multimodal large language model (MLLM). Our proposed system offers two major advantages: it adaptively and effectively captures essential information from video sequences of varying durations, and it achieves high compression rates while preserving crucial discriminative information. The proposed framework demonstrates promising performance across various benchmarks, excelling in both long-form video understanding tasks and standard video understanding benchmarks. These results underscore the versatility and efficacy of our approach, particularly in managing the complexities of prolonged video sequences.

</details>


### [8] [Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models](https://arxiv.org/abs/2602.17871)
*Dhruba Ghosh,Yuhui Zhang,Ludwig Schmidt*

Main category: cs.CV

TL;DR: 该研究发现当前视觉语言模型在细粒度图像分类任务上表现不佳，通过实验发现更好的视觉编码器能显著提升细粒度分类性能，而预训练阶段对细粒度能力至关重要。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在各种视觉问答基准测试中取得了显著进展，但在传统的细粒度图像分类任务上表现落后。研究旨在探索视觉语言模型在细粒度视觉知识方面与其他视觉基准测试之间的差距原因。

Method: 对大量最新的视觉语言模型在细粒度分类基准上进行测试，通过一系列消融实验分析影响性能的因素。研究比较了不同LLM和视觉编码器的影响，并考察了预训练阶段对细粒度性能的重要性。

Result: 研究发现：1）使用更好的LLM对所有基准测试分数都有同等提升；2）更好的视觉编码器能不成比例地提高细粒度分类性能；3）预训练阶段对细粒度性能至关重要，特别是在预训练期间语言模型权重未冻结的情况下。

Conclusion: 这些发现为增强视觉语言模型中的细粒度视觉理解和以视觉为中心的能力提供了方向，强调了视觉编码器质量和预训练策略对细粒度视觉知识获取的重要性。

Abstract: Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base models, alignment architectures, and training data. However, recent works show that these models trail behind in traditional image classification benchmarks, which test fine-grained visual knowledge. We test a large number of recent VLMs on fine-grained classification benchmarks and identify potential factors in the disconnect between fine-grained knowledge and other vision benchmarks. Through a series of ablation experiments, we find that using a better LLM improves all benchmark scores equally, while a better vision encoder disproportionately improves fine-grained classification performance. Furthermore, we find that the pretraining stage is also vital to fine-grained performance, particularly when the language model weights are unfrozen during pretraining. These insights pave the way for enhancing fine-grained visual understanding and vision-centric capabilities in VLMs.

</details>


### [9] [A Single Image and Multimodality Is All You Need for Novel View Synthesis](https://arxiv.org/abs/2602.17909)
*Amirhosein Javadi,Chi-Shiang Gau,Konstantinos D. Polyzos,Tara Javidi*

Main category: cs.CV

TL;DR: 本文提出了一种利用稀疏多模态测距数据（如雷达或激光雷达）改进基于扩散模型的单图像新视角合成方法，通过局部高斯过程在角度域建模深度，显著提升了几何一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的单图像新视角合成方法依赖于单目深度估计的几何信息，但在低纹理、恶劣天气和遮挡严重的真实场景中，深度估计的可靠性有限，导致合成视图的质量和一致性受到限制。

Method: 提出了一个多模态深度重建框架，利用极稀疏的测距传感数据（如汽车雷达或激光雷达）生成密集深度图。采用局部高斯过程在角度域建模深度，实现计算高效推理并显式量化观测有限区域的不确定性。重建的深度和不确定性可直接替代现有扩散渲染流程中的单目深度估计器。

Result: 在真实多模态驾驶场景实验中，用稀疏测距重建深度替代纯视觉深度，显著提升了单图像新视角视频生成的几何一致性和视觉质量。

Conclusion: 研究强调了可靠几何先验对基于扩散的视角合成的重要性，并展示了即使在极端稀疏情况下，多模态传感也能带来实际效益。该方法可作为现有扩散渲染流程的即插即用改进方案。

Abstract: Diffusion-based approaches have recently demonstrated strong performance for single-image novel view synthesis by conditioning generative models on geometry inferred from monocular depth estimation. However, in practice, the quality and consistency of the synthesized views are fundamentally limited by the reliability of the underlying depth estimates, which are often fragile under low texture, adverse weather, and occlusion-heavy real-world conditions. In this work, we show that incorporating sparse multimodal range measurements provides a simple yet effective way to overcome these limitations. We introduce a multimodal depth reconstruction framework that leverages extremely sparse range sensing data, such as automotive radar or LiDAR, to produce dense depth maps that serve as robust geometric conditioning for diffusion-based novel view synthesis. Our approach models depth in an angular domain using a localized Gaussian Process formulation, enabling computationally efficient inference while explicitly quantifying uncertainty in regions with limited observations. The reconstructed depth and uncertainty are used as a drop-in replacement for monocular depth estimators in existing diffusion-based rendering pipelines, without modifying the generative model itself. Experiments on real-world multimodal driving scenes demonstrate that replacing vision-only depth with our sparse range-based reconstruction substantially improves both geometric consistency and visual quality in single-image novel-view video generation. These results highlight the importance of reliable geometric priors for diffusion-based view synthesis and demonstrate the practical benefits of multimodal sensing even at extreme levels of sparsity.

</details>


### [10] [ZACH-ViT: Regime-Dependent Inductive Bias in Compact Vision Transformers for Medical Imaging](https://arxiv.org/abs/2602.17929)
*Athanasios Angelakis*

Main category: cs.CV

TL;DR: ZACH-ViT是一种紧凑型视觉Transformer，移除了位置嵌入和CLS标记，通过全局平均池化实现排列不变性，在医学图像任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 传统视觉Transformer依赖位置嵌入和类别标记编码固定的空间先验，这在医学成像中可能阻碍泛化能力，因为医学图像的空间布局信息较弱或不一致。

Method: 提出ZACH-ViT，移除位置嵌入和CLS标记，通过全局平均池化实现排列不变性；使用自适应残差投影保持训练稳定性；在紧凑配置下保持严格的参数预算。

Result: 在7个MedMNIST数据集上评估，ZACH-ViT（0.25M参数）在BloodMNIST上表现最佳，在PathMNIST上与TransMIL竞争，在具有强解剖先验的数据集上相对优势减弱；保持亚秒级推理时间。

Conclusion: 将架构归纳偏置与数据结构对齐比追求通用基准主导更重要；ZACH-ViT在资源受限的临床环境中具有部署潜力。

Abstract: Vision Transformers rely on positional embeddings and class tokens that encode fixed spatial priors. While effective for natural images, these priors may hinder generalization when spatial layout is weakly informative or inconsistent, a frequent condition in medical imaging and edge-deployed clinical systems. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a compact Vision Transformer that removes both positional embeddings and the [CLS] token, achieving permutation invariance through global average pooling over patch representations. The term "Zero-token" specifically refers to removing the dedicated [CLS] aggregation token and positional embeddings; patch tokens remain unchanged and are processed normally. Adaptive residual projections preserve training stability in compact configurations while maintaining a strict parameter budget.
  Evaluation is performed across seven MedMNIST datasets spanning binary and multi-class tasks under a strict few-shot protocol (50 samples per class, fixed hyperparameters, five random seeds). The empirical analysis demonstrates regime-dependent behavior: ZACH-ViT (0.25M parameters, trained from scratch) achieves its strongest advantage on BloodMNIST and remains competitive with TransMIL on PathMNIST, while its relative advantage decreases on datasets with strong anatomical priors (OCTMNIST, OrganAMNIST), consistent with the architectural hypothesis. These findings support the view that aligning architectural inductive bias with data structure can be more important than pursuing universal benchmark dominance. Despite its minimal size and lack of pretraining, ZACH-ViT achieves competitive performance while maintaining sub-second inference times, supporting deployment in resource-constrained clinical environments. Code and models are available at https://github.com/Bluesman79/ZACH-ViT.

</details>


### [11] [ROCKET: Residual-Oriented Multi-Layer Alignment for Spatially-Aware Vision-Language-Action Models](https://arxiv.org/abs/2602.17951)
*Guoheng Sun,Tingting Du,Kaixi Feng,Chenxiang Luo,Xingguo Ding,Zheyu Shen,Ziyao Wang,Yexiao He,Ang Li*

Main category: cs.CV

TL;DR: ROCKET提出了一种残差导向的多层表示对齐框架，通过共享投影器将VLA模型的多个层与3D视觉基础模型对齐，减少梯度冲突，显著提升3D空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action模型通常在2D数据上预训练，缺乏3D空间理解能力。现有表示对齐方法通常只在单层进行监督，无法充分利用深度分布的信息，而朴素的多层对齐会导致梯度干扰。

Method: 提出ROCKET框架，将多层对齐建模为将一个残差流对齐到另一个残差流。使用共享投影器通过层不变映射将VLA骨干的多个层与强大的3D视觉基础模型的多个层对齐，减少梯度冲突。采用Matryoshka风格的稀疏激活方案平衡多个对齐损失，并结合免训练层选择策略。

Result: 在LIBERO数据集上仅需约4%的计算预算就达到98.5%的SOTA成功率。在LIBERO-Plus和RoboTwin数据集以及多个VLA模型上都表现出优越性能。

Conclusion: ROCKET通过残差导向的多层表示对齐框架，有效解决了现有VLA模型缺乏3D空间理解的问题，以较低计算成本实现了显著的性能提升。

Abstract: Vision-Language-Action (VLA) models enable instruction-following robotic manipulation, but they are typically pretrained on 2D data and lack 3D spatial understanding. An effective approach is representation alignment, where a strong vision foundation model is used to guide a 2D VLA model. However, existing methods usually apply supervision at only a single layer, failing to fully exploit the rich information distributed across depth; meanwhile, naïve multi-layer alignment can cause gradient interference. We introduce ROCKET, a residual-oriented multi-layer representation alignment framework that formulates multi-layer alignment as aligning one residual stream to another. Concretely, ROCKET employs a shared projector to align multiple layers of the VLA backbone with multiple layers of a powerful 3D vision foundation model via a layer-invariant mapping, which reduces gradient conflicts. We provide both theoretical justification and empirical analyses showing that a shared projector is sufficient and outperforms prior designs, and further propose a Matryoshka-style sparse activation scheme for the shared projector to balance multiple alignment losses. Our experiments show that, combined with a training-free layer selection strategy, ROCKET requires only about 4% of the compute budget while achieving 98.5% state-of-the-art success rate on LIBERO. We further demonstrate the superior performance of ROCKET across LIBERO-Plus and RoboTwin, as well as multiple VLA models. The code and model weights can be found at https://github.com/CASE-Lab-UMD/ROCKET-VLA.

</details>


### [12] [Image Quality Assessment: Exploring Quality Awareness via Memory-driven Distortion Patterns Matching](https://arxiv.org/abs/2602.18000)
*Xuting Lan,Mingliang Zhou,Xuekai Wei,Jielu Yan,Yueting Huang,Huayan Pu,Jun Luo,Weijia Jia*

Main category: cs.CV

TL;DR: 提出基于记忆驱动的质量感知框架（MQAF），通过建立存储失真模式的记忆库，在有无参考图像时动态切换双模式质量评估策略，减少对高质量参考图像的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有全参考图像质量评估（FR-IQA）方法依赖参考图像质量，限制了在理想参考源不可用的实际应用。受人类视觉系统能够积累视觉记忆的启发，希望开发能够基于长期记忆存储进行图像质量评估的方法。

Method: 提出记忆驱动的质量感知框架（MQAF）：1）建立存储失真模式的记忆库；2）动态切换双模式质量评估策略：有参考图像时，通过自适应加权参考信息并比较失真图像与记忆库中的失真模式获得参考引导质量分数；无参考图像时，依赖记忆库中的失真模式推断图像质量，实现无参考质量评估（NR-IQA）。

Result: 实验结果表明，该方法在多个数据集上优于最先进的方法，同时能够适应无参考和全参考两种任务。

Conclusion: 提出的记忆驱动框架通过模拟人类视觉记忆机制，有效减少了对高质量参考图像的依赖，在有无参考图像的情况下都能实现高质量评估，具有更好的实际应用价值。

Abstract: Existing full-reference image quality assessment (FR-IQA) methods achieve high-precision evaluation by analysing feature differences between reference and distorted images. However, their performance is constrained by the quality of the reference image, which limits real-world applications where ideal reference sources are unavailable. Notably, the human visual system has the ability to accumulate visual memory, allowing image quality assessment on the basis of long-term memory storage. Inspired by this biological memory mechanism, we propose a memory-driven quality-aware framework (MQAF), which establishes a memory bank for storing distortion patterns and dynamically switches between dual-mode quality assessment strategies to reduce reliance on high-quality reference images. When reference images are available, MQAF obtains reference-guided quality scores by adaptively weighting reference information and comparing the distorted image with stored distortion patterns in the memory bank. When the reference image is absent, the framework relies on distortion patterns in the memory bank to infer image quality, enabling no-reference quality assessment (NR-IQA). The experimental results show that our method outperforms state-of-the-art approaches across multiple datasets while adapting to both no-reference and full-reference tasks.

</details>


### [13] [MUOT_3M: A 3 Million Frame Multimodal Underwater Benchmark and the MUTrack Tracking Method](https://arxiv.org/abs/2602.18006)
*Ahsan Baidar Bakht,Mohamad Alansari,Muhayy Ud Din,Muzammal Naseer,Sajid Javed,Irfan Hussain,Jiri Matas,Arif Mahmood*

Main category: cs.CV

TL;DR: 本文提出了首个伪多模态水下目标跟踪基准MUOT_3M和基于SAM的多模态到单模态跟踪器MUTrack，解决了水下跟踪数据集稀缺和模态限制问题。


<details>
  <summary>Details</summary>
Motivation: 水下目标跟踪对海洋机器人、生态监测和海洋探索至关重要，但进展受到大型、多模态、多样化数据集稀缺的限制。现有基准数据集规模小且仅支持RGB模态，在严重颜色失真、浑浊和低能见度条件下鲁棒性有限。

Method: 1) 构建MUOT_3M基准：包含3030个视频的300万帧，标注了32个跟踪属性、677个细粒度类别，以及同步的RGB、估计增强RGB、估计深度和语言模态；2) 提出MUTrack跟踪器：基于SAM架构，采用视觉几何对齐、视觉语言融合和四级知识蒸馏，将多模态知识转移到单模态学生模型中。

Result: 在五个UOT基准上的广泛评估表明，MUTrack比最强的SOTA基线在AUC上提高了8.40%，在精度上提高了7.80%，同时以24 FPS的速度运行。MUOT_3M和MUTrack为可扩展、多模态训练但实际可部署的水下跟踪建立了新基础。

Conclusion: MUOT_3M基准和MUTrack跟踪器解决了水下目标跟踪领域的数据集稀缺和模态限制问题，通过多模态训练和知识蒸馏实现了高性能的单模态部署，为水下跟踪研究提供了新的基础。

Abstract: Underwater Object Tracking (UOT) is crucial for efficient marine robotics, large scale ecological monitoring, and ocean exploration; however, progress has been hindered by the scarcity of large, multimodal, and diverse datasets. Existing benchmarks remain small and RGB only, limiting robustness under severe color distortion, turbidity, and low visibility conditions. We introduce MUOT_3M, the first pseudo multimodal UOT benchmark comprising 3 million frames from 3,030 videos (27.8h) annotated with 32 tracking attributes, 677 fine grained classes, and synchronized RGB, estimated enhanced RGB, estimated depth, and language modalities validated by a marine biologist. Building upon MUOT_3M, we propose MUTrack, a SAM-based multimodal to unimodal tracker featuring visual geometric alignment, vision language fusion, and four level knowledge distillation that transfers multimodal knowledge into a unimodal student model. Extensive evaluations across five UOT benchmarks demonstrate that MUTrack achieves up to 8.40% higher AUC and 7.80% higher precision than the strongest SOTA baselines while running at 24 FPS. MUOT_3M and MUTrack establish a new foundation for scalable, multimodally trained yet practically deployable underwater tracking.

</details>


### [14] [Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating](https://arxiv.org/abs/2602.18016)
*Jiamin Luo,Xuqian Gu,Jingjing Wang,Jiahong Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于大语言模型的情感视觉定制任务（L-AVC），旨在通过多模态大语言模型编辑图像的主观情感内容，并开发了高效精确的情感操纵方法（EPEM）来解决情感语义转换和情感无关内容保留的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定制研究主要关注客观对齐（如语言、布局等控制信号与编辑图像的匹配），但忽略了主观情感内容，且缺乏面向情感视觉定制的通用基础模型。因此需要开发能够有效处理情感内容的视觉定制方法。

Method: 提出高效精确情感操纵方法（EPEM），包含两个核心模块：1）高效情感间转换（EIC）模块，使大语言模型在编辑前后高效对齐情感语义转换；2）精确情感外保留（PER）模块，精确保留情感无关内容。

Result: 在构建的L-AVC数据集上进行全面实验评估，结果表明EPEM方法在L-AVC任务上优于多个最先进的基线方法，证明了情感信息对L-AVC的重要性以及EPEM在高效精确操纵情感信息方面的有效性。

Conclusion: 本文提出的L-AVC任务和EPEM方法填补了情感视觉定制领域的空白，通过大语言模型实现了对图像主观情感的高效精确编辑，为情感感知的视觉定制提供了有效解决方案。

Abstract: Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.

</details>


### [15] [DeepSVU: Towards In-depth Security-oriented Video Understanding via Unified Physical-world Regularized MoE](https://arxiv.org/abs/2602.18019)
*Yujie Jin,Wenxin Zhang,Jingjing Wang,Guodong Zhou*

Main category: cs.CV

TL;DR: 该论文提出了深度安全导向视频理解（DeepSVU）新任务，旨在不仅检测威胁，还要归因和评估威胁原因，并提出了统一物理世界正则化MoE（UPRM）方法来解决建模和权衡物理世界信息的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有安全导向视频理解（SVU）研究主要关注检测和定位视频中的威胁（如枪击、抢劫），但缺乏生成和评估威胁原因的有效能力。为了填补这一空白，本文提出了深度安全导向视频理解（DeepSVU）新任务。

Method: 提出了统一物理世界正则化MoE（UPRM）方法，包含两个关键组件：统一物理世界增强MoE（UPE）块和物理世界权衡正则化器（PTR），分别用于建模从粗到细的物理世界信息和自适应权衡这些因素。

Result: 在DeepSVU指令数据集（UCF-C指令和CUVA指令）上的大量实验表明，UPRM优于多个先进的视频-语言模型以及非VLM方法，证明了从粗到细的物理世界信息在DeepSVU任务中的重要性以及UPRM在捕捉此类信息方面的有效性。

Conclusion: 本文提出的DeepSVU任务和UPRM方法有效解决了安全导向视频理解中威胁原因归因和评估的挑战，通过建模物理世界信息提升了视频安全分析能力。

Abstract: In the literature, prior research on Security-oriented Video Understanding (SVU) has predominantly focused on detecting and localize the threats (e.g., shootings, robberies) in videos, while largely lacking the effective capability to generate and evaluate the threat causes. Motivated by these gaps, this paper introduces a new chat paradigm SVU task, i.e., In-depth Security-oriented Video Understanding (DeepSVU), which aims to not only identify and locate the threats but also attribute and evaluate the causes threatening segments. Furthermore, this paper reveals two key challenges in the proposed task: 1) how to effectively model the coarse-to-fine physical-world information (e.g., human behavior, object interactions and background context) to boost the DeepSVU task; and 2) how to adaptively trade off these factors. To tackle these challenges, this paper proposes a new Unified Physical-world Regularized MoE (UPRM) approach. Specifically, UPRM incorporates two key components: the Unified Physical-world Enhanced MoE (UPE) Block and the Physical-world Trade-off Regularizer (PTR), to address the above two challenges, respectively. Extensive experiments conduct on our DeepSVU instructions datasets (i.e., UCF-C instructions and CUVA instructions) demonstrate that UPRM outperforms several advanced Video-LLMs as well as non-VLM approaches. Such information.These justify the importance of the coarse-to-fine physical-world information in the DeepSVU task and demonstrate the effectiveness of our UPRM in capturing such information.

</details>


### [16] [UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models](https://arxiv.org/abs/2602.18020)
*Jiabing Yang,Yixiang Chen,Yuan Xu,Peiyan Li,Xiangnan Wu,Zichen Wen,Bowen Fang,Tao Yu,Zhengbo Zhang,Yingda Li,Kai Wang,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: 提出UAOR方法，一种无需训练、即插即用的模块，通过不确定性感知的观察信息重注入机制，在VLA模型推理时增强对观察信息的关注，提升动作生成的置信度和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型增强方法通常需要额外的观察线索（如深度图、点云）或辅助模块（如目标检测器、编码器），这些方法需要昂贵的数据收集和额外训练。作者希望开发一种无需训练、即插即用的模块来提升VLA模型的性能。

Method: 提出不确定性感知观察重注入（UAOR）方法：当当前语言模型层表现出高不确定性（通过动作熵衡量）时，通过注意力检索将关键观察信息重注入到下一层的FFN中。该方法利用语言模型中FFN作为"键值记忆"的特性，在推理过程中增强对观察信息的关注。

Result: 综合实验表明，该方法在各种VLA模型上都能持续提升性能，涵盖仿真和真实世界任务，且开销极小。UAOR无需额外的观察线索或模块，成为现有VLA流程的通用实用插件。

Conclusion: UAOR是一种有效、无需训练、即插即用的VLA模型增强模块，通过不确定性感知的观察信息重注入机制，在推理过程中提升模型对观察信息的关注，实现更自信和可靠的动作生成。

Abstract: Vision-Language-Action (VLA) models leverage pretrained Vision-Language Models (VLMs) as backbones to map images and instructions to actions, demonstrating remarkable potential for generalizable robotic manipulation. To enhance performance, existing methods often incorporate extra observation cues (e.g., depth maps, point clouds) or auxiliary modules (e.g., object detectors, encoders) to enable more precise and reliable task execution, yet these typically require costly data collection and additional training. Inspired by the finding that Feed-Forward Network (FFN) in language models can act as "key-value memory", we propose Uncertainty-aware Observation Reinjection (UAOR), an effective, training-free and plug-and-play module for VLA models. Specifically, when the current language model layer exhibits high uncertainty, measured by Action Entropy, it reinjects key observation information into the next layer's Feed-Forward Network (FFN) through attention retrieval. This mechanism helps VLAs better attend to observations during inference, enabling more confident and faithful action generation. Comprehensive experiments show that our method consistently improves diverse VLA models across simulation and real-world tasks with minimal overhead. Notably, UAOR eliminates the need for additional observation cues or modules, making it a versatile and practical plug-in for existing VLA pipelines. The project page is at https://uaor.jiabingyang.cn.

</details>


### [17] [Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers](https://arxiv.org/abs/2602.18022)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: 本文提出DCAG框架，通过同时操控DiT注意力机制中的Key和Value通道来实现训练自由的编辑强度控制，相比仅操控Key的方法在编辑保真度上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于DiT的图像编辑模型需要训练自由的编辑强度控制方法，但现有注意力操控方法仅关注Key空间来调节注意力路由，完全忽略了控制特征聚合的Value空间。

Method: 首先发现DiT多模态注意力层中Key和Value投影都存在明显的偏置-增量结构，然后提出双通道注意力引导(DCAG)框架，同时操控Key通道（控制注意力位置）和Value通道（控制聚合内容）。理论分析表明Key通道通过非线性softmax函数作为粗粒度控制，Value通道通过线性加权求和作为细粒度补充。

Result: 在PIE-Bench基准测试（700张图像，10个编辑类别）上，DCAG在所有保真度指标上都优于仅使用Key引导的方法，在局部编辑任务中改进最显著：对象删除（LPIPS降低4.9%）和对象添加（LPIPS降低3.2%）。

Conclusion: DCAG通过同时操控Key和Value通道的二维参数空间(δ_k, δ_v)，实现了比任何单通道方法更精确的编辑-保真度权衡，为基于DiT的图像编辑提供了更精细的控制能力。

Abstract: Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value space -- which governs feature aggregation -- entirely unexploited. In this paper, we first reveal that both Key and Value projections in DiT's multi-modal attention layers exhibit a pronounced bias-delta structure, where token embeddings cluster tightly around a layer-specific bias vector. Building on this observation, we propose Dual-Channel Attention Guidance (DCAG), a training-free framework that simultaneously manipulates both the Key channel (controlling where to attend) and the Value channel (controlling what to aggregate). We provide a theoretical analysis showing that the Key channel operates through the nonlinear softmax function, acting as a coarse control knob, while the Value channel operates through linear weighted summation, serving as a fine-grained complement. Together, the two-dimensional parameter space $(δ_k, δ_v)$ enables more precise editing-fidelity trade-offs than any single-channel method. Extensive experiments on the PIE-Bench benchmark (700 images, 10 editing categories) demonstrate that DCAG consistently outperforms Key-only guidance across all fidelity metrics, with the most significant improvements observed in localized editing tasks such as object deletion (4.9% LPIPS reduction) and object addition (3.2% LPIPS reduction).

</details>


### [18] [Spatio-temporal Decoupled Knowledge Compensator for Few-Shot Action Recognition](https://arxiv.org/abs/2602.18043)
*Hongyu Qu,Xiangbo Shu,Rui Yan,Hailiang Gao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: DiST提出了一种用于少样本动作识别的分解-融合框架，利用大语言模型提供的解耦空间和时间知识来学习表达性多粒度原型。


<details>
  <summary>Details</summary>
Motivation: 现有少样本动作识别方法通常使用语义粗糙的类别名称作为辅助上下文来指导学习判别性视觉特征，但动作名称提供的上下文过于有限，无法为捕捉动作中的新颖空间和时间概念提供足够的背景知识。

Method: 提出DiST框架：1) 分解阶段：将普通动作名称解耦为多样化的时空属性描述；2) 融合阶段：提出空间/时间知识补偿器(SKC/TKC)来发现判别性的对象级和帧级原型。SKC在空间知识指导下自适应聚合重要补丁标记，TKC利用时间属性辅助帧间时间关系建模。

Result: 实验结果表明DiST在五个标准少样本动作识别数据集上达到了最先进的性能。

Conclusion: DiST通过利用大语言模型提供的解耦空间和时间知识，能够学习表达性多粒度原型，有效捕捉细粒度空间细节和多样化时间模式，在少样本动作识别任务中表现出色。

Abstract: Few-Shot Action Recognition (FSAR) is a challenging task that requires recognizing novel action categories with a few labeled videos. Recent works typically apply semantically coarse category names as auxiliary contexts to guide the learning of discriminative visual features. However, such context provided by the action names is too limited to provide sufficient background knowledge for capturing novel spatial and temporal concepts in actions. In this paper, we propose DiST, an innovative Decomposition-incorporation framework for FSAR that makes use of decoupled Spatial and Temporal knowledge provided by large language models to learn expressive multi-granularity prototypes. In the decomposition stage, we decouple vanilla action names into diverse spatio-temporal attribute descriptions (action-related knowledge). Such commonsense knowledge complements semantic contexts from spatial and temporal perspectives. In the incorporation stage, we propose Spatial/Temporal Knowledge Compensators (SKC/TKC) to discover discriminative object-level and frame-level prototypes, respectively. In SKC, object-level prototypes adaptively aggregate important patch tokens under the guidance of spatial knowledge. Moreover, in TKC, frame-level prototypes utilize temporal attributes to assist in inter-frame temporal relation modeling. These learned prototypes thus provide transparency in capturing fine-grained spatial details and diverse temporal patterns. Experimental results show DiST achieves state-of-the-art results on five standard FSAR datasets.

</details>


### [19] [CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras](https://arxiv.org/abs/2602.18047)
*Rong Fu,Wenxin Zhang,Yibo Meng,Jia Yee Tan,Jiaxuan Lu,Rui Lu,Jiekai Wu,Zhaolu Kang,Simon Fong*

Main category: cs.CV

TL;DR: CityGuard：一种用于分散式监控的隐私保护身份检索框架，通过拓扑感知Transformer处理视角变化、遮挡和域偏移，同时满足数据保护要求。


<details>
  <summary>Details</summary>
Motivation: 城市规模的人员重识别面临视角变化、遮挡和域偏移等外观变化挑战，同时需要遵守数据保护规定，防止共享原始图像数据。

Method: 1) 分散自适应度量学习器根据特征分布调整实例级边界；2) 空间条件注意力将粗略几何信息注入图自注意力；3) 差分隐私嵌入映射与紧凑近似索引结合，支持安全高效部署。

Result: 在Market-1501和其他公共基准测试中，该框架在检索精度和查询吞吐量方面均优于强基线，验证了其在隐私关键城市身份匹配中的实用性。

Conclusion: CityGuard框架能够生成对视角变化、遮挡和域偏移鲁棒的描述符，并在严格的差分隐私计算下实现隐私与效用的可调平衡，适用于隐私关键的城市身份匹配应用。

Abstract: City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.

</details>


### [20] [Temporal Consistency-Aware Text-to-Motion Generation](https://arxiv.org/abs/2602.18057)
*Hongsong Wang,Wenjing Yan,Qiuxia Lai,Xin Geng*

Main category: cs.CV

TL;DR: TCA-T2M：一种时间一致性感知的文本到动作生成框架，通过跨序列时间对齐和运动约束提升动作生成的语义对齐和物理合理性


<details>
  <summary>Details</summary>
Motivation: 现有两阶段文本到动作生成框架通常忽略跨序列时间一致性（即相同动作在不同实例间共享的时间结构），导致语义错位和物理上不合理的动作

Method: 提出TCA-T2M框架：1）时间一致性感知空间VQ-VAE用于跨序列时间对齐；2）掩码运动变换器用于文本条件动作生成；3）运动学约束块减轻离散化伪影确保物理合理性

Result: 在HumanML3D和KIT-ML基准测试中达到最先进性能，证明了时间一致性对鲁棒和连贯文本到动作生成的重要性

Conclusion: TCA-T2M通过引入时间一致性感知机制有效解决了现有文本到动作生成中的语义对齐和物理合理性问题，为更鲁棒的动作生成提供了新思路

Abstract: Text-to-Motion (T2M) generation aims to synthesize realistic human motion sequences from natural language descriptions. While two-stage frameworks leveraging discrete motion representations have advanced T2M research, they often neglect cross-sequence temporal consistency, i.e., the shared temporal structures present across different instances of the same action. This leads to semantic misalignments and physically implausible motions. To address this limitation, we propose TCA-T2M, a framework for temporal consistency-aware T2M generation. Our approach introduces a temporal consistency-aware spatial VQ-VAE (TCaS-VQ-VAE) for cross-sequence temporal alignment, coupled with a masked motion transformer for text-conditioned motion generation. Additionally, a kinematic constraint block mitigates discretization artifacts to ensure physical plausibility. Experiments on HumanML3D and KIT-ML benchmarks demonstrate that TCA-T2M achieves state-of-the-art performance, highlighting the importance of temporal consistency in robust and coherent T2M generation.

</details>


### [21] [Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation](https://arxiv.org/abs/2602.18066)
*Daniel Busch,Christian Bohn,Thomas Kurbiel,Klaus Friedrichs,Richard Meyes,Tobias Meisen*

Main category: cs.CV

TL;DR: 该论文提出了一种两阶段训练策略，用于鸟瞰图语义分割，通过自监督预训练减少对标注数据的依赖，在仅使用50%标注数据的情况下仍能超越全监督基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前多摄像头鸟瞰图语义分割方法依赖昂贵且标注不一致的地面真值数据，这限制了方法的可扩展性和实用性。作者旨在减少对标注数据的依赖，同时保持甚至提升模型性能。

Method: 采用两阶段训练策略：1）自监督预训练阶段：将BEVFormer预测结果可微分地重投影到图像平面，使用Mask2Former生成的多视角语义伪标签进行训练，并加入时间一致性损失；2）监督微调阶段：仅使用50%的标注数据集进行微调。

Result: 在nuScenes数据集上，该方法比全监督基线模型提升高达2.5个百分点的mIoU，同时将标注数据使用量减半，总训练时间减少三分之二。

Conclusion: 可微分重投影加相机视角伪标签能够产生可迁移的BEV特征，为减少标注依赖的自动驾驶感知提供了一条可扩展的路径。

Abstract: Dense Bird's Eye View (BEV) semantic maps are central to autonomous driving, yet current multi-camera methods depend on costly, inconsistently annotated BEV ground truth. We address this limitation with a two-phase training strategy for fine-grained road marking segmentation that removes full supervision during pretraining and halves the amount of training data during fine-tuning while still outperforming the comparable supervised baseline model. During the self-supervised pretraining, BEVFormer predictions are differentiably reprojected into the image plane and trained against multi-view semantic pseudo-labels generated by the widely used semantic segmentation model Mask2Former. A temporal loss encourages consistency across frames. The subsequent supervised fine-tuning phase requires only 50% of the dataset and significantly less training time. With our method, the fine-tuning benefits from rich priors learned during pretraining boosting the performance and BEV segmentation quality (up to +2.5pp mIoU over the fully supervised baseline) on nuScenes. It simultaneously halves the usage of annotation data and reduces total training time by up to two thirds. The results demonstrate that differentiable reprojection plus camera perspective pseudo labels yields transferable BEV features and a scalable path toward reduced-label autonomous perception.

</details>


### [22] [DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text](https://arxiv.org/abs/2602.18089)
*Kunwar Arpit Singh,Ankush Prakash,Haroon R Lone*

Main category: cs.CV

TL;DR: DohaScript是一个大规模、多作者的手写印地语数据集，包含531位贡献者书写的六首传统印地语对句，旨在解决德瓦纳格里文字手写数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 尽管德瓦纳格里文字有数亿使用者，但手写文本在公开基准数据集中严重不足。现有资源规模有限，主要关注孤立字符或短词，缺乏受控词汇内容和作者多样性，无法捕捉德瓦纳格里手写体的连续、融合和结构复杂特性。

Method: 收集531位独特贡献者的手写印地语文本，设计为平行风格语料库，所有作者转录相同的六首传统印地语对句。数据集包含非识别性人口统计元数据，基于客观清晰度和分辨率标准进行严格质量筛选，并提供页面级布局难度标注。

Result: 基线实验显示了清晰的质量分离和强大的对未见作者的泛化能力，突出了数据集的可靠性和实用价值。数据集支持手写识别、作者识别、风格分析和生成建模等任务。

Conclusion: DohaScript旨在作为标准化、可复现的基准，用于推进低资源脚本环境下连续手写德瓦纳格里文本的研究。

Abstract: Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.

</details>


### [23] [Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.18093)
*Hanshuai Cui,Zhiqing Tang,Qianli Ma,Zhi Yao,Weijia Jia*

Main category: cs.CV

TL;DR: PrediT：一种无需训练的DiT加速框架，通过线性多步预测模型输出，结合校正器和动态步长调制，实现5.54倍延迟降低且保持生成质量


<details>
  <summary>Details</summary>
Motivation: DiT在迭代去噪过程中计算成本高，现有基于特征缓存和重用的训练免费加速方法可能导致潜在漂移和视觉质量下降。作者观察到模型输出在扩散轨迹上平滑演化，这为预测而非简单重用提供了理论基础。

Method: 提出PrediT框架：1) 将特征预测建模为线性多步问题，使用经典线性多步方法从历史信息预测未来模型输出；2) 在高动态区域激活校正器防止误差累积；3) 动态步长调制机制通过监控特征变化率自适应调整预测范围。

Result: 在多种基于DiT的图像和视频生成模型上，PrediT实现了高达5.54倍的延迟降低，同时质量下降可忽略不计。

Conclusion: PrediT是一种有效的训练免费加速框架，通过预测而非简单重用特征，在显著降低DiT计算成本的同时保持了生成质量，为扩散模型的实时应用提供了可行方案。

Abstract: Diffusion Transformers (DiT) have emerged as a widely adopted backbone for high-fidelity image and video generation, yet their iterative denoising process incurs high computational costs. Existing training-free acceleration methods rely on feature caching and reuse under the assumption of temporal stability. However, reusing features for multiple steps may lead to latent drift and visual degradation. We observe that model outputs evolve smoothly along much of the diffusion trajectory, enabling principled predictions rather than naive reuse. Based on this insight, we propose \textbf{PrediT}, a training-free acceleration framework that formulates feature prediction as a linear multistep problem. We employ classical linear multistep methods to forecast future model outputs from historical information, combined with a corrector that activates in high-dynamics regions to prevent error accumulation. A dynamic step modulation mechanism adaptively adjusts the prediction horizon by monitoring the feature change rate. Together, these components enable substantial acceleration while preserving generation fidelity. Extensive experiments validate that our method achieves up to $5.54\times$ latency reduction across various DiT-based image and video generation models, while incurring negligible quality degradation.

</details>


### [24] [OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2602.18094)
*Ling Lin,Yang Bai,Heng Su,Congcong Zhu,Yaoxing Wang,Yang Zhou,Huazhu Fu,Jingrun Chen*

Main category: cs.CV

TL;DR: OODBench：一个自动化构建的基准测试，用于评估视觉语言模型处理分布外数据的能力，包含4万个实例级OOD实例-类别对，发现现有VLM在常见类别上仍存在显著性能下降。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用中，数据通常不满足独立同分布假设，而分布外数据处理不当可能带来安全风险（如自动驾驶、医疗辅助）。现有研究缺乏全面评估VLM处理OOD数据能力的有效基准。

Method: 提出OODBench方法，采用最小人工验证的自动化方式构建新基准，包含4万个实例级OOD实例-类别对。同时提出可靠自动化评估指标，采用从基础到高级的渐进式提示问题来更全面评估OOD数据对不同难度问题的影响。

Result: 当前VLM在OODBench上仍表现出显著性能下降，即使底层图像类别是常见的。提出的自动化评估方法能够有效评估OOD数据对模型性能的影响。

Conclusion: OODBench为评估VLM处理分布外数据能力提供了有效基准，总结了重要发现和见解，有助于未来在OOD数据获取和评估方面的研究。

Abstract: Existing Visual-Language Models (VLMs) have achieved significant progress by being trained on massive-scale datasets, typically under the assumption that data are independent and identically distributed (IID). However, in real-world scenarios, it is often impractical to expect that all data processed by an AI system satisfy this assumption. Furthermore, failure to appropriately handle out-of-distribution (OOD) objects may introduce safety risks in real-world applications (e.g., autonomous driving or medical assistance). Unfortunately, current research has not yet provided valid benchmarks that can comprehensively assess the performance of VLMs in response to OOD data. Therefore, we propose OODBench, a predominantly automated method with minimal human verification, for constructing new benchmarks and evaluating the ability of VLMs to process OOD data. OODBench contains 40K instance-level OOD instance-category pairs, and we show that current VLMs still exhibit notable performance degradation on OODBench, even when the underlying image categories are common. In addition, we propose a reliable automated assessment metric that employs a Basic-to-Advanced Progression of prompted questions to assess the impact of OOD data on questions of varying difficulty more fully. Lastly, we summarize substantial findings and insights to facilitate future research in the acquisition and evaluation of OOD data.

</details>


### [25] [Evaluating Graphical Perception Capabilities of Vision Transformers](https://arxiv.org/abs/2602.18178)
*Poonam Poonam,Pere-Pau Vázquez,Timo Ropinski*

Main category: cs.CV

TL;DR: ViTs在可视化图形感知任务中表现不如CNNs和人类，存在感知差距


<details>
  <summary>Details</summary>
Motivation: 虽然ViTs在各种图像任务中表现出色，但其在可视化图形感知任务中的能力尚未被充分探索，而这类任务对解释可视化至关重要

Method: 基于Cleveland和McGill的基础研究，设计了一系列受控的图形感知任务，将ViTs与CNNs和人类参与者进行基准测试

Result: ViTs在通用视觉任务中表现强劲，但在可视化领域的类人图形感知能力有限，与人类感知的一致性较差

Conclusion: ViTs在可视化系统中应用存在重要限制，需要更多考虑其在图形感知建模中的适用性

Abstract: Vision Transformers, ViTs, have emerged as a powerful alternative to convolutional neural networks, CNNs, in a variety of image-based tasks. While CNNs have previously been evaluated for their ability to perform graphical perception tasks, which are essential for interpreting visualizations, the perceptual capabilities of ViTs remain largely unexplored. In this work, we investigate the performance of ViTs in elementary visual judgment tasks inspired by the foundational studies of Cleveland and McGill, which quantified the accuracy of human perception across different visual encodings. Inspired by their study, we benchmark ViTs against CNNs and human participants in a series of controlled graphical perception tasks. Our results reveal that, although ViTs demonstrate strong performance in general vision tasks, their alignment with human-like graphical perception in the visualization domain is limited. This study highlights key perceptual gaps and points to important considerations for the application of ViTs in visualization systems and graphical perceptual modeling.

</details>


### [26] [BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards](https://arxiv.org/abs/2602.18193)
*Yiran Yang,Zhaowei Liu,Yuan Yuan,Yukun Song,Xiong Ma,Yinghao Song,Xiangji Zeng,Lu Sun,Yulu Wang,Hai Zhou,Shuai Cui,Zhaohan Gong,Jiefei Zhang*

Main category: cs.CV

TL;DR: BLM-Guard：一个用于短视频广告内容审核的框架，结合思维链推理、规则策略和强化学习，通过多任务架构检测模态内操纵和跨模态不匹配


<details>
  <summary>Details</summary>
Motivation: 短视频平台上的多模态广告存在欺骗性视觉、语音和字幕内容，需要比社区安全过滤器更细粒度、基于策略的审核机制

Method: 1. 结合思维链推理与基于规则的策略原则和批评者引导的奖励；2. 规则驱动的ICoT数据合成管道生成结构化场景描述、推理链和标签；3. 强化学习使用平衡因果一致性与策略遵从性的复合奖励优化模型；4. 多任务架构建模模态内操纵和跨模态不匹配

Result: 在真实短视频广告上的实验显示，BLM-Guard在准确性、一致性和泛化能力方面超越了强基线方法

Conclusion: BLM-Guard框架为商业广告内容审核提供了一种有效的方法，通过融合规则驱动数据合成、强化学习和多任务建模，实现了对多模态欺骗性内容的细粒度检测

Abstract: Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning with rule-based policy principles and a critic-guided reward. A rule-driven ICoT data-synthesis pipeline jump-starts training by generating structured scene descriptions, reasoning chains and labels, cutting annotation costs. Reinforcement learning then refines the model using a composite reward balancing causal coherence with policy adherence. A multitask architecture models intra-modal manipulations (e.g., exaggerated imagery) and cross-modal mismatches (e.g., subtitle-speech drift), boosting robustness. Experiments on real short-video ads show BLM-Guard surpasses strong baselines in accuracy, consistency and generalization.

</details>


### [27] [A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion](https://arxiv.org/abs/2602.18199)
*Gahyeon Shim,Soogeun Park,Hyemin Ahn*

Main category: cs.CV

TL;DR: DMC是一个后处理模块，通过自监督数据驱动方法改进文本生成动作的物理合理性，同时保持语义一致性，可应用于各种文本到动作生成模型。


<details>
  <summary>Details</summary>
Motivation: 当前文本生成人体动作的方法在语义对齐方面取得了进展，但确保动作的语义和物理双重真实性仍然是一个挑战。现有方法生成的动经常存在物理不合理的问题，如脚部漂浮等。

Method: 提出了Distortion-aware Motion Calibrator (DMC)，这是一个后处理模块，采用自监督和数据驱动的方法。DMC学习在给定故意扭曲的动作和原始文本描述时，生成物理合理的动作，而不依赖复杂的物理建模。

Result: DMC在多个文本到动作生成模型上表现出色：在T2M上FID分数降低42.74%，在T2M-GPT上降低13.20%，同时获得最高的R-Precision。应用于MoMask等高质量模型时，穿透率降低33.0%，并将漂浮伪影调整到更接近真实参考。

Conclusion: DMC作为一个有前景的后处理动作细化框架，能够通过结合文本语义和物理合理性，改进任何类型的文本到动作生成模型，在保持语义一致性的同时提高物理合理性。

Abstract: Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines physically implausible motions (e.g., foot floating) while preserving semantic consistency with the original textual description. Rather than relying on complex physical modeling, we propose a self-supervised and data-driven approach, whereby DMC learns to obtain physically plausible motions when an intentionally distorted motion and the original textual descriptions are given as inputs. We evaluate DMC as a post-hoc module to improve motions obtained from various text-to-motion generation models and demonstrate its effectiveness in improving physical plausibility while enhancing semantic consistency. The experimental results show that DMC reduces FID score by 42.74% on T2M and 13.20% on T2M-GPT, while also achieving the highest R-Precision. When applied to high-quality models like MoMask, DMC improves the physical plausibility of motions by reducing penetration by 33.0% as well as adjusting floating artifacts closer to the ground-truth reference. These results highlight that DMC can serve as a promising post-hoc motion refinement framework for any kind of text-to-motion models by incorporating textual semantics and physical plausibility.

</details>


### [28] [On the Adversarial Robustness of Discrete Image Tokenizers](https://arxiv.org/abs/2602.18252)
*Rishika Bhagwatkar,Irina Rish,Nicolas Flammarion,Francesco Croce*

Main category: cs.CV

TL;DR: 该论文首次研究了离散图像分词器对对抗攻击的脆弱性，提出了针对分词器的攻击方法，并开发了无监督对抗训练防御策略，提高了多模态基础模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 离散图像分词器在多模态系统中应用日益广泛，但相比CLIP编码器，其对抗攻击脆弱性尚未被探索。本文旨在填补这一研究空白，研究分词器的安全漏洞并提出防御方案。

Method: 1. 提出针对离散分词器的对抗攻击方法，旨在扰动分词器提取的特征并改变提取的token；2. 受鲁棒CLIP编码器研究启发，采用无监督对抗训练微调流行分词器，保持其他组件不变。

Result: 攻击方法计算高效、应用无关，在分类、多模态检索和字幕生成任务中均有效。防御方法显著提高了对无监督和端到端监督攻击的鲁棒性，并能泛化到未见任务和数据。

Conclusion: 本文强调了分词器鲁棒性在下游任务中的关键作用，为开发安全的多模态基础模型迈出了重要一步。无监督对抗训练相比监督方法更具通用性，可利用未标记图像。

Abstract: Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial attacks has not been explored. Ours being the first work studying this topic, we first formulate attacks that aim to perturb the features extracted by discrete tokenizers, and thus change the extracted tokens. These attacks are computationally efficient, application-agnostic, and effective across classification, multimodal retrieval, and captioning tasks. Second, to defend against this vulnerability, inspired by recent work on robust CLIP encoders, we fine-tune popular tokenizers with unsupervised adversarial training, keeping all other components frozen. While unsupervised and task-agnostic, our approach significantly improves robustness to both unsupervised and end-to-end supervised attacks and generalizes well to unseen tasks and data. Unlike supervised adversarial training, our approach can leverage unlabeled images, making it more versatile. Overall, our work highlights the critical role of tokenizer robustness in downstream tasks and presents an important step in the development of safe multimodal foundation models.

</details>


### [29] [DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control](https://arxiv.org/abs/2602.18282)
*Shiyan Du,Conghan Yue,Xinyu Cheng,Dongyu Zhang*

Main category: cs.CV

TL;DR: DEIG是一个用于细粒度可控多实例生成的框架，通过实例细节提取器和细节融合模块解决现有方法在复杂文本描述下的语义理解挑战，在空间一致性、语义准确性和组合泛化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多实例生成方法在空间布局和属性绑定方面已有进步，但在处理复杂文本描述时仍面临细粒度语义理解的挑战，特别是在防止实例间属性泄漏和精确匹配局部化文本描述方面存在局限。

Method: 提出DEIG框架，包含两个核心组件：1) 实例细节提取器(IDE)，将文本编码器嵌入转换为紧凑的实例感知表示；2) 细节融合模块(DFM)，应用基于实例的掩码注意力机制防止实例间属性泄漏。还构建了包含详细组合实例描述的高质量数据集，并开发了DEIG-Bench基准测试。

Result: DEIG在多个基准测试中一致优于现有方法，在空间一致性、语义准确性和组合泛化方面表现优异。同时，DEIG可作为即插即用模块，易于集成到标准基于扩散的生成流程中。

Conclusion: DEIG通过创新的实例细节提取和融合机制，有效解决了多实例生成中的细粒度语义理解问题，能够生成与丰富局部化文本描述精确匹配的视觉连贯多实例场景，为可控图像生成提供了有力工具。

Abstract: Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.

</details>


### [30] [Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation](https://arxiv.org/abs/2602.18309)
*Ziyue Liu,Davide Talon,Federico Girella,Zanxi Ruan,Mattia Mondo,Loris Bazzani,Yiming Wang,Marco Cristani*

Main category: cs.CV

TL;DR: LOTS框架通过结合全局草图引导和多个局部草图-文本对来增强时尚图像生成，在保持全局结构的同时利用局部语义指导


<details>
  <summary>Details</summary>
Motivation: 设计师在早期时尚构思阶段使用草图表达结构和轮廓，文本描述补充材质、颜色和风格细节。需要有效结合文本和视觉模态，在利用文本局部属性指导时保持草图视觉结构

Method: 提出LOTS框架：1) 多级条件阶段在共享潜在空间中独立编码局部特征，同时保持全局结构协调；2) 扩散对引导阶段通过注意力机制在扩散模型的多步去噪过程中整合局部和全局条件

Result: 创建了首个时尚数据集Sketchy，包含每张图像的多个文本-草图对，提供高质量专业草图。实验表明方法在保持全局结构的同时利用更丰富的局部语义指导，优于现有技术

Conclusion: LOTS框架通过多级局部-全局条件机制有效结合草图和文本模态，增强了时尚图像生成的结构一致性和语义丰富性，数据集和代码已公开

Abstract: Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an "in the wild" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.

</details>


### [31] [Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting](https://arxiv.org/abs/2602.18314)
*Tianyi Song,Danail Stoyanov,Evangelos Mazomenos,Francisco Vasconcelos*

Main category: cs.CV

TL;DR: Diff2DGS：用于机器人手术中遮挡场景实时重建的两阶段框架，结合扩散模型修复遮挡组织，使用2D高斯泼溅与可学习变形模型捕捉动态变形，在图像质量和深度精度上均超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 机器人手术中实时重建变形手术场景对提升外科医生引导和自动化至关重要。现有方法在遮挡区域重建质量有限，且缺乏3D真值基准导致深度精度评估不足。

Method: 提出两阶段框架：第一阶段使用基于扩散的视频模块，利用时间先验修复被器械遮挡的组织，保持时空一致性；第二阶段采用2D高斯泼溅结合可学习变形模型，捕捉动态组织变形和解剖几何。

Result: 在EndoNeRF上达到38.02 dB PSNR，在StereoMIS上达到34.40 dB PSNR，均超越现有方法。实验表明仅优化图像质量不能保证最优3D重建精度，因此进一步优化深度质量以获得更准确的几何重建。

Conclusion: Diff2DGS在机器人手术场景重建中实现了高质量的遮挡修复和准确的3D几何重建，为手术导航和自动化提供了可靠的技术基础。

Abstract: Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.

</details>


### [32] [Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis](https://arxiv.org/abs/2602.18322)
*Ziteng Cui,Shuhong Liu,Xiaoyu Dong,Xuangeng Chu,Lin Gu,Ming-Hsuan Yang,Tatsuya Harada*

Main category: cs.CV

TL;DR: Luminance-GS++：基于3D高斯泼溅的鲁棒新视角合成框架，通过全局自适应亮度调整和局部像素级残差细化处理复杂光照变化，保持实时渲染效率的同时提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像采集面临复杂光照变化和相机成像管道的固有限制，多视角捕获中光照、传感器响应和ISP配置的差异导致光度不一致性，违反了现代3D新视角合成方法（如NeRF和3DGS）的光度一致性假设，导致重建和渲染质量下降。

Method: 提出Luminance-GS++框架，结合全局视角自适应亮度调整和局部像素级残差细化进行精确色彩校正，设计无监督目标联合强制执行亮度校正以及多视角几何和光度一致性，保持显式3DGS表示不变。

Result: 在低光照、过曝光以及复杂亮度和色彩变化等挑战性场景中展现出最先进的性能，同时保持实时渲染效率。

Conclusion: Luminance-GS++通过创新的光照校正方法有效解决了多视角捕获中的光度不一致问题，在保持3DGS实时渲染优势的同时显著提升了复杂光照条件下的重建和渲染质量。

Abstract: High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.

</details>


### [33] [G-LoG Bi-filtration for Medical Image Classification](https://arxiv.org/abs/2602.18329)
*Qingsong Wang,Jiaxing He,Bingzhe Hou,Tieru Wu,Yang Cao,Cailing Yao*

Main category: cs.CV

TL;DR: 本文提出了一种基于高斯-拉普拉斯算子(G-LoG)的双重过滤方法，用于医学图像拓扑数据分析，通过多参数持久性模块生成特征，在MedMNIST数据集上表现优于单参数过滤，且基于拓扑特征的简单MLP模型性能可与复杂深度学习模型媲美。


<details>
  <summary>Details</summary>
Motivation: 在拓扑数据分析(TDA)中，构建实用的过滤方法来检测对象的拓扑和几何特征是一个重要任务。本文旨在利用拉普拉斯高斯算子在增强医学图像边界方面的能力，开发更适合多参数持久性模块的特征提取方法。

Method: 提出G-LoG(高斯-拉普拉斯高斯)双重过滤方法：1)利用拉普拉斯高斯算子增强医学图像边界；2)将体积图像建模为有界函数；3)证明从有界函数的双重过滤获得的持久性模块的交错距离相对于有界函数的最大范数是稳定的。

Result: 在MedMNIST数据集上的实验表明：1)G-LoG双重过滤显著优于单参数过滤；2)基于该双重过滤生成的拓扑特征训练的简单多层感知器(MLP)性能可与Google AutoML Vision、ResNet、AutoKeras和auto-sklearn等复杂深度学习模型相媲美。

Conclusion: G-LoG双重过滤为医学图像拓扑数据分析提供了一种有效方法，能够生成适合多参数持久性模块的特征，在保持稳定性的同时，显著提升拓扑特征提取性能，为医学图像分析提供了新的拓扑特征提取框架。

Abstract: Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.

</details>


### [34] [Self-Aware Object Detection via Degradation Manifolds](https://arxiv.org/abs/2602.18394)
*Stefan Becker,Simon Weiss,Wolfgang Hübner,Michael Arens*

Main category: cs.CV

TL;DR: 提出基于退化流形的退化感知自感知目标检测框架，通过对比学习组织特征空间，实现无需退化标签的输入质量评估


<details>
  <summary>Details</summary>
Motivation: 目标检测器在标准成像条件下表现良好，但在遇到模糊、噪声、压缩、恶劣天气或分辨率变化时会无声失败。在安全关键应用中，仅产生预测而不评估输入是否在检测器名义操作范围内是不够的

Method: 基于退化流形的退化感知自感知框架，通过多层对比学习训练轻量级嵌入头，将具有相同退化组成的图像拉近，不同退化配置的图像推远，形成几何组织的表示空间。从干净训练嵌入中估计原始原型作为名义操作点

Result: 在合成损坏基准测试、跨数据集零样本迁移和自然天气引起的分布偏移实验中，显示出强大的原始-退化可分离性、跨多个检测器架构的一致行为，以及在语义偏移下的稳健泛化能力

Conclusion: 退化感知表示几何为自感知目标检测提供了实用且检测器无关的基础，能够独立于检测置信度提供退化引起的偏移的内在图像级信号

Abstract: Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.
  We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.
  To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.
  Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.

</details>


### [35] [Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control](https://arxiv.org/abs/2602.18422)
*Linxi Xie,Lisong C. Sun,Ashley Neall,Tong Wu,Shengqu Cai,Gordon Wetzstein*

Main category: cs.CV

TL;DR: 研究人员开发了一个以人为中心的视频世界模型，能够通过追踪头部和手部姿势来控制生成虚拟环境，相比现有方法提供了更精细的控制能力。


<details>
  <summary>Details</summary>
Motivation: 扩展现实（XR）需要能够响应用户真实世界动作的生成模型，但当前的视频世界模型只能接受文本或键盘输入等粗略控制信号，限制了其在具身交互中的实用性。

Method: 提出了一个以人为中心的视频世界模型，能够同时接受追踪的头部姿势和关节级手部姿势作为条件输入。评估了现有的扩散变换器条件策略，并提出了一种有效的3D头部和手部控制机制，支持灵巧的手-物体交互。训练了一个双向视频扩散模型教师，并将其蒸馏成一个因果的交互式系统，用于生成第一人称虚拟环境。

Result: 通过人类受试者评估，该系统相比相关基线方法，在任务表现上有显著提升，并且在感知到的动作控制程度上显著更高。

Conclusion: 该研究成功开发了一个能够通过追踪头部和手部姿势进行精细控制的视频世界模型，为扩展现实应用提供了更自然、更精确的交互方式，显著提升了用户的控制感和任务表现。

Abstract: Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.

</details>


### [36] [CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation](https://arxiv.org/abs/2602.18424)
*Xia Su,Ruiqi Chen,Benlin Liu,Jingwei Ma,Zonglin Di,Ranjay Krishna,Jon Froehlich*

Main category: cs.CV

TL;DR: CapNav是一个评估视觉语言模型在考虑智能体物理能力约束下进行室内导航的新基准，包含5种代表性智能体、45个真实室内场景、473个导航任务和2365个问答对，测试结果显示当前VLM在严格移动约束下导航性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现实世界导航决策需要考虑智能体的物理移动约束（如扫地机器人不能爬楼梯，四足机器人可以），而现有视觉语言导航研究往往忽视这些能力限制。需要评估VLM在考虑智能体具体物理和操作能力下的导航表现。

Method: 定义了5种代表性人类和机器人智能体，描述其物理尺寸、移动能力和环境交互能力。构建包含45个真实室内场景、473个导航任务和2365个问答对的CapNav基准，测试VLM能否基于智能体能力穿越室内环境。评估了13个现代VLM模型。

Result: 当前VLM的导航性能随着移动约束收紧而急剧下降，即使是先进模型在处理需要空间维度推理的障碍类型时也表现不佳。模型难以准确考虑智能体的物理能力限制进行导航决策。

Conclusion: CapNav基准揭示了当前VLM在能力感知导航方面的局限性，为未来VLM在具身空间推理方面的进步提供了机会，强调了开发能够理解智能体物理约束的导航系统的重要性。

Abstract: Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav

</details>


### [37] [Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory](https://arxiv.org/abs/2602.18434)
*Vatsal Agarwal,Saksham Suri,Matthew Gwilliam,Pulkit Kumar,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: MemStream通过增加token预算、自适应选择策略和训练免费检索专家混合，显著提升流媒体视频问答性能


<details>
  <summary>Details</summary>
Motivation: 现有流媒体视频理解方法使用有限的每帧token数量，导致细粒度视觉细节丢失，且在处理密集视频流时存在查询-帧相似度随时间增加的问题，偏向检索后期帧

Method: 1. 增加token预算以实现更细粒度的时空理解；2. 引入自适应选择策略减少token冗余同时保留局部时空信息；3. 提出训练免费的检索专家混合方法，利用外部模型更好识别相关帧

Result: 在CG-Bench上提升8.0%，LVBench上提升8.5%，VideoMME(Long)上提升2.4%（相比ReKV with Qwen2.5-VL-7B）

Conclusion: MemStream通过扩展token预算、自适应token选择和检索专家混合，显著提升了流媒体视频问答的性能，解决了现有方法在处理密集视频流时的局限性

Abstract: Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [38] [On the scaling relationship between cloze probabilities and language model next-token prediction](https://arxiv.org/abs/2602.17848)
*Cassandra L. Jacobs,Morgan Grobol*

Main category: cs.CL

TL;DR: 大型语言模型在预测眼动和阅读时间数据方面表现更好，但会低估人类反应概率；模型越大，对完形填空数据的预测质量越高，但对词汇共现统计敏感性降低


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在预测人类语言处理行为（眼动、阅读时间、完形填空）方面的表现，探索模型规模如何影响其对不同层次语言信息的敏感性

Method: 通过比较不同规模的语言模型在眼动数据、阅读时间数据和完形填空任务上的预测表现，分析模型对词汇共现统计和语义信息的敏感性差异

Result: 大型模型在预测眼动和阅读时间数据方面表现更好，但在完形填空任务中低估人类反应概率；模型越大，对下一个词的预测质量越高，对词汇共现统计的敏感性降低，但与人类完形填空反应的语义对齐更好

Conclusion: 大型语言模型更强的记忆能力使其能猜测更语义合适的词，但使其对单词识别相关的低层次信息敏感性降低，这支持了模型规模影响语言处理不同层次敏感性的观点

Abstract: Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.

</details>


### [39] [Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations](https://arxiv.org/abs/2602.17881)
*Joschka Braun*

Main category: cs.CL

TL;DR: 研究发现：控制语言模型行为的转向向量虽然平均有效，但可靠性因行为而异；转向可靠性取决于训练激活差异的余弦相似度和正负激活在转向方向上的分离程度。


<details>
  <summary>Details</summary>
Motivation: 转向向量是一种通过添加学习偏置来控制语言模型行为的轻量级方法，但在许多目标行为上效果不稳定。本研究旨在探究为什么转向可靠性在不同行为间存在差异，以及训练数据如何影响转向效果。

Method: 通过分析转向向量训练数据，研究训练激活差异的余弦相似度、正负激活在转向方向上的分离程度，以及不同提示变体训练的转向向量之间的方向差异和效果相关性。

Result: 1. 训练激活差异的余弦相似度越高，转向越可靠；2. 正负激活在转向方向上分离度越好的行为数据集，转向效果越可靠；3. 不同提示变体训练的转向向量方向不同但效果相似，且在不同数据集上效果相关。

Conclusion: 转向向量不可靠的原因是潜在目标行为表示无法被线性转向方向有效近似。这些发现为诊断转向不可靠性提供了实用方法，并激励开发更鲁棒的转向方法，明确考虑非线性潜在行为表示。

Abstract: Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.

</details>


### [40] [Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions](https://arxiv.org/abs/2602.17907)
*Raymond Li,Amirhossein Abaskohi,Chuyuan Li,Gabriel Murray,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出使用语言模型生成语义软标签目标来改进神经主题模型，通过投影下一个token概率到预定义词汇表获得上下文丰富的监督信号，显著提升主题质量和文档检索效果。


<details>
  <summary>Details</summary>
Motivation: 传统神经主题模型通常通过重构文档的词袋表示进行优化，忽略了上下文信息且难以处理数据稀疏性问题，需要更有效的监督信号来提升主题质量。

Method: 使用语言模型生成语义软标签目标：通过专门设计的提示词条件化，将下一个token的概率投影到预定义词汇表上，获得上下文丰富的监督信号。然后训练主题模型使用语言模型的隐藏状态来重构这些软标签。

Result: 在三个数据集上的实验表明，该方法在主题连贯性和纯度方面相比现有基线有显著提升。引入的检索指标也显示，该方法在识别语义相似文档方面显著优于现有方法。

Conclusion: 通过语言模型生成语义软标签目标的方法能够有效提升神经主题模型的质量，产生更符合语料库主题结构的主题，特别适用于检索导向的应用场景。

Abstract: Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.

</details>


### [41] [Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering](https://arxiv.org/abs/2602.17911)
*Jash Rajesh Parekh,Wonbin Kweon,Joey Chan,Rezarta Islamaj,Robert Leaman,Pengcheng Jiang,Chih-Hsuan Wei,Zhizheng Wang,Zhiyong Lu,Jiawei Han*

Main category: cs.CL

TL;DR: CondMedQA：首个条件性生物医学问答基准，提出条件门控推理框架，通过构建条件感知知识图谱和选择性激活推理路径来模拟临床条件推理。


<details>
  <summary>Details</summary>
Motivation: 当前生物医学问答系统假设医学知识普遍适用，但真实临床推理本质上是条件性的——几乎所有决策都依赖于患者特定因素（如合并症、禁忌症）。现有基准无法评估这种条件推理，检索增强或基于图的方法也缺乏确保检索知识适用于特定上下文的明确机制。

Method: 提出条件门控推理（CGR）框架：1）构建条件感知知识图谱；2）基于查询条件选择性激活或剪枝推理路径；3）确保检索的知识适用于给定上下文。

Result: CGR在生物医学问答基准测试中匹配或超越最先进性能，同时更可靠地选择条件适当的答案，突显了显式建模条件性对稳健医学推理的重要性。

Conclusion: 显式建模条件性对于稳健的医学推理至关重要，CondMedQA基准和CGR框架为解决生物医学问答中的条件推理问题提供了有效方案。

Abstract: Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.

</details>


### [42] [Analyzing LLM Instruction Optimization for Tabular Fact Verification](https://arxiv.org/abs/2602.17937)
*Xiaotang Du,Giwon Hong,Wai-Chung Kwan,Rohit Saxena,Ivan Titov,Pasquale Minervini,Emily Allaway*

Main category: cs.CL

TL;DR: 本文系统比较了基于DSPy框架的指令优化方法在表格事实验证任务中的效果，发现指令优化能持续提升验证准确率，不同优化器对不同提示技术效果各异。


<details>
  <summary>Details</summary>
Motivation: 指令优化为提升大语言模型推理性能提供了一种轻量级、模型无关的方法，但缺乏在表格事实验证任务中的系统性比较研究。

Method: 基于DSPy优化框架，评估了四种提示技术（直接预测、思维链、带SQL工具的ReAct、带Python执行的CodeAct），研究了三种优化器（COPRO、MiPROv2、SIMBA）在四个基准测试和三个模型家族上的表现。

Result: 指令优化持续提升验证准确率：MiPROv2对思维链提供最稳定的增益，SIMBA对ReAct智能体提供最大收益（尤其在更大模型规模下）。行为分析显示SIMBA通过应用启发式方法鼓励更直接的推理路径。

Conclusion: 思维链在表格事实检查中仍然有效（尤其对小模型），而基于大模型的ReAct智能体虽能达到竞争性性能，但需要仔细的指令优化。不同提示技术需要针对性的优化策略。

Abstract: Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

</details>


### [43] [CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications](https://arxiv.org/abs/2602.17949)
*Victoria Blake,Mathew Miller,Jamie Novak,Sze-yuan Ooi,Blanca Gallego*

Main category: cs.CL

TL;DR: CUICurate是一个基于图检索增强生成的框架，用于自动化UMLS概念集构建，结合知识图谱检索和LLM推理，显著减少人工工作量并提高概念集完整性。


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别工具通常将自由文本映射到UMLS概念唯一标识符，但许多下游任务需要的是包含相关同义词、子类型和超类型的概念集。构建这样的概念集劳动密集、执行不一致，现有工具支持不足，特别是对于直接在UMLS CUI上操作的NLP流水线。

Method: 提出了CUICurate框架，采用基于图的检索增强生成方法：构建并嵌入UMLS知识图谱进行语义检索；针对每个目标概念，从知识图谱检索候选CUI，然后通过大语言模型过滤和分类步骤，比较了GPT-5和GPT-5-mini两种LLM。

Result: 在所有概念上，CUICurate生成的概念集比人工基准更大、更完整，同时保持与人类相当的精确度。GPT-5-mini在过滤阶段召回率更高，而GPT-5的分类结果更接近临床医生判断。输出在多次运行中稳定且计算成本低。

Conclusion: CUICurate提供了一个可扩展且可重复的方法来支持UMLS概念集构建，显著减少人工工作量。通过将基于图的检索与LLM推理相结合，该框架生成聚焦的候选概念集，可适应不同表型和分析需求的临床NLP流水线。

Abstract: Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.

</details>


### [44] [Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering](https://arxiv.org/abs/2602.17981)
*Amine Kobeissi,Philippe Langlais*

Main category: cs.CL

TL;DR: 该论文研究了金融问答中检索增强生成的失败模式，特别是正确文档被检索到但包含答案的具体页面或块被遗漏的问题，并提出了一种针对金融文件页面级检索优化的方法。


<details>
  <summary>Details</summary>
Motivation: 在金融监管文件问答中，虽然检索增强生成被广泛应用，但可靠性依赖于检索到确切的上下文来支持答案。研究发现一个常见的失败模式：正确文档被检索到，但包含答案的具体页面或块被遗漏，导致生成器从不完整的上下文中推断答案。这种文档内检索失败模式在金融问答文献中缺乏系统研究。

Method: 1. 在多个粒度级别（文档、页面、块）评估检索性能；2. 引入基于oracle的分析来提供检索和生成性能的经验上限；3. 在FinanceBench的150个问题子集上，复现并比较多种检索策略（密集、稀疏、混合、分层方法，包括重排序和查询重构）；4. 提出一种领域微调的页面评分器，将页面作为文档和块之间的中间检索单元，专门针对金融文件微调双编码器进行页面级相关性判断。

Result: 1. 不同方法中，文档发现能力的提升通常转化为更强的页面召回率；2. oracle性能表明页面和块级检索仍有改进空间；3. 提出的领域微调页面评分器显著提高了页面召回率和块检索性能，利用了页面的语义连贯性优势。

Conclusion: 该研究揭示了金融问答中检索增强生成的关键失败模式，并提出了针对金融文件页面级检索优化的有效方法。通过专门针对页面级相关性进行微调，能够显著改善检索性能，为高风险的金融问答应用提供了更可靠的解决方案。

Abstract: Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.

</details>


### [45] [Towards More Standardized AI Evaluation: From Models to Agents](https://arxiv.org/abs/2602.18029)
*Ali El Filali,Inès Bedar*

Main category: cs.CL

TL;DR: 论文认为传统基于静态基准测试的AI评估方法已不适用于工具使用的复合智能体系统，需要将评估重新定义为确保系统可信度的核心控制功能。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统从静态模型演变为复合的、使用工具的智能体，评估不再只是最终检查点，而应成为核心控制功能。传统评估方法基于模型中心时代的假设（静态基准、聚合分数、一次性成功标准）已无法有效反映系统在变化和规模化环境中的真实行为。

Method: 论文采用分析性方法而非提出新指标：1）分析评估流水线本身引入的隐性故障模式；2）解释为何高基准分数经常误导团队；3）探讨智能体系统如何从根本上改变性能测量的意义。

Result: 研究发现传统评估方法在智能体时代变得模糊而非澄清系统行为，高基准分数与实际系统可信度之间存在显著差距，评估流水线本身可能成为故障来源。

Conclusion: 评估应重新定义为测量学科而非性能展示，其核心作用是建立对非确定性系统的信任、支持迭代改进和治理，特别是在智能体系统中评估应关注系统在变化环境下是否按预期行为。

Abstract: Evaluation is no longer a final checkpoint in the machine learning lifecycle. As AI systems evolve from static models to compound, tool-using agents, evaluation becomes a core control function. The question is no longer "How good is the model?" but "Can we trust the system to behave as intended, under change, at scale?". Yet most evaluation practices remain anchored in assumptions inherited from the model-centric era: static benchmarks, aggregate scores, and one-off success criteria. This paper argues that such approaches are increasingly obscure rather than illuminating system behavior. We examine how evaluation pipelines themselves introduce silent failure modes, why high benchmark scores routinely mislead teams, and how agentic systems fundamentally alter the meaning of performance measurement. Rather than proposing new metrics or harder benchmarks, we aim to clarify the role of evaluation in the AI era, and especially for agents: not as performance theater, but as a measurement discipline that conditions trust, iteration, and governance in non-deterministic systems.

</details>


### [46] [Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092)
*Matthew DiGiuseppe,Joshua Robison*

Main category: cs.CL

TL;DR: 研究发现，当用户认为聊天AI存在党派偏见时，其纠正错误观念的说服效果会降低28%，表明AI说服力受政治中立性感知影响


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型进入党派冲突，精英阶层越来越多地将其描绘为意识形态偏向的工具。本研究旨在测试这些可信度攻击是否会降低基于LLM的说服效果，探究AI说服力的政治条件性

Method: 在美国进行了一项预注册调查实验（N=2144），参与者与ChatGPT进行三轮对话，讨论个人持有的经济政策误解。实验组接受简短信息提示LLM对参与者所属党派存在偏见，对照组为中性条件

Result: 与中性对照组相比，提示LLM存在党派偏见的信息使说服效果降低28%。对话记录分析表明，警告改变了互动方式：受访者更频繁地反驳，接受度更低

Conclusion: 对话AI的说服效果具有政治条件性，受党派一致性感知的制约。当用户认为AI存在党派偏见时，其纠正错误观念的有效性会显著降低

Abstract: Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.

</details>


### [47] [Agentic Adversarial QA for Improving Domain-Specific LLMs](https://arxiv.org/abs/2602.18137)
*Vincent Grari,Ciprian Tomoiaga,Sylvain Lamprier,Tatsunori Hashimoto,Marcin Detyniecki*

Main category: cs.CL

TL;DR: 提出对抗性提问生成框架，通过比较待适应模型与专家模型的输出，生成紧凑的语义挑战性问题，在专业领域实现更高准确率且样本效率更高


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域适应能力有限，现有微调方法面临高质量任务相关数据稀缺的问题。传统合成数据生成方法虽然擅长事实回忆和概念知识，但存在两个关键缺陷：对专业领域的解释性推理能力支持不足，以及生成的合成语料库过大且冗余导致样本效率低下。

Method: 提出对抗性提问生成框架，通过迭代反馈驱动过程，比较待适应模型与基于参考文档的稳健专家模型的输出，生成紧凑的语义挑战性问题。这种方法旨在揭示和解决理解差距，产生高质量的训练数据。

Result: 在LegalBench语料库的专业子集上评估表明，该方法能够以显著更少的合成样本实现更高的准确率，证明了其在专业领域适应中的有效性和样本效率。

Conclusion: 对抗性提问生成框架为专业领域的大语言模型适应提供了一种有效解决方案，通过生成紧凑的语义挑战性问题，克服了传统合成数据生成方法的局限性，实现了更好的准确率和样本效率。

Abstract: Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.

</details>


### [48] [Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention](https://arxiv.org/abs/2602.18145)
*Siya Qi,Yudong Chen,Runcong Zhao,Qinglin Zhu,Zhanghao Hu,Wei Liu,Yulan He,Zheng Yuan,Lin Gui*

Main category: cs.CL

TL;DR: 本文提出了一种基于频率感知的注意力分析方法来检测大语言模型中的幻觉现象，通过分析注意力分布的高频成分来识别不稳定的注意力模式，从而开发轻量级幻觉检测器。


<details>
  <summary>Details</summary>
Motivation: 在基于上下文的生成任务中，幻觉检测对于确保大语言模型的可靠性至关重要。现有方法通常依赖粗粒度的注意力摘要，无法捕捉注意力中的细粒度不稳定性，需要更精细的分析方法。

Method: 受信号处理启发，引入频率感知的注意力视角，将注意力分布建模为离散信号，提取反映注意力快速局部变化的高频成分。基于高频注意力特征开发轻量级幻觉检测器。

Result: 分析发现幻觉标记与高频注意力能量相关，反映了碎片化和不稳定的基础行为。在RAGTruth和HalluRAG基准测试中，该方法在跨模型和任务上优于基于验证、内部表示和注意力的现有方法。

Conclusion: 频率感知的注意力分析为幻觉检测提供了新的视角，高频注意力特征能够有效识别幻觉现象，所开发的轻量级检测器在多个基准测试中表现出优越性能。

Abstract: Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.

</details>


### [49] [The Statistical Signature of LLMs](https://arxiv.org/abs/2602.18152)
*Ortal Hadad,Edoardo Loru,Jacopo Nudo,Niccolò Di Marco,Matteo Cinelli,Walter Quattrociocchi*

Main category: cs.CL

TL;DR: 论文通过无损压缩分析发现LLM生成文本比人类文本具有更高的结构规律性和可压缩性，这种差异在受控和中介环境中明显，但在小规模碎片化交互环境中减弱。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解大语言模型通过概率采样生成文本时，如何重塑语言的结构统计组织，以及如何从表面文本区分生成机制。

Method: 使用无损压缩作为模型无关的统计规律性度量方法，分析三个渐进复杂的信息生态系统：受控的人-LLM延续、知识基础设施的生成中介（维基百科 vs Grokipedia）、完全合成的社交互动环境（Moltbook vs Reddit）。

Result: 压缩分析揭示了概率生成的结构特征：在受控和中介环境中，LLM生成的语言比人类文本具有更高的结构规律性和可压缩性；但在碎片化交互环境中，这种差异减弱，表明在小尺度上表面可区分性存在基本限制。

Conclusion: 无损压缩提供了一个简单而稳健的框架，用于量化生成系统如何重塑文本生产，为通信的演化复杂性提供了结构视角，这种可压缩性差异在不同模型、任务和领域中一致出现。

Abstract: Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.

</details>


### [50] [FENCE: A Financial and Multimodal Jailbreak Detection Dataset](https://arxiv.org/abs/2602.18154)
*Mirae Kim,Seonghun Jeong,Youngjun Kwak*

Main category: cs.CL

TL;DR: 提出了FENCE数据集，一个用于金融领域多模态越狱检测的双语（韩语-英语）数据集，包含金融相关查询和基于图像的威胁，用于训练和评估越狱检测器。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）和视觉语言模型（VLMs）的越狱攻击构成重大风险，特别是VLMs处理文本和图像，攻击面更广。金融领域缺乏越狱检测资源，需要针对性的数据集来提升检测能力。

Method: 创建FENCE双语多模态数据集，包含金融相关查询和图像基础威胁，强调领域真实性。使用商业和开源VLMs进行实验评估漏洞，并基于FENCE训练基线检测器。

Result: 实验显示VLMs存在一致漏洞：GPT-4o有可测量的攻击成功率，开源模型暴露更大风险。基于FENCE训练的基线检测器在分布内准确率达到99%，在外部基准测试中保持强性能。

Conclusion: FENCE为金融领域多模态越狱检测提供了专注资源，支持敏感领域更安全可靠的AI系统部署。数据集展示了训练可靠检测模型的鲁棒性。

Abstract: Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.

</details>


### [51] [RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425)
*Deniz Qian,Hung-Ting Chen,Eunsol Choi*

Main category: cs.CL

TL;DR: RVR是一个多轮检索框架，通过检索-验证-检索的迭代过程最大化答案覆盖率，在多个数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 针对需要广泛有效答案的查询，现有检索方法难以全面覆盖多样化的文档。需要一种能够最大化答案覆盖率的检索框架。

Method: 提出检索-验证-检索（RVR）框架：第一轮检索器获取候选文档集，验证器识别高质量子集；后续轮次将查询与已验证文档结合，发现之前未覆盖的答案。支持使用现成检索器，也可通过微调进一步优化。

Result: 在QAMPARI多答案检索数据集上，相比基线方法（包括智能搜索方法）获得至少10%相对增益和3%绝对增益的完全召回率提升。在QUEST和WebQuestionsSP两个域外数据集上，不同基础检索器均获得一致增益。

Conclusion: RVR提供了一种有前景的迭代方法，通过验证器和适应新推理场景的检索器，实现了全面的答案召回。该方法即使在现成检索器上也有效，微调后能获得进一步增益。

Abstract: Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

</details>


### [52] [Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models](https://arxiv.org/abs/2602.18171)
*Wojciech Michaluk,Tymoteusz Urban,Mateusz Kubita,Soveatin Kuntur,Anna Wroblewska*

Main category: cs.CL

TL;DR: 本文提出了一种混合方法用于点击诱饵检测，结合了基于Transformer的文本嵌入和语言学驱动的信息性特征，在XGBoost分类器上取得了91%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题降低了在线信息质量并损害用户信任，需要有效的检测方法来应对这一问题。

Method: 采用混合方法，结合Transformer文本嵌入和15个明确的语言学特征（如第二人称代词、最高级、数字、注意力导向标点等），使用XGBoost分类器进行检测。

Result: 最佳模型（XGBoost结合增强特征）达到91%的F1分数，优于TF-IDF、Word2Vec、GloVe、LLM提示分类和仅特征基线。

Conclusion: 提出的特征集通过突出显著的语言学线索增强了可解释性，实现了透明且校准良好的点击诱饵预测，并发布了代码和训练模型以支持可重复研究。

Abstract: Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.

</details>


### [53] [VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429)
*Harshul Raj Surana,Arijit Maji,Aryan Vats,Akash Ghosh,Sriparna Saha,Amit Sheth*

Main category: cs.CL

TL;DR: 本文介绍了VIRAASAT数据集和SCoM框架，用于解决LLMs在印度文化多跳推理任务上的不足。VIRAASAT是一个半自动生成的印度文化多跳问答数据集，包含3200多个问题，覆盖印度所有邦和中央直辖区。SCoM框架通过训练模型内部模拟知识图谱操作，显著提升了文化推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和编程等推理任务上取得了显著进展，但在需要丰富社会文化知识和多样化本地背景的任务上表现不佳，特别是在涉及印度文化的任务中。现有的文化基准测试存在三个主要问题：(1) 手工制作，(2) 只包含测试事实记忆的单跳问题，(3) 扩展成本过高，导致这一缺陷未被充分测量。

Method: 提出了VIRAASAT方法，这是一种半自动化的多跳方法，用于生成印度文化特定的多跳问答数据集。该方法基于包含700多个专家策划的文化文物知识图谱，涵盖印度文化的13个关键属性（历史、节日等）。同时提出了符号操作链（SCoM）框架，通过训练模型内部模拟原子知识图谱操作，使模型能够可靠地遍历图谱的拓扑结构。

Result: VIRAASAT数据集覆盖印度所有28个邦和8个中央直辖区，生成了3200多个需要链式文化推理的多跳问题。实验表明，当前最先进的LLMs在VIRAASAT上表现不佳，特别是思维链微调无法有效处理低概率事实。SCoM框架在监督微调实验中比标准思维链基线提升了高达20%的性能。

Conclusion: VIRAASAT数据集和SCoM框架为构建文化感知推理模型奠定了坚实基础。该方法不仅解决了LLMs在文化推理方面的局限性，还提供了一种可扩展的方法来评估和改进模型在多样化文化背景下的表现。研究释放了VIRAASAT数据集和相关发现，促进了文化感知AI系统的发展。

Abstract: Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

</details>


### [54] [Improving Sampling for Masked Diffusion Models via Information Gain](https://arxiv.org/abs/2602.18176)
*Kaisen Yang,Jayden Teoh,Kaicheng Yang,Yitong Zhang,Alex Lamb*

Main category: cs.CL

TL;DR: 本文提出Info-Gain Sampler解码框架，解决掩码扩散模型中现有贪婪采样器忽视当前解码决策对后续步骤影响的问题，通过平衡即时不确定性和未来掩码位置的信息增益，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型采样器采用贪婪启发式方法，优先解码局部确定性最高的位置，但这种方法存在根本局限性：忽视当前解码选择对后续步骤的下游影响，未能充分利用MDMs的非因果特性来评估解码决策如何重塑所有剩余掩码位置的标记概率/不确定性。

Method: 提出Info-Gain Sampler解码框架，该框架基于信息增益原则，平衡即时不确定性与未来掩码标记的信息增益。通过评估每个解码决策如何影响所有剩余掩码位置的不确定性分布，实现更优的解码顺序规划。

Result: 在多种架构和任务（推理、编码、创意写作、图像生成）上的广泛评估表明，Info-Gain Sampler始终优于现有MDMs采样器。推理任务平均准确率提升3.6%，创意写作胜率达63.1%，推理任务累积不确定性从78.4降至48.6，大幅超越最佳基线方法。

Conclusion: Info-Gain Sampler为掩码扩散模型提供了一个原则性的解码框架，通过考虑当前决策对未来的信息增益影响，解决了现有贪婪方法的局限性，在多个领域实现了显著的性能提升。

Abstract: Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.

</details>


### [55] [Information-Theoretic Storage Cost in Sentence Comprehension](https://arxiv.org/abs/2602.18217)
*Kohei Kajikawa,Shinnosuke Isono,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 该研究提出了一种基于信息论的句子理解处理存储成本度量方法，使用预训练神经语言模型估计先前词汇对未来上下文的信息承载量，验证了该方法在英语中的有效性。


<details>
  <summary>Details</summary>
Motivation: 实时句子理解对工作记忆造成显著负荷，但现有基于符号语法的处理负荷度量方法采用离散、统一的句法预测成本，缺乏连续性和理论中立性。

Method: 提出基于信息论的处理存储成本度量，定义为先前词汇在不确定性条件下对未来上下文的信息承载量，使用预训练神经语言模型进行估计。

Result: 在英语中的三项分析表明：1）恢复了中心嵌入和关系从句中已知的处理不对称性；2）与语法标注语料库中的语法基础存储成本相关；3）在两个大规模自然数据集上预测阅读时间方差，优于传统信息基础预测器的基线模型。

Conclusion: 基于信息论的连续、理论中立的处理存储成本度量方法有效，能够捕捉句子理解中的工作记忆负荷，为心理语言学理论提供了新的量化工具。

Abstract: Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.

</details>


### [56] [Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning](https://arxiv.org/abs/2602.18232)
*Lexiang Tang,Weihao Gao,Bingchen Zhao,Lu Ma,Qiao jin,Bang Yang,Yuexian Zou*

Main category: cs.CL

TL;DR: 提出Confidence-Driven Contrastive Decoding方法，通过检测解码过程中的低置信度token并进行针对性干预，提高大语言模型推理可靠性，同时减少输出长度。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设增加推理时计算能均匀提高正确性，但研究发现推理不确定性高度局部化：少数低置信度token对推理错误和不必要的输出扩展有不成比例的影响。

Method: 提出Thinking by Subtraction方法，采用置信度驱动的对比解码。检测解码过程中的低置信度token，在这些位置进行选择性干预。通过用最小占位符替换高置信度token构建对比参考，在低置信度位置通过减去参考分布来优化预测。

Result: CCD方法在数学推理基准测试中显著提高准确性，同时大幅减少输出长度，KV缓存开销最小。作为无需训练的方法，通过针对性低置信度干预提高推理可靠性，避免计算冗余。

Conclusion: 置信度驱动的对比解码通过针对低置信度token的干预，有效提高大语言模型推理的可靠性，同时减少不必要的输出扩展，为推理优化提供了新思路。

Abstract: Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.

</details>


### [57] [PsihoRo: Depression and Anxiety Romanian Text Corpus](https://arxiv.org/abs/2602.18324)
*Alexandra Ciobotaru,Ana-Maria Bucur,Liviu P. Dinu*

Main category: cs.CL

TL;DR: 创建了首个罗马尼亚语抑郁和焦虑心理语料库PsihoRo，填补了该语言在心理健康NLP资源方面的空白


<details>
  <summary>Details</summary>
Motivation: 罗马尼亚语目前没有开源的心理健康语料库，而心理健康数据从社交媒体收集存在假设偏差问题，需要更实用的数据收集方法

Method: 使用包含6个开放式问题的表格收集数据，配合标准化的PHQ-9和GAD-7筛查问卷，共收集205名受访者的文本数据

Result: 创建了首个罗马尼亚语抑郁和焦虑心理语料库PsihoRo，并运用统计分析、罗马尼亚语LIWC文本分析、情感检测和主题建模等方法分析其特征

Conclusion: PsihoRo是理解和分析罗马尼亚人口心理健康文本的第一步，为NLP社区提供了重要的新资源

Abstract: Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

</details>


### [58] [Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System](https://arxiv.org/abs/2602.18346)
*Pavithra PM Nair,Preethu Rose Anish*

Main category: cs.CL

TL;DR: Vichara是一个针对印度司法系统的AI框架，用于预测和解释上诉判决，通过结构化处理案件文档并采用IRAC框架，在多个数据集上超越了现有基准。


<details>
  <summary>Details</summary>
Motivation: 印度法院面临大量案件积压，特别是上诉案件，需要AI技术来帮助预测判决并提高司法效率。

Method: Vichara框架处理英文上诉案件文件，将其分解为决策点（包含法律问题、裁决机构、结果、推理和时间背景的结构化表示），并采用基于IRAC框架的印度法律推理格式生成解释。

Result: 在PredEx和ILDC_expert数据集上，Vichara超越了现有判决预测基准，GPT-4o mini表现最佳（F1：PredEx 81.5，ILDC_expert 80.3），Llama-3.1-8B次之。人类评估显示GPT-4o mini的解释在清晰度、关联性和实用性方面表现最优。

Conclusion: Vichara框架为印度司法系统提供了有效的判决预测和解释能力，有助于缓解案件积压问题，提高法律专业人士的工作效率。

Abstract: In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.

</details>


### [59] [Validating Political Position Predictions of Arguments](https://arxiv.org/abs/2602.18351)
*Jordan Robinson,Angus R. Williams,Katie Atkinson,Anthony G. Cohn*

Main category: cs.CL

TL;DR: 该论文提出了一种双尺度验证框架，结合点对点和成对人工标注，用于政治立场预测的主观连续知识表示，构建了一个大规模政治立场知识库。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识表示常需要捕捉主观连续属性（如政治立场），这与广泛接受的成对验证黄金标准存在冲突。需要解决主观连续知识的验证挑战。

Method: 采用双尺度验证框架，结合点对点和成对人工标注。使用22个语言模型，基于英国政治电视节目《Question Time》的30场辩论中的23,228个论点，构建政治立场预测知识库。

Result: 点对点评估显示中等水平的人机一致性（Krippendorff's α=0.578），反映内在主观性；而成对验证显示人机排名对齐更强（最佳模型α=0.86）。

Conclusion: 贡献包括：实用的主观连续知识验证方法；经过验证的结构化论证知识库；证明可以从点对点语言模型预测中提取序数结构，推进传统符号或分类方法不足领域的知识表示能力。

Abstract: Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [60] [Reducing Text Bias in Synthetically Generated MCQAs for VLMs in Autonomous Driving](https://arxiv.org/abs/2602.17677)
*Sutej Kulgod,Sean Ye,Sanchit Tanwar,Christoffer Heckman*

Main category: cs.LG

TL;DR: 该研究发现多选问答基准存在文本线索漏洞，导致视觉语言模型无需视觉输入即可获得高准确率。作者提出方法消除文本捷径，强制模型依赖视觉理解。


<details>
  <summary>Details</summary>
Motivation: 现有MCQA基准存在隐藏文本线索问题，模型可通过语言模式而非视觉上下文获得高分，无法真实反映视觉理解能力。

Method: 通过将正确答案与语言伪影解耦，并采用课程学习策略，消除可被利用的文本捷径，强制模型依赖视觉基础。

Result: 方法将盲目准确率从随机基准上+66.9%降至+2.9%，消除了绝大多数可被利用的文本捷径，确保性能准确反映感知理解。

Conclusion: 需要消除MCQA基准中的文本线索漏洞，强制模型依赖视觉基础，才能准确评估视觉语言模型在驾驶任务中的真实视觉理解能力。

Abstract: Multiple Choice Question Answering (MCQA) benchmarks are an established standard for measuring Vision Language Model (VLM) performance in driving tasks. However, we observe the known phenomenon that synthetically generated MCQAs are highly susceptible to hidden textual cues that allow models to exploit linguistic patterns rather than visual context. Our results show that a VLM fine-tuned on such data can achieve accuracy comparable to human-validated benchmarks even without visual input. Our proposed method reduces blind accuracy from +66.9% above random to +2.9%, eliminating the vast majority of exploitable textual shortcuts. By decoupling the correct answer from linguistic artifacts and employing a curriculum learning strategy, we force the model to rely on visual grounding, ensuring that performance accurately reflects perceptual understanding.

</details>


### [61] [BioBridge: Bridging Proteins and Language for Enhanced Biological Reasoning with LLMs](https://arxiv.org/abs/2602.17680)
*Yujia Wang,Jihong Guan,Wengen Li,Shuigeng Zhou,Xuhong Wang*

Main category: cs.LG

TL;DR: BioBridge是一个蛋白质理解框架，通过领域增量持续预训练将蛋白质领域知识和通用推理能力结合到LLM中，实现跨模态对齐和端到端优化，在蛋白质基准测试和通用理解任务上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质语言模型（PLMs）对多任务适应性有限，在不同生物背景下泛化能力差；而通用大语言模型（LLMs）缺乏解释蛋白质序列的能力，在领域特定知识上不足，限制了生物语义推理能力。需要结合两者的优势。

Method: 提出BioBridge框架：1）采用领域增量持续预训练（DICP）同时注入蛋白质领域知识和通用推理语料；2）通过PLM-Projector-LLM管道实现跨模态对齐，将蛋白质序列嵌入映射到语言模型的语义空间；3）采用端到端优化统一支持蛋白质属性预测和知识问答等多种任务。

Result: BioBridge在EC和BindingDB等多个蛋白质基准测试上表现与主流PLMs相当；在MMLU和RACE等通用理解任务上达到与LLMs相当的结果，展示了其结合领域特定适应性和通用语言能力的创新优势。

Conclusion: BioBridge成功地将蛋白质领域知识与通用语言能力相结合，通过创新的持续预训练框架和跨模态对齐方法，实现了在蛋白质理解和通用语言任务上的双重优势，为生物信息学领域提供了有效的多任务解决方案。

Abstract: Existing Protein Language Models (PLMs) often suffer from limited adaptability to multiple tasks and exhibit poor generalization across diverse biological contexts. In contrast, general-purpose Large Language Models (LLMs) lack the capability to interpret protein sequences and fall short in domain-specific knowledge, limiting their capacity for effective biosemantic reasoning. To combine the advantages of both, we propose BioBridge, a domain-adaptive continual pretraining framework for protein understanding. This framework employs Domain-Incremental Continual Pre-training (DICP) to infuse protein domain knowledge and general reasoning corpus into a LLM simultaneously, effectively mitigating catastrophic forgetting. Cross-modal alignment is achieved via a PLM-Projector-LLM pipeline, which maps protein sequence embeddings into the semantic space of the language model. Ultimately, an end-to-end optimization is adopted to uniformly support various tasks, including protein property prediction and knowledge question-answering. Our proposed BioBridge demonstrates performance comparable to that of mainstream PLMs on multiple protein benchmarks, such as EC and BindingDB. It also achieves results on par with LLMs on general understanding tasks like MMLU and RACE. This showcases its innovative advantage of combining domain-specific adaptability with general-purpose language competency.

</details>


### [62] [LATMiX: Learnable Affine Transformations for Microscaling Quantization of LLMs](https://arxiv.org/abs/2602.17681)
*Ofir Gordon,Lior Dikstein,Arnon Netzer,Idan Achituve,Hai Victor Habi*

Main category: cs.LG

TL;DR: 本文提出LATMiX方法，通过可学习的可逆仿射变换优化MX格式的低比特量化，在多个模型尺寸上显著提升量化精度。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法主要关注传统量化方案，而现代硬件日益支持微缩放(MX)数据格式。将可逆变换与MX量化结合时会出现严重性能下降，现有方法对变换施加了过多限制性假设。

Method: 首先对MX量化下的变换进行理论分析，推导量化误差边界；然后提出LATMiX方法，将异常值减少推广到可学习的可逆仿射变换，使用标准深度学习工具进行优化。

Result: 实验表明，在广泛的零样本基准测试中，LATMiX在MX低比特量化上相比强基线方法实现了平均准确率的持续提升，且适用于多种模型尺寸。

Conclusion: 通过理论分析和实验验证，LATMiX方法成功地将可逆变换与MX量化格式结合，为大规模语言模型的高效部署提供了有效的量化解决方案。

Abstract: Post-training quantization (PTQ) is a widely used approach for reducing the memory and compute costs of large language models (LLMs). Recent studies have shown that applying invertible transformations to activations can significantly improve quantization robustness by reducing activation outliers; however, existing approaches are largely restricted to rotation or Hadamard-based transformations. Moreover, most studies focused primarily on traditional quantization schemes, whereas modern hardware increasingly supports the microscaling (MX) data format. Attempts to combine both showed severe performance degradation, leading prior work to introduce assumptions on the transformations. In this work, we take a complementary perspective. First, we provide a theoretical analysis of transformations under MX quantization by deriving a bound on the quantization error. Our analysis emphasizes the importance of accounting for both the activation distribution and the underlying quantization structure. Building on this analysis, we propose LATMiX, a method that generalizes outlier reduction to learnable invertible affine transformations optimized using standard deep learning tools. Experiments show consistent improvements in average accuracy for MX low-bit quantization over strong baselines on a wide range of zero-shot benchmarks, across multiple model sizes.

</details>


### [63] [Probabilistic NDVI Forecasting from Sparse Satellite Time Series and Weather Covariates](https://arxiv.org/abs/2602.17683)
*Irene Iele,Giulia Romoli,Daniele Molino,Elena Mulero Ayllón,Filippo Ruffini,Paolo Soda,Matteo Tortora*

Main category: cs.LG

TL;DR: 提出一个用于农田NDVI预测的概率性预测框架，通过Transformer架构分离历史植被动态和未来外生信息建模，引入时间距离加权分位数损失处理不规则采样，在卫星数据实验中优于多种基线方法。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要准确的植被动态短期预测，但卫星NDVI预测面临云覆盖导致的不规则稀疏采样以及作物生长的异质性气候条件等挑战。

Method: 提出概率预测框架，采用Transformer架构明确分离历史植被动态和未来外生信息建模，整合历史NDVI观测与历史及未来气象协变量。引入时间距离加权分位数损失处理不规则重访模式，加入累积和极端天气特征工程捕捉延迟气象效应。

Result: 在欧洲卫星数据上的广泛实验表明，该方法在点预测和概率评估指标上均优于多种统计、深度学习和近期时间序列基线方法。消融研究显示目标历史起核心作用，而气象协变量在联合利用时提供补充增益。

Conclusion: 提出的框架能够有效处理晴空采集约束下的农田NDVI预测问题，通过分离历史植被动态和未来外生信息建模，结合时间距离加权损失和气象特征工程，实现了优于现有方法的预测性能。

Abstract: Accurate short-term forecasting of vegetation dynamics is a key enabler for data-driven decision support in precision agriculture. Normalized Difference Vegetation Index (NDVI) forecasting from satellite observations, however, remains challenging due to sparse and irregular sampling caused by cloud coverage, as well as the heterogeneous climatic conditions under which crops evolve. In this work, we propose a probabilistic forecasting framework specifically designed for field-level NDVI prediction under clear-sky acquisition constraints. The method leverages a transformer-based architecture that explicitly separates the modeling of historical vegetation dynamics from future exogenous information, integrating historical NDVI observations with both historical and future meteorological covariates. To address irregular revisit patterns and horizon-dependent uncertainty, we introduce a temporal-distance weighted quantile loss that aligns the training objective with the effective forecasting horizon. In addition, we incorporate cumulative and extreme-weather feature engineering to better capture delayed meteorological effects relevant to vegetation response. Extensive experiments on European satellite data demonstrate that the proposed approach consistently outperforms a diverse set of statistical, deep learning, and recent time series baselines across both point-wise and probabilistic evaluation metrics. Ablation studies further highlight the central role of target history, while showing that meteorological covariates provide complementary gains when jointly exploited. The code is available at https://github.com/arco-group/ndvi-forecasting.

</details>


### [64] [CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models](https://arxiv.org/abs/2602.17684)
*Xiao Zhu,Xinyu Zhou,Boyu Zhu,Hanxu Hu,Mingzhe Du,Haotian Zhang,Huiming Wang,Zhijiang Guo*

Main category: cs.LG

TL;DR: CodeScaler是一种无需执行的奖励模型，通过精心设计的偏好数据和语法感知代码提取，在代码生成任务中超越了基于单元测试的强化学习方法，实现了更高效的训练和推理。


<details>
  <summary>Details</summary>
Motivation: 当前基于可验证奖励的强化学习方法（RLVR）依赖于单元测试的执行反馈，但其可扩展性受到高质量测试用例可用性和可靠性的限制。需要一种无需执行的方法来扩展代码生成的强化学习训练和推理。

Method: 提出CodeScaler，一个无需执行的奖励模型。使用从已验证代码问题中精心策划的偏好数据进行训练，结合语法感知的代码提取和保持有效性的奖励塑造技术，确保稳定和鲁棒的优化。

Result: 在五个编码基准测试中，CodeScaler将Qwen3-8B-Base平均提升11.72分，比基于执行的强化学习方法高出1.82分。能够在没有测试用例的合成数据集上进行可扩展的强化学习。推理时延迟降低10倍，性能与单元测试方法相当。在RM-Bench上，不仅在代码领域超越现有奖励模型3.3分，在通用和推理领域也平均提升2.7分。

Conclusion: CodeScaler提供了一种有效的无需执行奖励模型，克服了传统基于测试的强化学习方法的可扩展性限制，在代码生成任务中实现了更好的性能和效率，同时展示了跨领域的泛化能力。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has driven recent progress in code large language models by leveraging execution-based feedback from unit tests, but its scalability is fundamentally constrained by the availability and reliability of high-quality test cases. We propose CodeScaler, an execution-free reward model designed to scale both reinforcement learning training and test-time inference for code generation. CodeScaler is trained on carefully curated preference data derived from verified code problems and incorporates syntax-aware code extraction and validity-preserving reward shaping to ensure stable and robust optimization. Across five coding benchmarks, CodeScaler improves Qwen3-8B-Base by an average of +11.72 points, outperforming binary execution-based RL by +1.82 points, and enables scalable reinforcement learning on synthetic datasets without any test cases. At inference time, CodeScaler serves as an effective test-time scaling method, achieving performance comparable to unit test approaches while providing a 10-fold reduction in latency. Moreover, CodeScaler surpasses existing reward models on RM-Bench not only in the code domain (+3.3 points), but also in general and reasoning domains (+2.7 points on average).

</details>


### [65] [Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling](https://arxiv.org/abs/2602.17685)
*Agni Bandyopadhyay,Gunther Waxenegger-Wilfing*

Main category: cs.LG

TL;DR: 该论文提出了一种用于低地球轨道多目标主动碎片清除的统一共椭圆机动框架，比较了三种规划算法（贪婪启发式、蒙特卡洛树搜索和深度强化学习），实验表明Masked PPO在任务效率和计算性能上表现最优。


<details>
  <summary>Details</summary>
Motivation: 解决低地球轨道多目标主动碎片清除的挑战，需要高效、可扩展且资源优化的任务规划方法，以应对随机碎片场、禁飞区和燃料约束等现实约束条件。

Method: 提出统一的共椭圆机动框架，结合霍曼转移、安全椭圆接近操作和显式加油逻辑。在包含随机碎片场、禁飞区和ΔV约束的逼真轨道模拟环境中，对三种规划算法进行基准测试：贪婪启发式、蒙特卡洛树搜索和基于Masked PPO的深度强化学习。

Result: 在100个测试场景中，Masked PPO实现了最优的任务效率和计算性能，访问的碎片数量可达贪婪算法的两倍，并在运行时间上显著优于蒙特卡洛树搜索。

Conclusion: 现代强化学习方法在可扩展、安全和资源高效的空间任务规划方面具有巨大潜力，为未来主动碎片清除自主性的发展铺平了道路。

Abstract: This paper addresses the challenge of multi target active debris removal (ADR) in Low Earth Orbit (LEO) by introducing a unified coelliptic maneuver framework that combines Hohmann transfers, safety ellipse proximity operations, and explicit refueling logic. We benchmark three distinct planning algorithms Greedy heuristic, Monte Carlo Tree Search (MCTS), and deep reinforcement learning (RL) using Masked Proximal Policy Optimization (PPO) within a realistic orbital simulation environment featuring randomized debris fields, keep out zones, and delta V constraints. Experimental results over 100 test scenarios demonstrate that Masked PPO achieves superior mission efficiency and computational performance, visiting up to twice as many debris as Greedy and significantly outperforming MCTS in runtime. These findings underscore the promise of modern RL methods for scalable, safe, and resource efficient space mission planning, paving the way for future advancements in ADR autonomy.

</details>


### [66] [EXACT: Explicit Attribute-Guided Decoding-Time Personalization](https://arxiv.org/abs/2602.17695)
*Xin Yu,Hanwen Xing,Lingzhou Xue*

Main category: cs.LG

TL;DR: EXACT是一种新的解码时个性化方法，通过可解释属性对齐生成与有限成对偏好反馈，解决了现有方法无法处理跨提示偏好变化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有解码时个性化方法主要依赖隐式、难以解释的偏好表示，并采用僵化的、上下文无关的用户表示，无法捕捉偏好如何随提示变化而转移。

Method: EXACT使用预定义的可解释属性集，首先在离线阶段通过最大化偏好响应似然识别用户特定属性子集，然后在在线推理时检索与输入提示最语义相关的属性并注入上下文以引导生成。

Result: 在温和假设下建立了理论近似保证，证明相似性检索机制能有效缓解上下文偏好转移，适应不同任务而无需聚合冲突偏好。在人工标注偏好数据集上的实验显示，EXACT在偏好建模准确性和个性化生成质量方面持续优于强基线。

Conclusion: EXACT提供了一种可扩展、可解释的解码时个性化方法，能有效处理跨提示的偏好变化，通过理论保证和实证验证展示了其优越性。

Abstract: Achieving personalized alignment requires adapting large language models to each user's evolving context. While decoding-time personalization offers a scalable alternative to training-time methods, existing methods largely rely on implicit, less interpretable preference representations and impose a rigid, context-agnostic user representation, failing to account for how preferences shift across prompts. We introduce EXACT, a new decoding-time personalization that aligns generation with limited pairwise preference feedback using a predefined set of interpretable attributes. EXACT first identifies user-specific attribute subsets by maximizing the likelihood of preferred responses in the offline stage. Then, for online inference, EXACT retrieves the most semantically relevant attributes for an incoming prompt and injects them into the context to steer generation. We establish theoretical approximation guarantees for the proposed algorithm under mild assumptions, and provably show that our similarity-based retrieval mechanism effectively mitigates contextual preference shifts, adapting to disparate tasks without pooling conflicting preferences. Extensive experiments on human-annotated preference datasets demonstrate that EXACT consistently outperforms strong baselines, including preference modeling accuracy and personalized generation quality.

</details>


### [67] [AnCoder: Anchored Code Generation via Discrete Diffusion Models](https://arxiv.org/abs/2602.17688)
*Anton Xue,Litu Rout,Constantine Caramanis,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: AnchorTree框架通过抽象语法树引导扩散过程，优先解决语法和语义关键标记，提高代码生成质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型在代码生成中经常产生无法执行的程序，因为它们没有尊重编程语言的刚性结构

Method: 引入AnchorTree框架，使用抽象语法树作为结构化先验，优先解析语法和语义关键标记（如关键字、标识符），建立结构支架指导后续生成

Result: 通过AnCoder模型验证，结构锚定的扩散方法为高质量代码生成提供了参数高效的路径

Conclusion: 结构化锚定扩散方法能够有效提升代码生成质量，解决现有扩散模型在编程语言结构处理上的不足

Abstract: Diffusion language models offer a compelling alternative to autoregressive code generation, enabling global planning and iterative refinement of complex program logic. However, existing approaches fail to respect the rigid structure of programming languages and, as a result, often produce broken programs that fail to execute. To address this, we introduce AnchorTree, a framework that explicitly anchors the diffusion process using structured, hierarchical priors native to code. Specifically, AnchorTree uses the abstract syntax tree to prioritize resolving syntactically and semantically salient tokens, such as keywords (e.g., if, while) and identifiers (e.g., variable names), thereby establishing a structural scaffold that guides the remaining generation. We validate this framework via AnCoder, a family of models showing that structurally anchored diffusion offers a parameter-efficient path to high-quality code generation.

</details>


### [68] [Robust Pre-Training of Medical Vision-and-Language Models with Domain-Invariant Multi-Modal Masked Reconstruction](https://arxiv.org/abs/2602.17689)
*Melika Filvantorkaman,Mohsen Piri*

Main category: cs.LG

TL;DR: 提出Robust-MMR框架，通过自监督预训练增强医学视觉语言模型在领域偏移下的鲁棒性，在多个医学VQA和分类任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型在实际部署中面临成像设备、采集协议和报告风格差异导致的领域偏移问题，现有多模态预训练方法大多忽视鲁棒性，将其视为下游适应问题。

Method: 提出Robust-MMR自监督预训练框架，整合非对称扰动感知掩码、领域一致性正则化和模态弹性约束，鼓励学习领域不变表示。

Result: 在VQA-RAD上达到78.9%跨域准确率（比最强基线高3.8%），SLAKE和VQA-2019分别达到74.6%和77.0%；扰动评估下VQA-RAD准确率从69.1%提升至75.6%；MELINDA跨域准确率从70.3%提升至75.2%；检索任务中平均排名退化从16+降至4.1。

Conclusion: 在预训练阶段显式建模鲁棒性能产生更可靠、可迁移的医学视觉语言表示，适用于真实世界部署。

Abstract: Medical vision-language models show strong potential for joint reasoning over medical images and clinical text, but their performance often degrades under domain shift caused by variations in imaging devices, acquisition protocols, and reporting styles. Existing multi-modal pre-training methods largely overlook robustness, treating it as a downstream adaptation problem. In this work, we propose Robust Multi-Modal Masked Reconstruction (Robust-MMR), a self-supervised pre-training framework that explicitly incorporates robustness objectives into masked vision-language learning. Robust-MMR integrates asymmetric perturbation-aware masking, domain-consistency regularization, and modality-resilience constraints to encourage domain-invariant representations. We evaluate Robust-MMR on multiple medical vision-language benchmarks, including medical visual question answering (VQA-RAD, SLAKE, VQA-2019), cross-domain image-text classification (MELINDA), and robust image-caption retrieval (ROCO). Robust-MMR achieves 78.9% cross-domain accuracy on VQA-RAD, outperforming the strongest baseline by 3.8 percentage points, and reaches 74.6% and 77.0% accuracy on SLAKE and VQA-2019, respectively. Under perturbed evaluation, Robust-MMR improves VQA-RAD accuracy from 69.1% to 75.6%. For image-text classification, cross-domain MELINDA accuracy increases from 70.3% to 75.2%, while retrieval experiments show a reduction in mean rank degradation from over 16 to 4.1 under perturbation. Qualitative results further demonstrate improved clinical reasoning for disease detection and structural abnormality assessment. These findings show that explicitly modeling robustness during pre-training leads to more reliable and transferable medical vision-language representations for real-world deployment.

</details>


### [69] [Agentic Unlearning: When LLM Agent Meets Machine Unlearning](https://arxiv.org/abs/2602.17692)
*Bin Wang,Fan Wang,Pingping Wang,Jinyu Cong,Yang Yu,Yilong Yin,Zhongyi Han,Benzheng Wei*

Main category: cs.LG

TL;DR: 本文提出"agentic unlearning"方法，通过同步参数和记忆双路径的遗忘机制，解决传统遗忘方法中参数-记忆回流的再污染问题。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法仅针对模型参数，存在两个关键缺陷：1) 参数-记忆回流问题，检索会重新激活参数残留或记忆伪影重新引入敏感内容；2) 缺乏同时覆盖参数和记忆路径的统一策略。

Method: 提出同步回流遗忘(SBU)框架，包含记忆路径和参数路径的双重遗忘机制。记忆路径采用依赖闭包遗忘，修剪孤立实体并使共享伪影逻辑失效；参数路径使用随机参考对齐，将模型输出导向高熵先验。通过同步双更新协议集成两个路径，形成闭环机制。

Result: 在医疗QA基准测试中，SBU显著减少了目标隐私信息在两个路径上的痕迹，同时对保留数据的性能影响有限。

Conclusion: SBU通过同步参数和记忆路径的遗忘机制，有效解决了传统遗忘方法中的再污染问题，为具有闭环交互的智能体提供了更全面的信息遗忘方案。

Abstract: In this paper, we introduce \textbf{agentic unlearning} which removes specified information from both model parameters and persistent memory in agents with closed-loop interaction. Existing unlearning methods target parameters alone, leaving two critical gaps: (i) parameter-memory backflow, where retrieval reactivates parametric remnants or memory artifacts reintroduce sensitive content, and (ii) the absence of a unified strategy that covers both parameter and memory pathways. We present Synchronized Backflow Unlearning (SBU), a framework that unlearns jointly across parameter and memory pathways. The memory pathway performs dependency closure-based unlearning that prunes isolated entities while logically invalidating shared artifacts. The parameter pathway employs stochastic reference alignment to guide model outputs toward a high-entropy prior. These pathways are integrated via a synchronized dual-update protocol, forming a closed-loop mechanism where memory unlearning and parametric suppression reinforce each other to prevent cross-pathway recontamination. Experiments on medical QA benchmarks show that SBU reduces traces of targeted private information across both pathways with limited degradation on retained data.

</details>


### [70] [A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU](https://arxiv.org/abs/2602.17693)
*Yuchen Luo,Fangyue Zhu,Ruining Zhou,Mingzhe Huang,Jian Zhu,Fanyu Fan,Wei Shao*

Main category: cs.LG

TL;DR: 本文研究了在昇腾NPU上对推理导向模型进行训练后量化的可行性和局限性，发现4位权重量化对大型模型可行，但4位权重-激活量化在长上下文推理中不稳定，而8位量化保持数值稳定。


<details>
  <summary>Details</summary>
Motivation: 训练后量化（PTQ）对高效模型部署至关重要，但其在昇腾NPU上的效果相比GPU架构研究不足。本文旨在探索在昇腾NPU上部署量化推理模型的可行性和局限性。

Method: 对DeepSeek-R1-Distill-Qwen系列（1.5B/7B/14B）和QwQ-32B等推理导向模型进行案例研究，评估了四种不同的量化算法：AWQ、GPTQ、SmoothQuant和FlatQuant，涵盖了从仅权重压缩到基于旋转的高级方法。

Result: 4位仅权重量化对大型模型可行，但激进的4位权重-激活量化方案在NPU上存在逐层校准不稳定性，导致长上下文推理任务中的逻辑崩溃。标准8位量化保持数值稳定。INT8实际部署显示，虽然优化内核减少了延迟，但动态量化开销目前限制了端到端加速。

Conclusion: 研究结果为在昇腾NPU上部署量化推理模型的可行性和局限性提供了实用参考，指出了当前量化技术在NPU平台上的敏感性和限制。

Abstract: Post-Training Quantization (PTQ) is crucial for efficient model deployment, yet its effectiveness on Ascend NPU remains under-explored compared to GPU architectures. This paper presents a case study of representative PTQ baselines applied to reasoning-oriented models such as DeepSeek-R1-Distill-Qwen series (1.5B/7B/14B) and QwQ-32B. We evaluate four distinct algorithms, including AWQ, GPTQ, SmoothQuant, and FlatQuant, to cover the spectrum from weight-only compression to advanced rotation-based methods. Our empirical results reveal significant platform sensitivity. While 4-bit weight-only quantization proves viable for larger models, aggressive 4-bit weight-activation schemes suffer from layer-wise calibration instability on the NPU, leading to logic collapse in long-context reasoning tasks. Conversely, standard 8-bit quantization remains numerically stable. Furthermore, a real-world INT8 deployment demonstrates that although optimized kernels reduce latency, dynamic quantization overheads currently limit end-to-end acceleration. These findings offer a practical reference for the feasibility and limitations of deploying quantized reasoning models on Ascend NPU.

</details>


### [71] [Can LLM Safety Be Ensured by Constraining Parameter Regions?](https://arxiv.org/abs/2602.17696)
*Zongmin Li,Jian Su,Farah Benamara,Aixin Sun*

Main category: cs.LG

TL;DR: 当前大语言模型安全区域识别方法在不同数据集和模型上表现不稳定，重叠度低，无法可靠识别出稳定、与数据集无关的安全区域


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常被认为包含"安全区域"——参数子集，其修改直接影响安全行为。本研究旨在系统评估现有安全区域识别方法的可靠性和稳定性

Method: 系统评估了四种不同参数粒度（从单个权重到整个Transformer层）的安全区域识别方法，覆盖四个不同规模的LLM家族，使用十个安全识别数据集

Result: 识别出的安全区域仅表现出低到中等的重叠度（IoU测量），当使用效用数据集（即非有害查询）进一步精炼时，重叠度显著下降

Conclusion: 当前技术无法可靠地识别出稳定、与数据集无关的安全区域，表明现有安全区域识别方法存在局限性

Abstract: Large language models (LLMs) are often assumed to contain ``safety regions'' -- parameter subsets whose modification directly influences safety behaviors. We conduct a systematic evaluation of four safety region identification methods spanning different parameter granularities, from individual weights to entire Transformer layers, across four families of backbone LLMs with varying sizes. Using ten safety identification datasets, we find that the identified safety regions exhibit only low to moderate overlap, as measured by IoU. The overlap drops significantly when the safety regions are further refined using utility datasets (\ie non-harmful queries). These results suggest that current techniques fail to reliably identify a stable, dataset-agnostic safety region.

</details>


### [72] [Pimp My LLM: Leveraging Variability Modeling to Tune Inference Hyperparameters](https://arxiv.org/abs/2602.17697)
*Nada Zine,Clément Quinton,Romain Rouvoy*

Main category: cs.LG

TL;DR: 该论文提出将大语言模型视为可配置系统，应用可变性管理技术来系统分析推理时配置选择，以优化能耗和可持续性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的计算需求巨大，特别是推理阶段占主导地位，需要优化能耗和可持续性。现有研究探索了优化技术，但由于配置空间巨大，无法进行穷尽的经验评估。

Method: 将LLMs视为可配置系统，应用可变性管理技术：1) 使用基于特征的变异性模型表示生成超参数及其约束；2) 采样代表性配置；3) 测量能耗、延迟和准确性；4) 从收集的数据中学习预测模型。

Result: 变异性建模有效管理了LLM推理配置的复杂性，能够系统分析超参数效应和交互作用，揭示权衡关系，并支持从有限测量中准确预测推理行为。

Conclusion: 这项工作通过利用变异性建模实现LLMs的高效可持续配置，开辟了连接软件工程和机器学习的新研究方向。

Abstract: Large Language Models (LLMs) are being increasingly used across a wide range of tasks. However, their substantial computational demands raise concerns about the energy efficiency and sustainability of both training and inference. Inference, in particular, dominates total compute usage, making its optimization crucial. Recent research has explored optimization techniques and analyzed how configuration choices influence energy consumption. Yet, the vast configuration space of inference servers makes exhaustive empirical evaluation infeasible due to combinatorial explosion. In this paper, we introduce a new perspective on this problem by treating LLMs as configurable systems and applying variability management techniques to systematically analyze inference-time configuration choices. We evaluate our approach on the Hugging Face Transformers library by representing generation hyperparameters and their constraints using a feature-based variability model, sampling representative configurations, measuring their energy consumption, latency, accuracy, and learning predictive models from the collected data. Our results show that variability modeling effectively manages the complexity of LLM inference configurations. It enables systematic analysis of hyperparameters effects and interactions, reveals trade-offs, and supports accurate prediction of inference behavior from a limited number of measurements. Overall, this work opens a new research direction that bridges software engineering and machine learning by leveraging variability modeling for the efficient and sustainable configuration of LLMs.

</details>


### [73] [ScaleBITS: Scalable Bitwidth Search for Hardware-Aligned Mixed-Precision LLMs](https://arxiv.org/abs/2602.17698)
*Xinlin Li,Timothy Chou,Josh Fromm,Zichang Liu,Yunjie Pan,Christina Fragouli*

Main category: cs.LG

TL;DR: ScaleBITS是一个混合精度量化框架，能够在内存预算下实现自动化的细粒度比特宽度分配，同时保持硬件效率，显著提升超低比特量化性能。


<details>
  <summary>Details</summary>
Motivation: 后训练权重量化对于减少大型语言模型的内存和推理成本至关重要，但将平均精度推到4比特以下仍然具有挑战性，主要因为权重敏感度高度不均匀且缺乏原则性的精度分配方法。现有解决方案要么使用不规则细粒度混合精度导致高运行时开销，要么依赖启发式或高度受限的精度分配策略。

Method: 提出ScaleBITS混合精度量化框架，包含：1）基于新敏感度分析的指导；2）引入硬件对齐的块级权重分区方案，采用双向通道重排序技术；3）将全局比特宽度分配建模为约束优化问题，并开发可扩展的贪心算法近似方法，实现端到端原则性分配。

Result: 实验表明，ScaleBITS显著优于均匀精度量化（提升高达36%），在超低比特量化中优于最先进的敏感度感知基线方法（提升高达13%），且不增加运行时开销。

Conclusion: ScaleBITS框架成功解决了超低比特量化中的精度分配问题，通过硬件高效的混合精度量化实现了更好的性能，为大型语言模型的高效部署提供了有效解决方案。

Abstract: Post-training weight quantization is crucial for reducing the memory and inference cost of large language models (LLMs), yet pushing the average precision below 4 bits remains challenging due to highly non-uniform weight sensitivity and the lack of principled precision allocation. Existing solutions use irregular fine-grained mixed-precision with high runtime overhead or rely on heuristics or highly constrained precision allocation strategies. In this work, we propose ScaleBITS, a mixed-precision quantization framework that enables automated, fine-grained bitwidth allocation under a memory budget while preserving hardware efficiency. Guided by a new sensitivity analysis, we introduce a hardware-aligned, block-wise weight partitioning scheme, powered by bi-directional channel reordering. We formulate global bitwidth allocation as a constrained optimization problem and develop a scalable approximation to the greedy algorithm, enabling end-to-end principled allocation. Experiments show that ScaleBITS significantly improves over uniform-precision quantization (up to +36%) and outperforms state-of-the-art sensitivity-aware baselines (up to +13%) in ultra-low-bit regime, without adding runtime overhead.

</details>


### [74] [Certified Learning under Distribution Shift: Sound Verification and Identifiable Structure](https://arxiv.org/abs/2602.17699)
*Chandrasekhar Gokavarapu,Sudhakar Gadde,Y. Rajasekhar,S. R. Bhargava*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架，用于在分布偏移下对预测器的风险进行可验证的边界认证，通过可计算的偏移度量和模型参数来明确界定风险上限。


<details>
  <summary>Details</summary>
Motivation: 在现实世界应用中，机器学习模型经常面临训练分布和测试分布不一致的问题（分布偏移）。传统方法缺乏对分布偏移下风险的严格理论保证，需要建立一个统一的框架来认证模型在分布偏移下的风险边界。

Method: 建立了一个统一的理论框架，在可验证的正则性和复杂性约束下，通过可计算的偏移度量和模型参数推导出分布偏移下超额风险的显式上界。该框架包含三个核心要素：1）通过显式不等式认证分布偏移下的风险；2）对学习模型的验证在非平凡规模下是可靠的；3）通过可识别性条件而非事后解释来强制可解释性。

Result: 证明了在分布偏移下，预测器的超额风险存在由可计算偏移度量和模型参数确定的显式上界。所有声明都带有明确的假设条件，隔离了失败模式，并表征了不可认证的机制。

Conclusion: 该研究提供了一个理论严谨的框架，用于在分布偏移下对机器学习模型的风险进行可验证的认证。通过明确的假设、可计算的度量和模型参数，能够为实际应用中的分布偏移问题提供可靠的风险边界保证。

Abstract: Proposition. Let $f$ be a predictor trained on a distribution $P$ and evaluated on a shifted distribution $Q$. Under verifiable regularity and complexity constraints, the excess risk under shift admits an explicit upper bound determined by a computable shift metric and model parameters. We develop a unified framework in which (i) risk under distribution shift is certified by explicit inequalities, (ii) verification of learned models is sound for nontrivial sizes, and (iii) interpretability is enforced through identifiability conditions rather than post hoc explanations. All claims are stated with explicit assumptions. Failure modes are isolated. Non-certifiable regimes are characterized.

</details>


### [75] [MIDAS: Mosaic Input-Specific Differentiable Architecture Search](https://arxiv.org/abs/2602.17700)
*Konstanty Subbotko*

Main category: cs.LG

TL;DR: MIDAS提出了一种改进的可微分神经架构搜索方法，通过自注意力机制动态计算输入特定的架构参数，采用局部化补丁级架构选择和拓扑感知搜索空间，在多个基准测试中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 尽管可微分神经架构搜索（NAS）提供了高效的梯度优化方法，但在实际应用中仍然受到限制。现有方法如DARTS使用静态架构参数，缺乏对不同输入的适应性，且搜索过程不够稳健。

Method: MIDAS通过自注意力机制将静态架构参数替换为动态、输入特定的参数；采用局部化策略，为激活图的每个空间补丁单独计算架构选择；引入参数免费、拓扑感知的搜索空间，建模节点连接性并简化每个节点的两条入边选择。

Result: 在DARTS搜索空间上，CIFAR-10达到97.42% top-1准确率，CIFAR-100达到83.38%；在NAS-Bench-201上能一致找到全局最优架构；在RDARTS的四个搜索空间中，在两个上达到最先进水平。

Conclusion: MIDAS通过动态输入特定的架构参数和局部化选择机制，显著提升了可微分NAS的性能和鲁棒性。补丁级注意力提高了候选操作的区分度，产生的参数分布具有类别感知性和单峰性，为解码提供了可靠指导。

Abstract: Differentiable Neural Architecture Search (NAS) provides efficient, gradient-based methods for automatically designing neural networks, yet its adoption remains limited in practice. We present MIDAS, a novel approach that modernizes DARTS by replacing static architecture parameters with dynamic, input-specific parameters computed via self-attention. To improve robustness, MIDAS (i) localizes the architecture selection by computing it separately for each spatial patch of the activation map, and (ii) introduces a parameter-free, topology-aware search space that models node connectivity and simplifies selecting the two incoming edges per node. We evaluate MIDAS on the DARTS, NAS-Bench-201, and RDARTS search spaces. In DARTS, it reaches 97.42% top-1 on CIFAR-10 and 83.38% on CIFAR-100. In NAS-Bench-201, it consistently finds globally optimal architectures. In RDARTS, it sets the state of the art on two of four search spaces on CIFAR-10. We further analyze why MIDAS works, showing that patchwise attention improves discrimination among candidate operations, and the resulting input-specific parameter distributions are class-aware and predominantly unimodal, providing reliable guidance for decoding.

</details>


### [76] [Parallel Complex Diffusion for Scalable Time Series Generation](https://arxiv.org/abs/2602.17706)
*Rongyao Cai,Yuxi Wan,Kexin Zhang,Ming Jin,Zhiqiang Ge,Qingsong Wen,Yong Liu*

Main category: cs.LG

TL;DR: PaCoDi提出了一种基于频域的并行复杂扩散模型，通过傅里叶变换解耦时间序列生成中的长程依赖，在保持生成质量的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统时间扩散模型存在局部纠缠问题和注意力机制的O(L²)计算成本，难以高效建模时间序列中的长程依赖关系。

Method: 提出PaCoDi架构，在频域进行生成建模；利用傅里叶变换作为对角化算子将时间信号转换为解耦的频谱分量；证明正交前向扩散和条件反向分解定理；采用平均场理论近似和交互校正机制；利用实值信号的埃尔米特对称性压缩序列长度；推导异方差损失处理压缩流形上的非各向同性噪声分布。

Result: PaCoDi在生成质量和推理速度上均优于现有基线，注意力FLOPs减少50%且无信息损失，为时间序列建模提供了理论严谨且计算高效的解决方案。

Conclusion: PaCoDi通过频域解耦从根本上改变了时间序列生成的问题拓扑结构，在理论严谨性和计算效率之间取得了良好平衡，为解决长程依赖建模中的容量与效率权衡问题提供了新思路。

Abstract: Modeling long-range dependencies in time series generation poses a fundamental trade-off between representational capacity and computational efficiency. Traditional temporal diffusion models suffer from local entanglement and the $\mathcal{O}(L^2)$ cost of attention mechanisms. We address these limitations by introducing PaCoDi (Parallel Complex Diffusion), a spectral-native architecture that decouples generative modeling in the frequency domain. PaCoDi fundamentally alters the problem topology: the Fourier Transform acts as a diagonalizing operator, converting locally coupled temporal signals into globally decorrelated spectral components. Theoretically, we prove the Quadrature Forward Diffusion and Conditional Reverse Factorization theorem, demonstrating that the complex diffusion process can be split into independent real and imaginary branches. We bridge the gap between this decoupled theory and data reality using a \textbf{Mean Field Theory (MFT) approximation} reinforced by an interactive correction mechanism. Furthermore, we generalize this discrete DDPM to continuous-time Frequency SDEs, rigorously deriving the Spectral Wiener Process describe the differential spectral Brownian motion limit. Crucially, PaCoDi exploits the Hermitian Symmetry of real-valued signals to compress the sequence length by half, achieving a 50% reduction in attention FLOPs without information loss. We further derive a rigorous Heteroscedastic Loss to handle the non-isotropic noise distribution on the compressed manifold. Extensive experiments show that PaCoDi outperforms existing baselines in both generation quality and inference speed, offering a theoretically grounded and computationally efficient solution for time series modeling.

</details>


### [77] [Provable Adversarial Robustness in In-Context Learning](https://arxiv.org/abs/2602.17743)
*Di Zhang*

Main category: cs.LG

TL;DR: 论文提出了一个分布鲁棒的元学习框架，为基于Wasserstein距离的分布偏移下的上下文学习提供最坏情况性能保证，揭示了模型鲁棒性与容量平方根成正比，对抗性设置会带来与扰动幅度平方成正比的样本复杂度惩罚。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型上下文学习能力的理论解释假设测试任务来自与预训练相似的分布，这忽略了对抗性分布偏移对实际可靠性的威胁。为了填补这一理论空白，需要研究上下文学习在对抗性条件下的鲁棒性。

Method: 引入一个分布鲁棒的元学习框架，针对基于Wasserstein距离的分布偏移提供最坏情况性能保证。专注于线性自注意力Transformer模型，推导出连接对抗性扰动强度、模型容量和上下文示例数量的非渐近边界。

Result: 分析显示：1) 模型鲁棒性与其容量的平方根成正比（ρ_max ∝ √m）；2) 对抗性设置会带来与扰动幅度平方成正比的样本复杂度惩罚（N_ρ - N_0 ∝ ρ²）。在合成任务上的实验验证了这些缩放规律。

Conclusion: 这些发现推进了对上下文学习在对抗性条件下极限的理论理解，并表明模型容量是分布鲁棒性的基本资源。研究为实际应用中上下文学习的可靠性提供了理论指导。

Abstract: Large language models adapt to new tasks through in-context learning (ICL) without parameter updates. Current theoretical explanations for this capability assume test tasks are drawn from a distribution similar to that seen during pretraining. This assumption overlooks adversarial distribution shifts that threaten real-world reliability. To address this gap, we introduce a distributionally robust meta-learning framework that provides worst-case performance guarantees for ICL under Wasserstein-based distribution shifts. Focusing on linear self-attention Transformers, we derive a non-asymptotic bound linking adversarial perturbation strength ($ρ$), model capacity ($m$), and the number of in-context examples ($N$). The analysis reveals that model robustness scales with the square root of its capacity ($ρ_{\text{max}} \propto \sqrt{m}$), while adversarial settings impose a sample complexity penalty proportional to the square of the perturbation magnitude ($N_ρ- N_0 \propto ρ^2$). Experiments on synthetic tasks confirm these scaling laws. These findings advance the theoretical understanding of ICL's limits under adversarial conditions and suggest that model capacity serves as a fundamental resource for distributional robustness.

</details>


### [78] [Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs](https://arxiv.org/abs/2602.17778)
*Zachary Coalson,Bo Fang,Sanghyun Hong*

Main category: cs.LG

TL;DR: 论文发现对话大语言模型存在"轮次放大"新失效模式，攻击者可系统利用澄清寻求行为延长多轮对话而不完成任务，这种攻击源于对话动态机制，可在不同提示和任务中持续存在。


<details>
  <summary>Details</summary>
Motivation: 多轮交互长度是对话LLM运营成本的主要因素。研究发现对话LLMs存在新的失效模式：轮次放大，即模型持续延长多轮交互而不完成底层任务，攻击者可系统利用澄清寻求行为来可扩展地延长交互。

Method: 从机制角度出发，识别出与澄清寻求响应相关的查询无关的通用激活子空间。不同于依赖每轮提示优化的先前成本放大攻击，本研究攻击源于对话动态机制，并在不同提示和任务中持续存在。通过微调的供应链攻击和运行时参数损坏两种方式实现轮次放大。

Result: 在多个指令调优LLM和基准测试中，攻击显著增加了轮次计数，同时保持合规性。现有防御措施对这种新兴失效模式的保护有限。

Conclusion: 对话LLMs存在轮次放大这一新失效模式，攻击者可利用澄清寻求行为的通用激活子空间进行可扩展攻击，现有防御措施对此保护不足，需要新的防御机制来应对这种基于对话动态的攻击。

Abstract: Multi-turn interaction length is a dominant factor in the operational costs of conversational LLMs. In this work, we present a new failure mode in conversational LLMs: turn amplification, in which a model consistently prolongs multi-turn interactions without completing the underlying task. We show that an adversary can systematically exploit clarification-seeking behavior$-$commonly encouraged in multi-turn conversation settings$-$to scalably prolong interactions. Moving beyond prompt-level behaviors, we take a mechanistic perspective and identify a query-independent, universal activation subspace associated with clarification-seeking responses. Unlike prior cost-amplification attacks that rely on per-turn prompt optimization, our attack arises from conversational dynamics and persists across prompts and tasks. We show that this mechanism provides a scalable pathway to induce turn amplification: both supply-chain attacks via fine-tuning and runtime attacks through low-level parameter corruptions consistently shift models toward abstract, clarification-seeking behavior across prompts. Across multiple instruction-tuned LLMs and benchmarks, our attack substantially increases turn count while remaining compliant. We also show that existing defenses offer limited protection against this emerging class of failures.

</details>


### [79] [MantisV2: Closing the Zero-Shot Gap in Time Series Classification with Synthetic Data and Test-Time Strategies](https://arxiv.org/abs/2602.17868)
*Vasilii Feofanov,Songkang Wen,Jianfeng Zhang,Lujia Pan,Ievgen Redko*

Main category: cs.LG

TL;DR: MantisV2和Mantis+显著提升了时间序列分类基础模型的零样本特征提取能力，通过合成数据预训练、架构优化和测试时方法改进，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 开发时间序列分类基础模型具有重要实践意义，可作为通用特征提取器用于多种下游任务。早期模型如Mantis已显示出潜力，但冻结编码器和微调编码器之间存在显著性能差距，需要提升零样本特征提取能力。

Method: 1. 提出Mantis+：完全在合成时间序列上预训练的Mantis变体；2. 通过受控消融研究改进架构，得到更轻量的MantisV2编码器；3. 提出增强的测试时方法，利用中间层表示并改进输出标记聚合；4. 通过自集成和跨模型嵌入融合进一步提升性能。

Result: 在UCR、UEA、人类活动识别(HAR)基准和EEG数据集上的广泛实验表明，MantisV2和Mantis+在零样本性能上持续优于先前的时间序列基础模型，达到最先进水平。

Conclusion: 通过合成数据预训练、架构优化和测试时方法改进，显著提升了时间序列基础模型的零样本特征提取能力，为时间序列分析提供了更强大的通用特征提取器。

Abstract: Developing foundation models for time series classification is of high practical relevance, as such models can serve as universal feature extractors for diverse downstream tasks. Although early models such as Mantis have shown the promise of this approach, a substantial performance gap remained between frozen and fine-tuned encoders. In this work, we introduce methods that significantly strengthen zero-shot feature extraction for time series. First, we introduce Mantis+, a variant of Mantis pre-trained entirely on synthetic time series. Second, through controlled ablation studies, we refine the architecture and obtain MantisV2, an improved and more lightweight encoder. Third, we propose an enhanced test-time methodology that leverages intermediate-layer representations and refines output-token aggregation. In addition, we show that performance can be further improved via self-ensembling and cross-model embedding fusion. Extensive experiments on UCR, UEA, Human Activity Recognition (HAR) benchmarks, and EEG datasets show that MantisV2 and Mantis+ consistently outperform prior time series foundation models, achieving state-of-the-art zero-shot performance.

</details>


### [80] [Grassmannian Mixture-of-Experts: Concentration-Controlled Routing on Subspace Manifolds](https://arxiv.org/abs/2602.17798)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: GrMoE提出基于Grassmann流形的MoE路由框架，用矩阵Bingham分布的浓度参数控制路由稀疏性，实现连续可调的稀疏机制，避免专家崩溃。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型使用softmax门控缺乏控制稀疏性和利用率平衡的理论机制，且存在专家崩溃问题。需要一种几何原理明确、可连续调节稀疏性、能抵抗专家崩溃的路由框架。

Method: 提出Grassmannian MoE (GrMoE)，在Grassmann流形子空间上操作，使用矩阵Bingham分布的浓度参数Λ作为门控权重。开发摊销变分推理方法估计后验路由分布，实现不确定性感知的专家分配。理论证明浓度谱与路由熵、top-k质量、专家崩溃指数界的关系。

Result: 在350M/1.3B/2.7B参数的MoE语言模型上，GrMoE实现0%路由崩溃，困惑度相当或更好，负载均衡提升15-30%。浓度与有效稀疏性呈现平滑单调关系，支持训练后稀疏性调节。token级分析显示专家学习到与语言专业化相关的异质浓度值。

Conclusion: GrMoE建立了首个浓度控制稀疏性的形式化理论，提供几何原理明确、可连续调节、抵抗专家崩溃的路由框架，为MoE模型提供了更可解释和可控的路由机制。

Abstract: Mixture-of-Experts models rely on learned routers to assign tokens to experts, yet standard softmax gating provides no principled mechanism to control the tradeoff between sparsity and utilization. We propose Grassmannian MoE (GrMoE), a routing framework that operates on the Grassmannian manifold of subspaces, where gating weights arise from the concentration parameters of Matrix Bingham distributions. This construction yields a single, interpretable knob -- the concentration matrix $Λ$ -- that continuously controls routing entropy, replacing discrete top-$k$ selection with a smooth, geometrically principled sparsity mechanism. We further develop an amortized variational inference procedure for posterior routing distributions, enabling uncertainty-aware expert assignment that naturally resists expert collapse. We formally prove tight bounds relating the Bingham concentration spectrum to routing entropy, expected top-$k$ mass, and an exponential bound on expert collapse, establishing the first formal theory of concentration-controlled sparsity. On synthetic routing tasks, a 350M-parameter MoE language model with 8 experts, a 1.3B-parameter model with 16 experts, and a 2.7B-parameter model with 32 experts, GrMoE achieves 0\% routing collapse across all seeds, comparable or better perplexity with 15--30\% improved load balance, and a smooth monotonic relationship between concentration and effective sparsity that enables post-hoc sparsity tuning without retraining. Token-level analysis reveals that experts learn heterogeneous concentration values that correlate with linguistic specialization, providing interpretable routing behavior.

</details>


### [81] [Calibrated Adaptation: Bayesian Stiefel Manifold Priors for Reliable Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2602.17809)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: SBA是一种贝叶斯参数高效微调框架，通过Stiefel流形上的Matrix Langevin先验和切空间Laplace近似，为大型语言模型提供校准的不确定性估计，在领域偏移下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法（如LoRA）缺乏原则性的不确定性估计，导致预测校准不佳，在领域偏移下行为不可靠。需要一种既能保持参数效率又能提供校准不确定性的贝叶斯框架。

Method: 提出Stiefel-Bayes Adapters (SBA)：在Stiefel流形上放置Matrix Langevin先验，通过切空间Laplace近似和测地线回缩进行近似后验推断，避免从环境空间投影带来的结构方差膨胀。

Result: 在多个基准测试和模型上，SBA在保持与LoRA和DoRA相当任务性能的同时，将预期校准误差降低18-34%，领域偏移下选择性预测AUROC提高12-25%，以更少参数成本在OOD检测上优于五个LoRA模型的深度集成。

Conclusion: 在正确的几何结构上放置不确定性比简单地为适配器添加贝叶斯处理更重要。SBA为大型语言模型提供了参数高效且校准良好的不确定性估计框架。

Abstract: Parameter-efficient fine-tuning methods such as LoRA enable practical adaptation of large language models but provide no principled uncertainty estimates, leading to poorly calibrated predictions and unreliable behavior under domain shift. We introduce Stiefel-Bayes Adapters (SBA), a Bayesian PEFT framework that places a Matrix Langevin prior over orthonormal adapter factors on the Stiefel manifold $\St$ and performs approximate posterior inference via tangent space Laplace approximation with geodesic retraction. Unlike Gaussian priors in flat space projected onto orthogonality constraints, our prior on the manifold naturally encodes the inductive bias that adapter subspaces should be well conditioned and orthogonal, while the posterior provides calibrated predictive uncertainty without recalibration. We prove formally that the tangent space approximation strictly avoids the structural variance inflation inherent in projecting from ambient space, establishing a rigorous theoretical advantage for intrinsic manifold inference. Across GLUE and SuperGLUE benchmarks on RoBERTa-large, LLaMA-2-7B, LLaMA-2-13B, Mistral-7B, and Qwen2.5-7B, domain shift evaluations, selective prediction protocols, and an abstractive summarization task, SBA achieves task performance comparable to LoRA and DoRA while reducing Expected Calibration Error by 18 to 34\% over deterministic baselines, improving selective prediction AUROC by 12 to 25\% under domain shift, and outperforming deep ensembles of five LoRA models on OOD detection at a fraction of the parameter cost. Our results demonstrate that where you place uncertainty, on the right geometric structure, matters more than simply adding any Bayesian treatment to adapters.

</details>


### [82] [Machine Learning Based Prediction of Surgical Outcomes in Chronic Rhinosinusitis from Clinical Data](https://arxiv.org/abs/2602.17888)
*Sayeed Shafayet Chowdhury,Karen D'Souza,V. Siva Kakumani,Snehasis Mukhopadhyay,Shiaofen Fang,Rodney J. Schlosser,Daniel M. Beswick,Jeremiah A. Alt,Jess C. Mace,Zachary M. Soler,Timothy L. Smith,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 该研究使用监督机器学习模型预测慢性鼻窦炎患者的手术获益，在仅使用术前数据的情况下，最佳模型达到约85%的分类准确率，在30例测试病例中准确率80%，超过了专家临床医生的平均预测准确率（75.6%）。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能在医学预后中应用广泛，但将机器学习预测应用于前瞻性收集的标准化临床干预试验数据的研究仍然不足。慢性鼻窦炎作为一种持续炎症性疾病，对患者生活质量和社会成本造成重大负担。手术决策复杂，需要权衡已知风险与不确定的个体化结果，因此需要开发能够预测手术获益的工具来辅助临床决策。

Method: 研究使用监督机器学习模型预测慢性鼻窦炎患者的手术获益，以Sino-Nasal Outcome Test-22（SNOT-22）作为主要患者报告结果。使用前瞻性收集的观察性干预试验队列数据，所有患者均接受了手术。研究训练仅基于术前数据的模型，以识别那些在手术前可能不被推荐手术的患者。采用多种算法，包括集成方法。

Result: 最佳模型达到约85%的分类准确率，能够准确且可解释地预测手术候选资格。在30例混合难度病例的测试集上，模型准确率达到80%，超过了专家临床医生的平均预测准确率（75.6%）。

Conclusion: 该研究表明机器学习模型能够有效预测慢性鼻窦炎患者的手术获益，其性能优于临床专家，具有增强临床决策支持和实现个性化慢性鼻窦炎护理的潜力。

Abstract: Artificial intelligence (AI) has increasingly transformed medical prognostics by enabling rapid and accurate analysis across imaging and pathology. However, the investigation of machine learning predictions applied to prospectively collected, standardized data from observational clinical intervention trials remains underexplored, despite its potential to reduce costs and improve patient outcomes. Chronic rhinosinusitis (CRS), a persistent inflammatory disease of the paranasal sinuses lasting more than three months, imposes a substantial burden on quality of life (QoL) and societal cost. Although many patients respond to medical therapy, others with refractory symptoms often pursue surgical intervention. Surgical decision-making in CRS is complex, as it must weigh known procedural risks against uncertain individualized outcomes. In this study, we evaluated supervised machine learning models for predicting surgical benefit in CRS, using the Sino-Nasal Outcome Test-22 (SNOT-22) as the primary patient-reported outcome. Our prospectively collected cohort from an observational intervention trial comprised patients who all underwent surgery; we investigated whether models trained only on preoperative data could identify patients who might not have been recommended surgery prior to the procedure. Across multiple algorithms, including an ensemble approach, our best model achieved approximately 85% classification accuracy, providing accurate and interpretable predictions of surgical candidacy. Moreover, on a held-out set of 30 cases spanning mixed difficulty, our model achieved 80% accuracy, exceeding the average prediction accuracy of expert clinicians (75.6%), demonstrating its potential to augment clinical decision-making and support personalized CRS care.

</details>


### [83] [Causality by Abstraction: Symbolic Rule Learning in Multivariate Timeseries with Large Language Models](https://arxiv.org/abs/2602.17829)
*Preetom Biswas,Giulia Pedrielli,K. Selçuk Candan*

Main category: cs.LG

TL;DR: ruleXplain是一个利用大语言模型从仿真驱动动力系统中提取形式化解释的框架，通过带时间算子和延迟语义的约束符号规则语言，生成可验证的因果规则。


<details>
  <summary>Details</summary>
Motivation: 在具有延迟效应的时间序列数据中推断因果关系是一个基本挑战，特别是当底层系统表现出复杂动态时。传统方法往往无法产生泛化且可解释的解释，因为多个不同的输入轨迹可能产生几乎无法区分的输出。

Method: 提出ruleXplain框架，利用LLMs提取仿真驱动动力系统中输入-输出关系的正式解释。方法包括：1)引入带时间算子和延迟语义的约束符号规则语言；2)使用仿真器生成产生相似目标输出的多样化反事实输入轨迹；3)将反事实输入聚类并提供给LLM作为上下文；4)LLM生成编码联合时间趋势的符号规则；5)闭环精炼过程确保规则一致性和语义有效性。

Result: 使用PySIRTEM流行病模拟器（测试率输入到每日感染数）和EnergyPlus建筑能源模拟器（温度和太阳辐照度输入到电力需求）验证框架。进行三类实验：1)通过输入重建评估规则集的有效性；2)消融研究评估规则的因果编码；3)提取规则在具有不同相位动态的未见输出趋势上的泛化测试。

Conclusion: ruleXplain框架能够从复杂动态系统中提取形式化、可验证的因果规则解释，解决了传统方法在具有延迟效应的时间序列数据中推断因果关系的局限性。

Abstract: Inferring causal relations in timeseries data with delayed effects is a fundamental challenge, especially when the underlying system exhibits complex dynamics that cannot be captured by simple functional mappings. Traditional approaches often fail to produce generalized and interpretable explanations, as multiple distinct input trajectories may yield nearly indistinguishable outputs. In this work, we present ruleXplain, a framework that leverages Large Language Models (LLMs) to extract formal explanations for input-output relations in simulation-driven dynamical systems. Our method introduces a constrained symbolic rule language with temporal operators and delay semantics, enabling LLMs to generate verifiable causal rules through structured prompting. ruleXplain relies on the availability of a principled model (e.g., a simulator) that maps multivariate input time series to output time series. Within ruleXplain, the simulator is used to generate diverse counterfactual input trajectories that yield similar target output, serving as candidate explanations. Such counterfactual inputs are clustered and provided as context to the LLM, which is tasked with the generation of symbolic rules encoding the joint temporal trends responsible for the patterns observable in the output times series. A closed-loop refinement process ensures rule consistency and semantic validity. We validate the framework using the PySIRTEM epidemic simulator, mapping testing rate inputs to daily infection counts; and the EnergyPlus building energy simulator, observing temperature and solar irradiance inputs to electricity needs. For validation, we perform three classes of experiments: (1) the efficacy of the ruleset through input reconstruction; (2) ablation studies evaluating the causal encoding of the ruleset; and (3) generalization tests of the extracted rules across unseen output trends with varying phase dynamics.

</details>


### [84] [MePoly: Max Entropy Polynomial Policy Optimization](https://arxiv.org/abs/2602.17832)
*Hang Liu,Sangli Teng,Maani Ghaffari*

Main category: cs.LG

TL;DR: 提出MePoly方法，基于多项式能量模型的新型策略参数化，解决传统参数化策略难以表示多模态解的问题，提供显式可处理的概率密度，实现精确熵最大化


<details>
  <summary>Details</summary>
Motivation: 传统参数化策略难以表示随机最优控制问题的多模态解，而基于扩散的策略缺乏显式概率密度，使策略梯度优化复杂化

Method: 基于多项式能量模型的策略参数化方法MePoly，利用经典矩问题的理论基础，通过多项式能量函数提供显式可处理的概率密度

Result: MePoly能有效捕捉复杂的非凸流形，在多样化基准测试中性能优于基线方法

Conclusion: MePoly为随机最优控制提供了一种既能表示多模态解又具有显式概率密度的有效策略参数化方法

Abstract: Stochastic Optimal Control provides a unified mathematical framework for solving complex decision-making problems, encompassing paradigms such as maximum entropy reinforcement learning(RL) and imitation learning(IL). However, conventional parametric policies often struggle to represent the multi-modality of the solutions. Though diffusion-based policies are aimed at recovering the multi-modality, they lack an explicit probability density, which complicates policy-gradient optimization. To bridge this gap, we propose MePoly, a novel policy parameterization based on polynomial energy-based models. MePoly provides an explicit, tractable probability density, enabling exact entropy maximization. Theoretically, we ground our method in the classical moment problem, leveraging the universal approximation capabilities for arbitrary distributions. Empirically, we demonstrate that MePoly effectively captures complex non-convex manifolds and outperforms baselines in performance across diverse benchmarks.

</details>


### [85] [MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance](https://arxiv.org/abs/2602.17930)
*Narjes Nourzad,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: MIRA提出了一种结合LLM先验知识和结构化记忆图的强化学习方法，通过记忆图存储高回报经验和LLM输出，生成效用信号来调整优势估计，从而在稀疏奖励环境中加速早期学习，同时减少对实时LLM监督的依赖。


<details>
  <summary>Details</summary>
Motivation: 强化学习在稀疏或延迟奖励环境中样本效率低下，而LLM虽然能提供子目标分解和轨迹先验，但过度依赖LLM监督会带来可扩展性限制和不可靠信号的问题。需要一种既能利用LLM先验知识又能减少对其持续依赖的方法。

Method: MIRA构建结构化记忆图，存储智能体的高回报经验和LLM输出的子目标结构等信息。从记忆图中推导出效用信号，软调整优势估计来影响策略更新，而不改变底层奖励函数。随着训练进行，效用项逐渐衰减，保持标准收敛保证。

Result: 理论分析表明基于效用的塑形能改善稀疏奖励环境中的早期学习。实证结果显示MIRA优于RL基线方法，达到与频繁使用LLM监督方法相当的回报，同时显著减少了在线LLM查询次数。

Conclusion: MIRA通过结构化记忆图将LLM先验知识转化为持久记忆，实现了在稀疏奖励环境中加速早期学习的目标，同时减少了对实时LLM监督的依赖，为结合LLM先验与强化学习提供了可扩展的解决方案。

Abstract: Reinforcement learning (RL) agents often suffer from high sample complexity in sparse or delayed reward settings due to limited prior structure. Large language models (LLMs) can provide subgoal decompositions, plausible trajectories, and abstract priors that facilitate early learning. However, heavy reliance on LLM supervision introduces scalability constraints and dependence on potentially unreliable signals. We propose MIRA (Memory-Integrated Reinforcement Learning Agent), which incorporates a structured, evolving memory graph to guide early training. The graph stores decision-relevant information, including trajectory segments and subgoal structures, and is constructed from both the agent's high-return experiences and LLM outputs. This design amortizes LLM queries into a persistent memory rather than requiring continuous real-time supervision. From this memory graph, we derive a utility signal that softly adjusts advantage estimation to influence policy updates without modifying the underlying reward function. As training progresses, the agent's policy gradually surpasses the initial LLM-derived priors, and the utility term decays, preserving standard convergence guarantees. We provide theoretical analysis showing that utility-based shaping improves early-stage learning in sparse-reward environments. Empirically, MIRA outperforms RL baselines and achieves returns comparable to approaches that rely on frequent LLM supervision, while requiring substantially fewer online LLM queries. Project webpage: https://narjesno.github.io/MIRA/

</details>


### [86] [ADAPT: Hybrid Prompt Optimization for LLM Feature Visualization](https://arxiv.org/abs/2602.17867)
*João N. Cardoso,Arlindo L. Oliveira,Bruno Martins*

Main category: cs.LG

TL;DR: ADAPT：一种结合束搜索初始化和自适应梯度引导突变的混合方法，用于优化LLM激活空间中离散文本的特征可视化


<details>
  <summary>Details</summary>
Motivation: 理解LLM激活空间中学习到的方向编码了哪些特征需要找到能强烈激活这些方向的输入。特征可视化通过优化输入来最大化激活目标方向，为昂贵的数据库搜索方法提供了替代方案，但由于文本的离散性，在LLM中仍未得到充分探索。现有的提示优化技术也不适合这个领域，容易陷入局部最小值。

Method: ADAPT是一种混合方法，结合了束搜索初始化和自适应梯度引导突变，专门针对这些失败模式设计。该方法在Gemma 2 2B的稀疏自编码器潜在空间上进行评估，提出了基于数据集激活统计的指标来进行严格比较。

Result: ADAPT在不同层和潜在类型上始终优于先前的方法。结果表明LLM的特征可视化是可行的，但需要针对该领域量身定制的设计假设。

Conclusion: LLM的特征可视化是可行的，但需要专门针对离散文本优化挑战设计的混合方法。ADAPT通过结合束搜索和自适应梯度引导突变，为理解LLM激活空间中的学习特征提供了有效的工具。

Abstract: Understanding what features are encoded by learned directions in LLM activation space requires identifying inputs that strongly activate them. Feature visualization, which optimizes inputs to maximally activate a target direction, offers an alternative to costly dataset search approaches, but remains underexplored for LLMs due to the discrete nature of text. Furthermore, existing prompt optimization techniques are poorly suited to this domain, which is highly prone to local minima. To overcome these limitations, we introduce ADAPT, a hybrid method combining beam search initialization with adaptive gradient-guided mutation, designed around these failure modes. We evaluate on Sparse Autoencoder latents from Gemma 2 2B, proposing metrics grounded in dataset activation statistics to enable rigorous comparison, and show that ADAPT consistently outperforms prior methods across layers and latent types. Our results establish that feature visualization for LLMs is tractable, but requires design assumptions tailored to the domain.

</details>


### [87] [Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2602.17931)
*Narjes Nourzad,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 该论文提出了一种结合大语言模型（LLM）和记忆图的方法，用于解决稀疏或延迟奖励环境中的强化学习样本复杂度问题，通过构建记忆图编码子目标和轨迹，并从中推导效用函数来指导智能体探索，减少对LLM的频繁调用。


<details>
  <summary>Details</summary>
Motivation: 在稀疏或延迟奖励环境中，强化学习需要大量交互导致样本复杂度高。虽然大语言模型可以用于子目标发现和轨迹指导，但频繁依赖LLM调用会带来可扩展性和可靠性问题。

Method: 构建记忆图编码来自LLM指导和智能体自身成功轨迹的子目标和轨迹，从中推导效用函数评估智能体轨迹与先前成功策略的匹配程度。该效用函数塑造优势函数，为critic提供额外指导而不改变奖励。主要依赖离线输入和偶尔的在线查询，避免持续依赖LLM监督。

Result: 在基准环境中的初步实验显示，相比基线RL方法，该方法提高了样本效率并加速了早期学习，最终回报与需要频繁LLM交互的方法相当。

Conclusion: 该方法通过构建记忆图和推导效用函数，有效减少了强化学习在稀疏奖励环境中对频繁LLM调用的依赖，在保持性能的同时提高了可扩展性和可靠性。

Abstract: In environments with sparse or delayed rewards, reinforcement learning (RL) incurs high sample complexity due to the large number of interactions needed for learning. This limitation has motivated the use of large language models (LLMs) for subgoal discovery and trajectory guidance. While LLMs can support exploration, frequent reliance on LLM calls raises concerns about scalability and reliability. We address these challenges by constructing a memory graph that encodes subgoals and trajectories from both LLM guidance and the agent's own successful rollouts. From this graph, we derive a utility function that evaluates how closely the agent's trajectories align with prior successful strategies. This utility shapes the advantage function, providing the critic with additional guidance without altering the reward. Our method relies primarily on offline input and only occasional online queries, avoiding dependence on continuous LLM supervision. Preliminary experiments in benchmark environments show improved sample efficiency and faster early learning compared to baseline RL methods, with final returns comparable to methods that require frequent LLM interaction.

</details>


### [88] [NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs](https://arxiv.org/abs/2602.18008)
*Zihan Guan,Rituparna Datta,Mengxuan Hu,Shunshun Liu,Aiying Zhang,Prasanna Balachandran,Sheng Li,Anil Vullikanti*

Main category: cs.LG

TL;DR: 提出NIMM评估框架，用于评估LLM生成的机理模型在现实条件下的可靠性，并开发NIMMgen框架通过迭代优化提升模型正确性和实用性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的机理模型构建方法在现实条件下可靠性不明，需要评估框架来验证LLM生成的机理模型在实际应用中的有效性

Method: 提出NIMM评估框架，在部分观测和多样化任务目标的现实条件下评估LLM生成的机理模型；开发NIMMgen框架，通过迭代优化提升代码正确性和实际有效性

Result: 评估发现现有基线方法存在从模型有效性到代码正确性的根本挑战；NIMMgen在三个不同科学领域的数据集上表现出色，且学习到的机理模型支持反事实干预模拟

Conclusion: NIMM框架揭示了当前LLM生成机理模型的局限性，NIMMgen通过迭代优化显著提升了模型可靠性和实用性，为机理建模提供了有效的自动化解决方案

Abstract: Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem settings substantially oversimplify real-world conditions, leaving it unclear whether LLM-generated mechanistic models are reliable in practice. To address this gap, we introduce the Neural-Integrated Mechanistic Modeling (NIMM) evaluation framework, which evaluates LLM-generated mechanistic models under realistic settings with partial observations and diversified task objectives. Our evaluation reveals fundamental challenges in current baselines, ranging from model effectiveness to code-level correctness. Motivated by these findings, we design NIMMgen, an agentic framework for neural-integrated mechanistic modeling that enhances code correctness and practical validity through iterative refinement. Experiments across three datasets from diversified scientific domains demonstrate its strong performance. We also show that the learned mechanistic models support counterfactual intervention simulation.

</details>


### [89] [Two Calm Ends and the Wild Middle: A Geometric Picture of Memorization in Diffusion Models](https://arxiv.org/abs/2602.17846)
*Nick Dodson,Xinyu Gao,Qingsong Wang,Yusu Wang,Zhengchao Wan*

Main category: cs.LG

TL;DR: 扩散模型存在训练数据记忆风险，作者提出几何框架将噪声调度分为三个区域，识别出中等噪声区域是记忆风险最高的"危险区"，并提出几何干预方法缓解记忆问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然能生成高质量样本，但也可能记忆训练数据，引发隐私担忧。目前对记忆与泛化机制的理解有限，特别是噪声调度中记忆发生的位置、数据几何的影响以及不同噪声尺度现象的相互作用尚不明确。

Method: 提出几何框架，基于高斯壳覆盖训练数据的特性和后验集中行为，将噪声调度划分为三个区域。识别中等噪声区域为记忆风险最高的"危险区"，并提出几何条件指导的针对性干预方法。

Result: 研究发现记忆风险在噪声水平上高度不均匀：小噪声区域因训练覆盖有限而避免记忆；大噪声区域后验集中度低，表现出近似线性高斯去噪行为；中等噪声区域记忆风险最高。通过几何条件分析，提出了有效的针对性干预方法。

Conclusion: 扩散模型的记忆风险在噪声调度中分布不均，中等噪声区域是主要风险区。几何框架为理解记忆与泛化机制提供了新视角，几何干预方法能有效缓解记忆问题，为隐私保护提供了理论指导。

Abstract: Diffusion models generate high-quality samples but can also memorize training data, raising serious privacy concerns. Understanding the mechanisms governing when memorization versus generalization occurs remains an active area of research. In particular, it is unclear where along the noise schedule memorization is induced, how data geometry influences it, and how phenomena at different noise scales interact. We introduce a geometric framework that partitions the noise schedule into three regimes based on the coverage properties of training data by Gaussian shells and the concentration behavior of the posterior, which we argue are two fundamental objects governing memorization and generalization in diffusion models. This perspective reveals that memorization risk is highly non-uniform across noise levels. We further identify a danger zone at medium noise levels where memorization is most pronounced. In contrast, both the small and large noise regimes resist memorization, but through fundamentally different mechanisms: small noise avoids memorization due to limited training coverage, while large noise exhibits low posterior concentration and admits a provably near linear Gaussian denoising behavior. For the medium noise regime, we identify geometric conditions through which we propose a geometry-informed targeted intervention that mitigates memorization.

</details>


### [90] [Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards](https://arxiv.org/abs/2602.18037)
*Johannes Ackermann,Michael Noukhovitch,Takashi Ishida,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 该论文提出使用梯度正则化（GR）替代传统的KL惩罚，通过引导策略更新到奖励模型更准确的区域来防止奖励黑客攻击，在RLHF任务中表现优于KL惩罚方法。


<details>
  <summary>Details</summary>
Motivation: 在语言模型的后训练中，RLHF和RLVR存在奖励黑客问题，即策略可能利用奖励模型的不准确性学习到非预期的行为。传统方法使用KL惩罚限制策略更新，但作者认为应该引导策略更新到奖励模型更准确的区域。

Method: 提出梯度正则化（GR）方法：1）理论推导奖励模型准确性与收敛时最优解平坦度的关系；2）使用梯度正则化引导训练到更平坦的区域，从而保持奖励模型准确性；3）提出高效的有限差分估计实现显式GR。

Result: 实验表明：1）梯度范数与奖励准确性在RLHF中呈正相关；2）KL惩罚的参考重置隐式使用了GR；3）显式GR在多种RL实验中优于KL惩罚，包括更高的GPT评判胜率、避免过度关注基于规则的数学奖励格式、防止在LLM-as-a-Judge数学任务中黑客攻击评委。

Conclusion: 梯度正则化是一种有效的替代KL惩罚的方法，能够通过引导策略更新到奖励模型更准确的区域来防止奖励黑客攻击，在RLHF任务中表现更优。

Abstract: Reinforcement Learning from Human Feedback (RLHF) or Verifiable Rewards (RLVR) are two key steps in the post-training of modern Language Models (LMs). A common problem is reward hacking, where the policy may exploit inaccuracies of the reward and learn an unintended behavior. Most previous works address this by limiting the policy update with a Kullback-Leibler (KL) penalty towards a reference model. We propose a different framing: Train the LM in a way that biases policy updates towards regions in which the reward is more accurate. First, we derive a theoretical connection between the accuracy of a reward model and the flatness of an optimum at convergence. Gradient regularization (GR) can then be used to bias training to flatter regions and thereby maintain reward model accuracy. We confirm these results by showing that the gradient norm and reward accuracy are empirically correlated in RLHF. We then show that Reference Resets of the KL penalty implicitly use GR to find flatter regions with higher reward accuracy. We further improve on this by proposing to use explicit GR with an efficient finite-difference estimate. Empirically, GR performs better than a KL penalty across a diverse set of RL experiments with LMs. GR achieves a higher GPT-judged win-rate in RLHF, avoids overly focusing on the format in rule-based math rewards, and prevents hacking the judge in LLM-as-a-Judge math tasks.

</details>


### [91] [Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory](https://arxiv.org/abs/2602.18297)
*Usman Anwar,Tim Bakker,Dana Kianfar,Cristina Pinneri,Christos Louizos*

Main category: cs.LG

TL;DR: 本文通过信息论分析发现思维链与输出之间的非零互信息是思维链可监控的必要但不充分条件，提出了两种近似误差来源，并开发了两种训练方法来系统提升思维链的可监控性。


<details>
  <summary>Details</summary>
Motivation: 思维链监控器是基于LLM的系统，用于分析推理轨迹以检测输出是否具有特定属性（如代码生成中的测试黑客行为）。然而，当前思维链监控在实际应用中存在性能问题，需要从理论上理解其局限性并开发改进方法。

Method: 1. 信息论分析：证明思维链与输出之间的非零互信息是可监控性的必要但不充分条件；2. 识别两种近似误差来源：信息差距和引发误差；3. 提出两种训练方法：基于oracle的方法直接奖励模型产生最大化监控准确性的思维链；无标签方法最大化输出与思维链之间的条件互信息。

Result: 在多个不同环境中，两种方法都显著提高了监控准确性，同时防止了思维链退化，即使在与监控器对抗训练时也能缓解奖励黑客问题（当任务奖励规范不完善时）。

Conclusion: 思维链可监控性可以通过有针对性的训练目标系统性地改进。提出的两种方法（oracle方法和无标签方法）都能有效提升监控性能，同时保持思维链质量，为解决实际应用中的监控挑战提供了实用解决方案。

Abstract: Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.

</details>


### [92] [On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction](https://arxiv.org/abs/2602.18301)
*Ivan Bondarenko,Egor Palkin,Fedor Tikunov*

Main category: cs.LG

TL;DR: 研究发现冻结大语言模型可以通过两个学习到的原型标记在单次前向传播中重建数百个标记，探索了原型标记的信息编码方式及其在重建和约束下的行为。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型需要n次前向传播来生成长度为n的序列，效率较低。最近研究表明冻结LLMs可以通过两个学习到的原型标记在单次前向传播中重建数百个标记，这为超越自回归范式提供了可能。本研究旨在探索这些原型标记编码的信息及其行为特性。

Method: 进行了一系列实验：1）分离两个原型标记中的语义和句法内容；2）分析e-token的稳定性特性；3）可视化重建过程中对e-token的注意力模式；4）测试两种正则化方案：基于锚点的损失和关系蒸馏目标，用于在e-token上"施加"语义结构。

Result: 1）在标准优化下，m-token比e-token更强烈地捕获语义信息；2）基于锚点的约束与重建准确性之间存在明显权衡；3）关系蒸馏可以将批次级别的语义关系转移到原型标记空间，且不牺牲重建质量。

Conclusion: 研究支持了未来非自回归序列到序列系统的可行性，这些系统可以将原型标记作为中间表示进行预测。关系蒸馏方法特别有前景，因为它能有效转移语义关系而不损害重建能力。

Abstract: Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for "imposing" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.

</details>


### [93] [JAX-Privacy: A library for differentially private machine learning](https://arxiv.org/abs/2602.17861)
*Ryan McKenna,Galen Andrew,Borja Balle,Vadym Doroshenko,Arun Ganesh,Weiwei Kong,Alex Kurakin,Brendan McMahan,Mikhail Pravilov*

Main category: cs.LG

TL;DR: JAX-Privacy是一个用于简化差分隐私机器学习机制部署的库，旨在平衡易用性、灵活性和效率


<details>
  <summary>Details</summary>
Motivation: 简化差分隐私机器学习机制的部署，为研究人员和从业者提供统一的工具，整合该领域的最新研究成果

Method: 基于JAX构建，提供经过验证的模块化原语，涵盖批量选择、梯度裁剪、噪声添加、会计和审计等关键组件

Result: 创建了一个既支持深度定制又提供开箱即用体验的库，整合了大量差分隐私ML的最新研究成果

Conclusion: JAX-Privacy通过模块化设计和统一框架，有效促进了差分隐私机器学习的研究和应用部署

Abstract: JAX-Privacy is a library designed to simplify the deployment of robust and performant mechanisms for differentially private machine learning. Guided by design principles of usability, flexibility, and efficiency, JAX-Privacy serves both researchers requiring deep customization and practitioners who want a more out-of-the-box experience. The library provides verified, modular primitives for critical components for all aspects of the mechanism design including batch selection, gradient clipping, noise addition, accounting, and auditing, and brings together a large body of recent research on differentially private ML.

</details>


### [94] [Subgroups of $U(d)$ Induce Natural RNN and Transformer Architectures](https://arxiv.org/abs/2602.18417)
*Joshua Nunley*

Main category: cs.LG

TL;DR: 本文提出了一个在U(d)闭子群上构建具有隐藏状态的序列模型的直接框架，使用最小公理设置，从共享骨架推导出循环和Transformer模板，并在O(d)上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 为序列模型提供统一的数学框架，通过在U(d)的闭子群上构建隐藏状态，实现状态空间、切投影和更新映射的模块化替换。

Method: 使用最小公理设置，从共享骨架推导出循环和Transformer模板，子群选择作为状态空间、切投影和更新映射的即插即用替代。专门针对O(d)实现正交状态RNN和Transformer模型，并提出了切空间中的一般线性混合扩展。

Result: 在Tiny Shakespeare和Penn Treebank数据集上评估了正交状态RNN和Transformer模型，在参数匹配设置下表现良好。切空间中的线性混合扩展在O(d)实验中提高了有限预算下的性能。

Conclusion: 提出的框架为序列模型提供了统一的数学基础，子群选择作为灵活的设计维度，线性混合扩展进一步提升了模型性能，为序列建模提供了新的理论视角。

Abstract: This paper presents a direct framework for sequence models with hidden states on closed subgroups of U(d). We use a minimal axiomatic setup and derive recurrent and transformer templates from a shared skeleton in which subgroup choice acts as a drop-in replacement for state space, tangent projection, and update map. We then specialize to O(d) and evaluate orthogonal-state RNN and transformer models on Tiny Shakespeare and Penn Treebank under parameter-matched settings. We also report a general linear-mixing extension in tangent space, which applies across subgroup choices and improves finite-budget performance in the current O(d) experiments.

</details>


### [95] [Learning Optimal and Sample-Efficient Decision Policies with Guarantees](https://arxiv.org/abs/2602.17978)
*Daqian Shao*

Main category: cs.LG

TL;DR: 该论文提出了一种从存在隐藏混杂因素的离线数据集中学习决策策略的方法，使用工具变量识别因果效应，并应用于模仿学习和线性时序逻辑目标学习，提高了样本效率和性能保证。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习需要大量在线环境交互，但在高风险应用中成本高、危险或不可行。离线学习面临隐藏混杂因素导致虚假相关性的问题，需要开发能够处理这些挑战并具有理论保证的方法。

Method: 1. 使用工具变量识别因果效应，将问题转化为条件矩限制问题；2. 受双重/去偏机器学习启发，开发具有收敛和最优性保证的样本高效算法；3. 在模仿学习中放宽隐藏混杂因素条件，并调整CMR估计器；4. 针对线性时序逻辑表达的高层目标开发可证明最优的学习算法。

Result: 提出的CMR问题求解算法优于现有最先进算法，模仿学习算法能学习有效模仿策略并具有收敛率保证，LTL学习算法提高了样本效率。在强化学习基准和合成/半合成数据集上验证了方法的实用性。

Conclusion: 该论文开发的方法能够有效处理离线学习中的隐藏混杂因素问题，提供理论保证，提高样本效率，在现实世界决策制定中具有实际应用价值，特别是在高风险应用场景中。

Abstract: The paradigm of decision-making has been revolutionised by reinforcement learning and deep learning. Although this has led to significant progress in domains such as robotics, healthcare, and finance, the use of RL in practice is challenging, particularly when learning decision policies in high-stakes applications that may require guarantees. Traditional RL algorithms rely on a large number of online interactions with the environment, which is problematic in scenarios where online interactions are costly, dangerous, or infeasible. However, learning from offline datasets is hindered by the presence of hidden confounders. Such confounders can cause spurious correlations in the dataset and can mislead the agent into taking suboptimal or adversarial actions. Firstly, we address the problem of learning from offline datasets in the presence of hidden confounders. We work with instrumental variables (IVs) to identify the causal effect, which is an instance of a conditional moment restrictions (CMR) problem. Inspired by double/debiased machine learning, we derive a sample-efficient algorithm for solving CMR problems with convergence and optimality guarantees, which outperforms state-of-the-art algorithms. Secondly, we relax the conditions on the hidden confounders in the setting of (offline) imitation learning, and adapt our CMR estimator to derive an algorithm that can learn effective imitator policies with convergence rate guarantees. Finally, we consider the problem of learning high-level objectives expressed in linear temporal logic (LTL) and develop a provably optimal learning algorithm that improves sample efficiency over existing methods. Through evaluation on reinforcement learning benchmarks and synthetic and semi-synthetic datasets, we demonstrate the usefulness of the methods developed in this thesis in real-world decision making.

</details>


### [96] [PHAST: Port-Hamiltonian Architecture for Structured Temporal Dynamics Forecasting](https://arxiv.org/abs/2602.17998)
*Shubham Bhardwaj,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: PHAST模型解决仅从位置观测数据学习物理系统动力学的问题，通过端口哈密顿框架实现稳定长期预测和物理参数恢复。


<details>
  <summary>Details</summary>
Motivation: 真实物理系统都是耗散的，从部分观测数据预测其动力学是科学机器学习中的核心挑战。特别是仅从位置观测数据（动量隐变量）学习结构化模型，需要实现稳定长期预测并在提供足够结构时恢复物理意义参数。

Method: 提出PHAST（端口哈密顿结构化时间动力学架构），基于端口哈密顿框架将保守-耗散分解显式化，将哈密顿量分解为势能、质量和阻尼三个部分，对应三种知识状态（已知、部分已知、未知），使用高效低秩PSD/SPD参数化，并通过Strang分裂推进动力学。

Result: 在13个仅位置观测的基准测试中（涵盖机械、电气、分子、热力学、引力和生态系统），PHAST在长期预测方面表现最佳，并在提供足够锚点时能够恢复物理意义参数。研究表明没有锚点时识别问题是病态的（规范自由度）。

Conclusion: PHAST成功解决了仅从位置观测数据学习物理系统动力学的问题，实现了稳定长期预测和物理参数恢复。研究强调了将预测稳定性与可识别性分开评估的重要性，为科学机器学习中的结构化建模提供了有效框架。

Abstract: Real physical systems are dissipative -- a pendulum slows, a circuit loses charge to heat -- and forecasting their dynamics from partial observations is a central challenge in scientific machine learning. We address the \emph{position-only} (q-only) problem: given only generalized positions~$q_t$ at discrete times (momenta~$p_t$ latent), learn a structured model that (a)~produces stable long-horizon forecasts and (b)~recovers physically meaningful parameters when sufficient structure is provided. The port-Hamiltonian framework makes the conservative-dissipative split explicit via $\dot{x}=(J-R)\nabla H(x)$, guaranteeing $dH/dt\le 0$ when $R\succeq 0$. We introduce \textbf{PHAST} (Port-Hamiltonian Architecture for Structured Temporal dynamics), which decomposes the Hamiltonian into potential~$V(q)$, mass~$M(q)$, and damping~$D(q)$ across three knowledge regimes (KNOWN, PARTIAL, UNKNOWN), uses efficient low-rank PSD/SPD parameterizations, and advances dynamics with Strang splitting. Across thirteen q-only benchmarks spanning mechanical, electrical, molecular, thermal, gravitational, and ecological systems, PHAST achieves the best long-horizon forecasting among competitive baselines and enables physically meaningful parameter recovery when the regime provides sufficient anchors. We show that identification is fundamentally ill-posed without such anchors (gauge freedom), motivating a two-axis evaluation that separates forecasting stability from identifiability.

</details>


### [97] [Breaking the Correlation Plateau: On the Optimization and Capacity Limits of Attention-Based Regressors](https://arxiv.org/abs/2602.17898)
*Jingquan Yan,Yuwei Miao,Peiran Yu,Junzhou Huang*

Main category: cs.LG

TL;DR: 论文分析了注意力回归模型中PCC停滞现象的理论原因，揭示了MSE优化与PCC梯度间的冲突，以及softmax注意力在数据同质化时的局限性，提出了改进的ECA方法。


<details>
  <summary>Details</summary>
Motivation: 注意力回归模型训练中常见的PCC停滞现象缺乏理论解释，即Pearson相关系数在训练早期就停止改善，而MSE仍在持续下降。这种现象限制了模型在保持目标顺序和形状方面的性能提升。

Method: 首先从理论上分析了PCC停滞的两个根本原因：1) MSE优化与PCC梯度间的冲突，特别是在softmax注意力机制下，数据同质化会加剧这一问题；2) 任何凸聚合器（包括softmax注意力）的PCC改进存在理论极限，受输入凸包的严格限制。基于这些分析，提出了Extrapolative Correlation Attention (ECA)，包含新的理论驱动机制来改善PCC优化并突破凸包限制。

Result: 在包括具有挑战性的同质数据设置在内的多个基准测试中，ECA方法能够持续打破PCC停滞现象，在保持MSE性能的同时显著提升相关系数表现。

Conclusion: 论文首次为注意力回归模型中的PCC停滞现象提供了严格的理论分析，揭示了优化动态和模型容量的根本限制。提出的ECA方法通过理论驱动的机制有效解决了这些问题，为改进注意力回归模型的相关系数优化提供了新的方向。

Abstract: Attention-based regression models are often trained by jointly optimizing Mean Squared Error (MSE) loss and Pearson correlation coefficient (PCC) loss, emphasizing the magnitude of errors and the order or shape of targets, respectively. A common but poorly understood phenomenon during training is the PCC plateau: PCC stops improving early in training, even as MSE continues to decrease. We provide the first rigorous theoretical analysis of this behavior, revealing fundamental limitations in both optimization dynamics and model capacity. First, in regard to the flattened PCC curve, we uncover a critical conflict where lowering MSE (magnitude matching) can paradoxically suppress the PCC gradient (shape matching). This issue is exacerbated by the softmax attention mechanism, particularly when the data to be aggregated is highly homogeneous. Second, we identify a limitation in the model capacity: we derived a PCC improvement limit for any convex aggregator (including the softmax attention), showing that the convex hull of the inputs strictly bounds the achievable PCC gain. We demonstrate that data homogeneity intensifies both limitations. Motivated by these insights, we propose the Extrapolative Correlation Attention (ECA), which incorporates novel, theoretically-motivated mechanisms to improve the PCC optimization and extrapolate beyond the convex hull. Across diverse benchmarks, including challenging homogeneous data setting, ECA consistently breaks the PCC plateau, achieving significant improvements in correlation without compromising MSE performance.

</details>


### [98] [Distribution-Free Sequential Prediction with Abstentions](https://arxiv.org/abs/2602.17918)
*Jialin Yu,Moïse Blanchard*

Main category: cs.LG

TL;DR: 研究在流数据中对抗性注入攻击下的序列预测问题，学习者可以选择弃权以避免被污染实例的惩罚。在未知分布的情况下，提出AbstainBoost算法，为VC类实现分布无关的学习保证。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设学习者已知干净样本的分布μ，这在理论和实践中都是强假设。本文旨在探索在未知分布的情况下，是否能为VC类实现类似的对抗性学习保证，这与经典学习框架（如PAC学习）和其他非独立同分布模型（如平滑在线学习）的标准要求一致。

Method: 提出AbstainBoost算法，基于弱学习器的提升过程。该算法保证在分布无关的弃权学习设置下，对于一般VC类实现次线性误差。对于自适应对手，算法也为结构化函数类（包括线性分类器）提供类似保证。

Result: 算法在分布未知的情况下为VC类实现了对抗性学习保证。同时提供了相应的下界，揭示了误分类错误与错误弃权次数之间有趣的多项式权衡关系。

Conclusion: 在未知分布的情况下，通过AbstainBoost算法可以实现对抗性注入攻击下的有效学习，为VC类提供分布无关的学习保证，填补了现有研究的理论空白。

Abstract: We study a sequential prediction problem in which an adversary is allowed to inject arbitrarily many adversarial instances in a stream of i.i.d.\ instances, but at each round, the learner may also \emph{abstain} from making a prediction without incurring any penalty if the instance was indeed corrupted. This semi-adversarial setting naturally sits between the classical stochastic case with i.i.d.\ instances for which function classes with finite VC dimension are learnable; and the adversarial case with arbitrary instances, known to be significantly more restrictive. For this problem, Goel et al. (2023) showed that, if the learner knows the distribution $μ$ of clean samples in advance, learning can be achieved for all VC classes without restrictions on adversary corruptions. This is, however, a strong assumption in both theory and practice: a natural question is whether similar learning guarantees can be achieved without prior distributional knowledge, as is standard in classical learning frameworks (e.g., PAC learning or asymptotic consistency) and other non-i.i.d.\ models (e.g., smoothed online learning). We therefore focus on the distribution-free setting where $μ$ is \emph{unknown} and propose an algorithm \textsc{AbstainBoost} based on a boosting procedure of weak learners, which guarantees sublinear error for general VC classes in \emph{distribution-free} abstention learning for oblivious adversaries. These algorithms also enjoy similar guarantees for adaptive adversaries, for structured function classes including linear classifiers. These results are complemented with corresponding lower bounds, which reveal an interesting polynomial trade-off between misclassification error and number of erroneous abstentions.

</details>


### [99] [Tighter Regret Lower Bound for Gaussian Process Bandits with Squared Exponential Kernel in Hypersphere](https://arxiv.org/abs/2602.17940)
*Shogo Iwazaki*

Main category: cs.LG

TL;DR: 本文针对高斯过程赌博机问题，在平方指数核函数和超球面输入域下，建立了算法无关的最坏情况遗憾下界，部分解决了维度依赖对数因子的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 高斯过程赌博机问题中，对于平方指数核函数，现有上界和下界在维度依赖的对数因子方面存在差距，这是一个尚未解决的开放性问题。本文旨在在超球面输入域下部分解决这个问题。

Method: 采用算法无关的分析方法，针对平方指数核函数和超球面输入域，建立累积遗憾和简单遗憾的最坏情况下界。同时改进了平方指数核的最大信息增益上界。

Result: 1. 任何算法都遭受Ω(√[T(ln T)^d(ln ln T)^{-d}])的累积遗憾；2. 任何算法需要Ω(ε^{-2}(ln 1/ε)^d(ln ln 1/ε)^{-d})时间步找到ε最优解；3. 改进了平方指数核的最大信息增益上界为O((ln T)^{d+1}(ln ln T)^{-d})。

Conclusion: 在超球面输入域下，本文结果保证了现有最佳算法在维度无关对数因子意义上的最优性，部分解决了维度依赖对数因子的开放性问题。

Abstract: We study an algorithm-independent, worst-case lower bound for the Gaussian process (GP) bandit problem in the frequentist setting, where the reward function is fixed and has a bounded norm in the known reproducing kernel Hilbert space (RKHS). Specifically, we focus on the squared exponential (SE) kernel, one of the most widely used kernel functions in GP bandits. One of the remaining open questions for this problem is the gap in the \emph{dimension-dependent} logarithmic factors between upper and lower bounds. This paper partially resolves this open question under a hyperspherical input domain. We show that any algorithm suffers $Ω(\sqrt{T (\ln T)^{d} (\ln \ln T)^{-d}})$ cumulative regret, where $T$ and $d$ represent the total number of steps and the dimension of the hyperspherical domain, respectively. Regarding the simple regret, we show that any algorithm requires $Ω(ε^{-2}(\ln \frac{1}ε)^d (\ln \ln \frac{1}ε)^{-d})$ time steps to find an $ε$-optimal point. We also provide the improved $O((\ln T)^{d+1}(\ln \ln T)^{-d})$ upper bound on the maximum information gain for the SE kernel. Our results guarantee the optimality of the existing best algorithm up to \emph{dimension-independent} logarithmic factors under a hyperspherical input domain.

</details>


### [100] [Understanding the Generalization of Bilevel Programming in Hyperparameter Optimization: A Tale of Bias-Variance Decomposition](https://arxiv.org/abs/2602.17947)
*Yubo Zhou,Jun Shu,Junmin Liu,Deyu Meng*

Main category: cs.LG

TL;DR: 该论文分析了超参数优化中梯度估计的偏差-方差分解，提出了减少方差的集成策略，并在多个任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的超参数优化方法主要关注估计偏差，而忽略了数据分布导致的方差误差，这影响了性能表现。论文旨在解决超梯度估计中的方差问题。

Method: 1. 对超梯度估计误差进行偏差-方差分解；2. 提出集成超梯度策略来有效减少方差；3. 建立超梯度估计与超额误差之间的联系。

Result: 在正则化超参数学习、数据超清洗和少样本学习等任务上的实验结果表明，方差减少策略改善了超梯度估计，提高了性能。

Conclusion: 通过偏差-方差分解分析超梯度估计误差，提出的集成策略能有效减少方差，为实践中观察到的现象（如验证集过拟合）提供了理论解释。

Abstract: Gradient-based hyperparameter optimization (HPO) have emerged recently, leveraging bilevel programming techniques to optimize hyperparameter by estimating hypergradient w.r.t. validation loss. Nevertheless, previous theoretical works mainly focus on reducing the gap between the estimation and ground-truth (i.e., the bias), while ignoring the error due to data distribution (i.e., the variance), which degrades performance. To address this issue, we conduct a bias-variance decomposition for hypergradient estimation error and provide a supplemental detailed analysis of the variance term ignored by previous works. We also present a comprehensive analysis of the error bounds for hypergradient estimation. This facilitates an easy explanation of some phenomena commonly observed in practice, like overfitting to the validation set. Inspired by the derived theories, we propose an ensemble hypergradient strategy to reduce the variance in HPO algorithms effectively. Experimental results on tasks including regularization hyperparameter learning, data hyper-cleaning, and few-shot learning demonstrate that our variance reduction strategy improves hypergradient estimation. To explain the improved performance, we establish a connection between excess error and hypergradient estimation, offering some understanding of empirical observations.

</details>


### [101] [A Geometric Probe of the Accuracy-Robustness Trade-off: Sharp Boundaries in Symmetry-Breaking Dimensional Expansion](https://arxiv.org/abs/2602.17948)
*Yu Bai,Zhe Wang,Jiarui Zhang,Dong-Xiao Zhang,Yinjun Gao,Jun-Jie Zhang*

Main category: cs.LG

TL;DR: 该研究通过对称性破缺维度扩展(SBDE)探究了深度学习模型准确率与对抗鲁棒性之间的权衡机制。SBDE通过插入恒定像素扩展输入维度，能显著提升干净准确率(如CIFAR-10上从90.47%到95.63%)，但会降低对抗攻击鲁棒性。研究发现脆弱性主要来自插入维度，通过测试时掩码投影可恢复鲁棒性，揭示了准确率提升是通过在辅助轴上创建陡峭边界实现的。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在干净准确率和对抗鲁棒性之间存在普遍权衡现象，但其几何起源尚不明确。本研究旨在通过受控实验探究这种权衡背后的机制。

Method: 采用对称性破缺维度扩展(SBDE)作为受控探针，通过向输入图像插入恒定值像素来打破平移对称性。使用测试时掩码投影技术，将插入的辅助像素重置为训练时的值，以分析脆弱性的来源。

Result: SBDE能显著提升干净准确率(减少参数退化)，但会降低对迭代白盒攻击的鲁棒性。掩码投影能有效中和攻击并恢复鲁棒性，表明脆弱性几乎完全来自插入维度。模型通过沿辅助轴创建陡峭边界(陡峭损失梯度)来实现高准确率。

Conclusion: 研究为准确率-鲁棒性悖论提供了具体的几何解释：优化景观通过加深吸引盆地来提升准确率，但不可避免地沿着辅助自由度建立陡峭墙壁，从而对流形外扰动产生脆弱敏感性。

Abstract: The trade-off between clean accuracy and adversarial robustness is a pervasive phenomenon in deep learning, yet its geometric origin remains elusive. In this work, we utilize Symmetry-Breaking Dimensional Expansion (SBDE) as a controlled probe to investigate the mechanism underlying this trade-off. SBDE expands input images by inserting constant-valued pixels, which breaks translational symmetry and consistently improves clean accuracy (e.g., from $90.47\%$ to $95.63\%$ on CIFAR-10 with ResNet-18) by reducing parameter degeneracy. However, this accuracy gain comes at the cost of reduced robustness against iterative white-box attacks. By employing a test-time \emph{mask projection} that resets the inserted auxiliary pixels to their training values, we demonstrate that the vulnerability stems almost entirely from the inserted dimensions. The projection effectively neutralizes the attacks and restores robustness, revealing that the model achieves high accuracy by creating \emph{sharp boundaries} (steep loss gradients) specifically along the auxiliary axes. Our findings provide a concrete geometric explanation for the accuracy-robustness paradox: the optimization landscape deepens the basin of attraction to improve accuracy but inevitably erects steep walls along the auxiliary degrees of freedom, creating a fragile sensitivity to off-manifold perturbations.

</details>


### [102] [Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2602.18117)
*Yongjae Shin,Jongseong Chae,Jongeui Park,Youngchul Sung*

Main category: cs.LG

TL;DR: FINO是一种基于流匹配的离线到在线强化学习方法，通过注入噪声增强探索，结合熵引导采样平衡探索与利用，在有限在线预算下实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型在离线强化学习中表现出色，但在扩展到在线微调时面临挑战。现有方法通常将在线微调视为离线预训练的直接延续，未能解决关键问题，特别是在探索效率和样本效率方面。

Method: 提出FINO方法：1）使用基于流匹配的策略；2）在策略训练中注入噪声以鼓励超出离线数据集观察范围的行动探索；3）结合熵引导采样机制来平衡探索与利用，使策略能够在在线微调过程中自适应调整行为。

Result: 在多样化的挑战性任务上的实验表明，FINO在有限的在线预算下始终实现优越的性能，证明了其在离线到在线强化学习中的样本效率优势。

Conclusion: FINO通过噪声注入和熵引导采样有效解决了离线到在线强化学习中的探索挑战，为生成模型在在线强化学习中的应用提供了有效方法，在有限在线交互下实现了高性能。

Abstract: Generative models have recently demonstrated remarkable success across diverse domains, motivating their adoption as expressive policies in reinforcement learning (RL). While they have shown strong performance in offline RL, particularly where the target distribution is well defined, their extension to online fine-tuning has largely been treated as a direct continuation of offline pre-training, leaving key challenges unaddressed. In this paper, we propose Flow Matching with Injected Noise for Offline-to-Online RL (FINO), a novel method that leverages flow matching-based policies to enhance sample efficiency for offline-to-online RL. FINO facilitates effective exploration by injecting noise into policy training, thereby encouraging a broader range of actions beyond those observed in the offline dataset. In addition to exploration-enhanced flow policy training, we combine an entropy-guided sampling mechanism to balance exploration and exploitation, allowing the policy to adapt its behavior throughout online fine-tuning. Experiments across diverse, challenging tasks demonstrate that FINO consistently achieves superior performance under limited online budgets.

</details>


### [103] [Bayesian Online Model Selection](https://arxiv.org/abs/2602.17958)
*Aida Afshar,Yuke Zhang,Aldo Pacchiano*

Main category: cs.LG

TL;DR: 该论文提出了一种新的贝叶斯算法，用于解决随机多臂赌博机中的在线模型选择问题，能够在探索多个学习器的同时与最优学习器竞争。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯赌博机中的在线模型选择面临基本探索挑战：当环境实例从先验分布中采样时，如何设计自适应策略来探索多个赌博机学习器，并与事后最佳学习器竞争？

Method: 引入了一种新的贝叶斯算法来处理随机赌博机中的在线模型选择问题，算法能够自适应地探索多个基础学习器。

Result: 证明了贝叶斯遗憾的oracle-style保证为O(d*M√T + √(MT))，其中M是基础学习器数量，d*是最优基础学习器的遗憾系数，T是时间范围。实验验证了该方法在各种随机赌博机设置中具有竞争力。

Conclusion: 提出的贝叶斯算法有效解决了在线模型选择问题，性能可与最佳基础学习器竞争，同时研究了数据共享对缓解先验错误设定的作用。

Abstract: Online model selection in Bayesian bandits raises a fundamental exploration challenge: When an environment instance is sampled from a prior distribution, how can we design an adaptive strategy that explores multiple bandit learners and competes with the best one in hindsight? We address this problem by introducing a new Bayesian algorithm for online model selection in stochastic bandits. We prove an oracle-style guarantee of $O\left( d^* M \sqrt{T} + \sqrt{(MT)} \right)$ on the Bayesian regret, where $M$ is the number of base learners, $d^*$ is the regret coefficient of the optimal base learner, and $T$ is the time horizon. We also validate our method empirically across a range of stochastic bandit settings, demonstrating performance that is competitive with the best base learner. Additionally, we study the effect of sharing data among base learners and its role in mitigating prior mis-specification.

</details>


### [104] [Capabilities Ain't All You Need: Measuring Propensities in AI](https://arxiv.org/abs/2602.18182)
*Daniel Romero-Alvarado,Fernando Martínez-Plumed,Lorenzo Pacchiardi,Hugo Save,Siddhesh Milind Pawar,Behzad Mehrbakhsh,Pablo Antonio Moreno Casares,Ben Slater,Paolo Bova,Peter Romero,Zachary R. Tyler,Jonathan Prunty,Luning Sun,Jose Hernandez-Orallo*

Main category: cs.LG

TL;DR: 论文提出了首个测量AI倾向性的形式化框架，使用双逻辑函数描述模型在"理想区间"内的高成功率，并通过任务无关的评估标准估计理想区间的边界，发现倾向性与能力结合比单独使用任一项能更好地预测AI行为。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估主要关注能力测量，而倾向性（模型展现特定行为的倾向）在决定性能和安全性方面起着核心作用。传统IRT方法不适合测量倾向性，因为倾向性过高或过低都可能存在问题。

Method: 引入首个测量AI倾向性的形式化框架，使用双逻辑函数描述模型成功概率，当模型倾向性处于"理想区间"内时具有高成功率。开发任务无关的评估标准来估计理想区间的边界，并将该框架应用于六个LLM模型家族。

Result: 能够测量倾向性的偏移程度及其对任务的影响；使用一个基准估计的倾向性成功预测了保留任务上的行为；倾向性与能力结合比单独使用任一项具有更强的预测能力。

Conclusion: 该框架展示了如何进行严格的倾向性测量，并证明与仅使用能力评估相比，结合倾向性测量能更好地预测AI行为，为AI评估提供了更全面的方法。

Abstract: AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an "ideal band". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.

</details>


### [105] [LERD: Latent Event-Relational Dynamics for Neurodegenerative Classification](https://arxiv.org/abs/2602.18195)
*Hairong Chen,Yicheng Feng,Ziyu Jia,Samir Bhatt,Hengguan Huang*

Main category: cs.LG

TL;DR: LERD是一个端到端贝叶斯电生理神经动力学系统，直接从多通道EEG推断潜在神经事件及其关系结构，无需事件或交互标注，在阿尔茨海默病诊断中表现优异。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病改变脑电生理并破坏多通道EEG动力学，现有方法大多依赖黑盒分类器，没有明确建模生成观察信号的基础动力学，需要更准确且临床有用的EEG诊断方法。

Method: 提出LERD系统，结合连续时间事件推断模块和随机事件生成过程来捕捉灵活的时间模式，同时引入电生理启发的动力学先验来指导学习，并提供理论分析确保训练可处理性和稳定性保证。

Result: 在合成基准和两个真实世界AD EEG队列上的实验表明，LERD始终优于强基线方法，并产生与生理对齐的潜在摘要，有助于表征群体水平的动力学差异。

Conclusion: LERD提供了一种从多通道EEG推断神经事件和关系结构的有效方法，为阿尔茨海默病的EEG诊断提供了更准确、可解释的解决方案，有助于疾病监测和筛查。

Abstract: Alzheimer's disease (AD) alters brain electrophysiology and disrupts multichannel EEG dynamics, making accurate and clinically useful EEG-based diagnosis increasingly important for screening and disease monitoring. However, many existing approaches rely on black-box classifiers and do not explicitly model the underlying dynamics that generate observed signals. To address these limitations, we propose LERD, an end-to-end Bayesian electrophysiological neural dynamical system that infers latent neural events and their relational structure directly from multichannel EEG without event or interaction annotations. LERD combines a continuous-time event inference module with a stochastic event-generation process to capture flexible temporal patterns, while incorporating an electrophysiology-inspired dynamical prior to guide learning in a principled way. We further provide theoretical analysis that yields a tractable bound for training and stability guarantees for the inferred relational dynamics. Extensive experiments on synthetic benchmarks and two real-world AD EEG cohorts demonstrate that LERD consistently outperforms strong baselines and yields physiology-aligned latent summaries that help characterize group-level dynamical differences.

</details>


### [106] [[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games](https://arxiv.org/abs/2602.18230)
*Jorge Carrasco Pollo,Ioannis Kapetangeorgis,Joshua Rosenthal,John Hua Yao*

Main category: cs.LG

TL;DR: 该研究对Abdelnabi等人(2024)提出的基于可评分游戏的LLM多智能体谈判基准进行了可复现性分析，发现基准虽然复杂但模型比较存在模糊性，实验设置存在信息泄露检测不足等局限性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在多智能体谈判任务中表现出潜力，但缺乏稳健且可泛化的评估基准。Abdelnabi等人(2024)提出了基于可评分游戏的谈判基准，本研究旨在验证该基准的可复现性，并深入理解其可用性和泛化能力。

Method: 1. 复现原始实验并在更多模型上进行测试；2. 引入额外指标验证谈判质量和评估公平性；3. 在扩展版基准上分析更广泛模型的行为；4. 识别实验设置的局限性，特别是信息泄露检测和消融研究的完整性。

Result: 研究发现：1. 基准确实复杂，但模型比较存在模糊性，对其客观性提出质疑；2. 实验设置存在局限性，特别是信息泄露检测不足和消融研究不够彻底；3. 通过分析更广泛模型在扩展基准上的表现，为潜在用户提供了额外背景信息。

Conclusion: 研究结果强调了上下文在模型比较评估中的重要性，为谈判基准的改进提供了见解，并揭示了当前评估框架在客观性和全面性方面的不足。

Abstract: Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability and generalizability. We replicate the original experiments on additional models, and introduce additional metrics to verify negotiation quality and evenness of evaluation. Our findings reveal that while the benchmark is indeed complex, model comparison is ambiguous, raising questions about its objectivity. Furthermore, we identify limitations in the experimental setup, particularly in information leakage detection and thoroughness of the ablation study. By examining and analyzing the behavior of a wider range of models on an extended version of the benchmark, we reveal insights that provide additional context to potential users. Our results highlight the importance of context in model-comparative evaluations.

</details>


### [107] [Asynchronous Heavy-Tailed Optimization](https://arxiv.org/abs/2602.18002)
*Junfei Sun,Dixi Yao,Xuchen Gong,Tahseen Rabbani,Manzil Zaheer,Tian Li*

Main category: cs.LG

TL;DR: 本文研究了重尾随机梯度噪声下的异步优化问题，提出了基于延迟感知学习率调度和延迟补偿的算法改进，在图像和语言任务中表现出更好的精度/运行时间权衡和超参数鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 重尾随机梯度噪声在Transformer模型中常见，会破坏优化过程的稳定性。现有研究主要关注集中式或分布式同步设置下的重尾噪声处理，而重尾噪声与异步优化之间的相互作用尚未充分探索。

Method: 提出了两种处理异步更新中掉队者的通信方案，基于延迟感知学习率调度和延迟补偿进行算法改进，并进行了理论分析。

Result: 在重尾噪声下的收敛保证与同步对应方法的速率相匹配，相比现有异步方法提高了延迟容忍度。在图像和语言任务中，提出的方法在精度/运行时间权衡和超参数鲁棒性方面优于先前的同步和异步方法。

Conclusion: 通过延迟感知学习率调度和延迟补偿的算法改进，可以有效处理重尾噪声下的异步优化问题，提高异步算法的性能和鲁棒性。

Abstract: Heavy-tailed stochastic gradient noise, commonly observed in transformer models, can destabilize the optimization process. Recent works mainly focus on developing and understanding approaches to address heavy-tailed noise in the centralized or distributed, synchronous setting, leaving the interactions between such noise and asynchronous optimization underexplored. In this work, we investigate two communication schemes that handle stragglers with asynchronous updates in the presence of heavy-tailed gradient noise. We propose and theoretically analyze algorithmic modifications based on delay-aware learning rate scheduling and delay compensation to enhance the performance of asynchronous algorithms. Our convergence guarantees under heavy-tailed noise match the rate of the synchronous counterparts and improve delay tolerance compared with existing asynchronous approaches. Empirically, our approaches outperform prior synchronous and asynchronous methods in terms of accuracy/runtime trade-offs and are more robust to hyperparameters in both image and language tasks.

</details>


### [108] [Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers](https://arxiv.org/abs/2602.18292)
*Xiaotong Ji,Rasul Tutunov,Matthieu Zimmer,Haitham Bou-Ammar*

Main category: cs.LG

TL;DR: 论文提出将解码视为一个原则性的优化层，通过正则化问题统一现有解码方法，并设计了新的Best-of-K解码器来提升多样本管道的性能。


<details>
  <summary>Details</summary>
Motivation: 当前解码方法被视为启发式的调参过程，缺乏理论框架。作者认为解码应该被理解为原则性的优化层，能够统一解释现有方法并便于设计新的解码器。

Method: 将解码建模为在每个token上求解正则化概率单纯形优化问题，平衡模型分数与结构偏好/约束。该框架统一了贪婪解码、Softmax采样、Top-K、Top-P和Sparsemax等方法，并基于此设计了Best-of-K解码器，针对K样本预算下的覆盖率优化。

Result: Best-of-K解码器在数学推理任务上显著提升性能，例如Qwen2.5-Math-7B在MATH500数据集上在高采样温度下准确率提升+18.6%。

Conclusion: 解码应该被视为原则性的优化层而非启发式调参，提出的统一框架不仅解释了现有方法，还便于设计新的解码器如Best-of-K，显著提升了多样本管道的性能。

Abstract: Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.

</details>


### [109] [JPmHC Dynamical Isometry via Orthogonal Hyper-Connections](https://arxiv.org/abs/2602.18308)
*Biswa Sengupta,Jinhua Wang,Leo Brunswic*

Main category: cs.LG

TL;DR: JPmHC框架通过可训练的线性混合器替代恒等跳跃连接，在保持梯度谱特性的同时解决超连接架构的训练不稳定性和内存开销问题。


<details>
  <summary>Details</summary>
Motivation: 超连接等深度学习方法扩展了残差连接范式，但破坏了恒等映射特性，导致训练不稳定、可扩展性受限和内存开销增加。

Method: 提出JPmHC框架，用可训练的线性混合器替代恒等跳跃，通过算子范数有界流形约束混合器，防止梯度病理并增强稳定性。包括自由概率分析预测雅可比谱、内存高效的隐式微分、以及通过Cayley变换的Stiefel约束混合器。

Result: 在ARC-AGI上的实验表明，JPmHC相比双随机基线实现了更快的收敛速度、更高的准确率和更低的计算成本。

Conclusion: JPmHC作为HC的灵活可扩展扩展，推进了谱感知、稳定且高效的深度学习，为拓扑架构设计和基础模型演进提供了见解。

Abstract: Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.

</details>


### [110] [Continual-NExT: A Unified Comprehension And Generation Continual Learning Framework](https://arxiv.org/abs/2602.18055)
*Jingyang Qiao,Zhizhong Zhang,Xin Tan,Jingyu Gong,Yanyun Qu,Yuan Xie*

Main category: cs.LG

TL;DR: 本文提出了Continual-NExT框架和MAGE方法，用于解决双模态MLLMs在持续学习中的遗忘、幻觉、指令不遵循和跨模态知识迁移失败等问题。


<details>
  <summary>Details</summary>
Motivation: 双模态MLLMs虽然具有强大的即时学习和泛化能力，但在终身演化方面存在缺陷，难以适应动态现实场景。现有研究缺乏标准化的持续学习框架，且面临灾难性遗忘、幻觉、指令不遵循和跨模态知识迁移失败等挑战。

Method: 提出了Continual-NExT持续学习框架，并设计了MAGE方法（通用LoRA和专家LoRA的混合与聚合），以促进跨模态知识迁移并减轻遗忘。

Result: 大量实验表明，MAGE方法优于其他持续学习方法，并实现了最先进的性能。

Conclusion: 本文建立的Continual-NExT框架和提出的MAGE方法有效提升了双模态MLLMs的持续学习能力，解决了现有挑战。

Abstract: Dual-to-Dual MLLMs refer to Multimodal Large Language Models, which can enable unified multimodal comprehension and generation through text and image modalities. Although exhibiting strong instantaneous learning and generalization capabilities, Dual-to-Dual MLLMs still remain deficient in lifelong evolution, significantly affecting continual adaptation to dynamic real-world scenarios. One of the challenges is that learning new tasks inevitably destroys the learned knowledge. Beyond traditional catastrophic forgetting, Dual-to-Dual MLLMs face other challenges, including hallucination, instruction unfollowing, and failures in cross-modal knowledge transfer. However, no standardized continual learning framework for Dual-to-Dual MLLMs has been established yet, leaving these challenges unexplored. Thus, in this paper, we establish Continual-NExT, a continual learning framework for Dual-to-Dual MLLMs with deliberately-architected evaluation metrics. To improve the continual learning capability of Dual-to-Dual MLLMs, we propose an efficient MAGE (Mixture and Aggregation of General LoRA and Expert LoRA) method to further facilitate knowledge transfer across modalities and mitigate forgetting. Extensive experiments demonstrate that MAGE outperforms other continual learning methods and achieves state-of-the-art performance.

</details>


### [111] [Balancing Symmetry and Efficiency in Graph Flow Matching](https://arxiv.org/abs/2602.18084)
*Benjamin Honoré,Alba Carballo-Castro,Yiming Qin,Pascal Frossard*

Main category: cs.LG

TL;DR: 该研究探讨了图生成模型中严格等变性的权衡问题，提出通过可控对称性调制方案来放松等变性，以加速训练收敛并防止过拟合。


<details>
  <summary>Details</summary>
Motivation: 严格的等变性虽然能确保模型尊重图的置换对称性，但会增加计算成本并减缓收敛速度，因为模型必须在大量可能的节点置换中保持一致。研究者希望探索这种权衡，找到平衡等变性和训练效率的方法。

Method: 从等变离散流匹配模型出发，通过基于正弦位置编码和节点置换的可控对称性调制方案，在训练过程中放松模型的等变性。这种方案允许有控制地打破对称性。

Result: 实验表明：1）对称性打破可以加速早期训练，提供更简单的学习信号；2）但可能导致捷径解和过拟合，使模型重复生成训练集中的图；3）适当调制对称性信号可以延迟过拟合同时加速收敛，使模型仅用基线训练轮数的19%就能达到更强的性能。

Conclusion: 在图生成模型中，严格等变性并非总是最优选择。通过可控对称性调制放松等变性，可以在保持模型性能的同时显著加速训练收敛，避免过拟合问题，实现更好的训练效率与泛化能力的平衡。

Abstract: Equivariance is central to graph generative models, as it ensures the model respects the permutation symmetry of graphs. However, strict equivariance can increase computational cost due to added architectural constraints, and can slow down convergence because the model must be consistent across a large space of possible node permutations. We study this trade-off for graph generative models. Specifically, we start from an equivariant discrete flow-matching model, and relax its equivariance during training via a controllable symmetry modulation scheme based on sinusoidal positional encodings and node permutations. Experiments first show that symmetry-breaking can accelerate early training by providing an easier learning signal, but at the expense of encouraging shortcut solutions that can cause overfitting, where the model repeatedly generates graphs that are duplicates of the training set. On the contrary, properly modulating the symmetry signal can delay overfitting while accelerating convergence, allowing the model to reach stronger performance with $19\%$ of the baseline training epochs.

</details>


### [112] [FedZMG: Efficient Client-Side Optimization in Federated Learning](https://arxiv.org/abs/2602.18384)
*Fotios Zantalis,Evangelos Zervas,Grigorios Koulouras*

Main category: cs.LG

TL;DR: FedZMG是一种用于联邦学习的客户端优化算法，通过将梯度投影到零均值超平面来减少客户端漂移，无需额外通信或超参数调优，在非IID数据上表现优于FedAvg和FedAdam。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据通常是非独立同分布的，这会导致客户端漂移问题，降低收敛速度和模型性能。现有的自适应优化器虽然能缓解这一问题，但往往引入计算复杂度或通信开销，不适合资源受限的物联网环境。

Method: 提出联邦零均值梯度算法，将局部梯度投影到零均值超平面上，有效中和异构数据分布中的"强度"或"偏置"偏移。该方法基于梯度中心化思想，无需额外通信或超参数调优。

Result: 理论分析证明FedZMG能减少有效梯度方差并提供更紧的收敛边界。在EMNIST、CIFAR100和Shakespeare数据集上的实验表明，FedZMG在高度非IID设置下比FedAvg和FedAdam具有更好的收敛速度和最终验证准确率。

Conclusion: FedZMG是一种参数免费、客户端侧的优化算法，能有效解决联邦学习中的客户端漂移问题，特别适合资源受限的物联网环境，在异构数据分布下表现出优越性能。

Abstract: Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the "intensity" or "bias" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.

</details>


### [113] [TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs](https://arxiv.org/abs/2602.18109)
*Rong Fu,Yibo Meng,Guangzhen Yao,Jiaxuan Lu,Zeyu Zhang,Zhaolu Kang,Ziming Guo,Jia Yee Tan,Xiaojing Du,Simon James Fong*

Main category: cs.LG

TL;DR: TempoNet是一个基于强化学习的实时调度器，使用Transformer架构和深度Q近似，通过紧急令牌化器处理时间松弛，采用延迟感知稀疏注意力实现高效推理，在多核处理器上实现优于传统调度器的截止时间满足率。


<details>
  <summary>Details</summary>
Motivation: 实时调度器需要在严格的计算预算下处理紧截止时间，传统调度方法在处理复杂实时任务集时存在局限性，需要更智能、高效的调度解决方案。

Method: 1. 使用紧急令牌化器将时间松弛离散化为可学习嵌入；2. 采用置换不变Transformer与深度Q近似配对；3. 使用延迟感知稀疏注意力堆栈，包含块状top-k选择和局部敏感分块；4. 多核映射层通过掩码贪婪选择或可微分匹配将Q分数转换为处理器分配。

Result: 在工业混合关键性追踪和大规模多处理器设置上的评估显示，相比分析调度器和神经基线，TempoNet在截止时间满足率方面获得一致提升，同时改善了优化稳定性，推理延迟低于毫秒级。

Conclusion: TempoNet为基于Transformer的高吞吐量实时调度决策提供了一个实用框架，展示了在复杂实时系统中的有效性和效率。

Abstract: Real-time schedulers must reason about tight deadlines under strict compute budgets. We present TempoNet, a reinforcement learning scheduler that pairs a permutation-invariant Transformer with a deep Q-approximation. An Urgency Tokenizer discretizes temporal slack into learnable embeddings, stabilizing value learning and capturing deadline proximity. A latency-aware sparse attention stack with blockwise top-k selection and locality-sensitive chunking enables global reasoning over unordered task sets with near-linear scaling and sub-millisecond inference. A multicore mapping layer converts contextualized Q-scores into processor assignments through masked-greedy selection or differentiable matching. Extensive evaluations on industrial mixed-criticality traces and large multiprocessor settings show consistent gains in deadline fulfillment over analytic schedulers and neural baselines, together with improved optimization stability. Diagnostics include sensitivity analyses for slack quantization, attention-driven policy interpretation, hardware-in-the-loop and kernel micro-benchmarks, and robustness under stress with simple runtime mitigations; we also report sample-efficiency benefits from behavioral-cloning pretraining and compatibility with an actor-critic variant without altering the inference pipeline. These results establish a practical framework for Transformer-based decision making in high-throughput real-time scheduling.

</details>


### [114] [Non-Stationary Online Resource Allocation: Learning from a Single Sample](https://arxiv.org/abs/2602.18114)
*Yiding Feng,Jiashuo Jiang,Yige Wang*

Main category: cs.LG

TL;DR: 研究非平稳需求下的在线资源分配问题，仅需每个周期一个历史样本，提出基于分位数的元策略，在两种样本信息度下分别实现次线性遗憾和对数遗憾


<details>
  <summary>Details</summary>
Motivation: 解决实际应用中资源分配面临的两个关键挑战：需求分布的非平稳性和离线数据稀缺。传统方法通常需要大量历史数据或假设平稳环境，而现实场景中需求模式可能任意变化且历史数据有限

Method: 提出类型依赖的分位数元策略，将问题解耦为三个模块：奖励分布估计、通过流体松弛优化目标服务概率、通过动态接受阈值进行实时决策。针对奖励可观测样本设计静态阈值策略，针对仅类型样本设计部分自适应和完全自适应策略

Result: 对于奖励可观测样本，静态阈值策略达到$\tilde{O}(\sqrt{T})$遗憾；对于仅类型样本，在最小到达概率假设下，部分自适应策略达到$\tilde{O}(\sqrt{T})$遗憾，完全自适应策略首次实现$O((\log T)^3)$的多对数遗憾保证

Conclusion: 该框架在仅需每个周期一个样本的极小离线数据要求下，处理任意非平稳性而不需要变化预算假设，支持多资源约束，显著推进了非平稳多资源分配的理论边界

Abstract: We study online resource allocation under non-stationary demand with a minimum offline data requirement. In this problem, a decision-maker must allocate multiple types of resources to sequentially arriving queries over a finite horizon. Each query belongs to a finite set of types with fixed resource consumption and a stochastic reward drawn from an unknown, type-specific distribution. Critically, the environment exhibits arbitrary non-stationarity -- arrival distributions may shift unpredictably-while the algorithm requires only one historical sample per period to operate effectively. We distinguish two settings based on sample informativeness: (i) reward-observed samples containing both query type and reward realization, and (ii) the more challenging type-only samples revealing only query type information.
  We propose a novel type-dependent quantile-based meta-policy that decouples the problem into modular components: reward distribution estimation, optimization of target service probabilities via fluid relaxation, and real-time decisions through dynamic acceptance thresholds. For reward-observed samples, our static threshold policy achieves $\tilde{O}(\sqrt{T})$ regret. For type-only samples, we first establish that sublinear regret is impossible without additional structure; under a mild minimum-arrival-probability assumption, we design both a partially adaptive policy attaining the same $\tilde{O}({T})$ bound and, more significantly, a fully adaptive resolving policy with careful rounding that achieves the first poly-logarithmic regret guarantee of $O((\log T)^3)$ for non-stationary multi-resource allocation. Our framework advances prior work by operating with minimal offline data (one sample per period), handling arbitrary non-stationarity without variation-budget assumptions, and supporting multiple resource constraints.

</details>


### [115] [RAT+: Train Dense, Infer Sparse -- Recurrence Augmented Attention for Dilated Inference](https://arxiv.org/abs/2602.18196)
*Xiuying Wei,Caglar Gulcehre*

Main category: cs.LG

TL;DR: RAT+是一种通过密集预训练结合全序列循环和主动循环学习的注意力架构，可在推理时灵活切换到扩张注意力模式，无需重新训练稀疏模型，在保持准确性的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 结构化扩张注意力在推理时具有效率优势，但将预训练注意力模型稀疏化为扩张模式会导致严重的准确性下降。需要一种既能保持密集预训练优势，又能在推理时灵活切换为高效稀疏模式的解决方案。

Method: RAT+架构通过全序列循环增强注意力，并采用主动循环学习。模型只需进行一次密集预训练，推理时可灵活切换到扩张注意力模式（可选带局部窗口）或混合层/头组合，仅需少量token的适应性调整而非重新训练。

Result: 在1.5B参数、100B token训练下，RAT+在16倍扩张时接近密集注意力准确性，64倍扩张时在常识推理和LongBench任务上仅下降2-3个点。此外，RAT+在稀疏化为top-k块注意力时优于普通注意力。在2.6B参数、200B token规模下观察到相同趋势。

Conclusion: RAT+提供了一种有效的解决方案，通过单一密集预训练模型实现推理时灵活的效率-准确性权衡，避免了为不同稀疏模式重新训练多个模型的开销，在保持性能的同时显著提升推理效率。

Abstract: Structured dilated attention has an appealing inference-time efficiency knob: it reduces the FLOPs of the attention and the KV cache size by a factor of the dilation size D, while preserving long-range connectivity. However, we find a persistent failure mode of them -- sparsifying a pretrained attention model to a dilated pattern leads to severe accuracy degradation. We introduce RAT+, a dense-pretraining architecture that augments attention with full-sequence recurrence and active recurrence learning. A single RAT+ model is pretrained densely once, then flexibly switched at inference time to dilated attention (optionally with local windows) or hybrid layer/head compositions, requiring only a short 1B-token resolution adaptation rather than retraining separate sparse models. At 1.5B parameters trained on 100B tokens, RAT+ closely matches dense accuracy at 16 and drops by about 2-3 points at 64 on commonsense reasoning and LongBench tasks, respectively. Moreover, RAT+ outperforms attention when sparsifying to the top-k block attention. We further scale to 2.6B parameters and 200B tokens and observe the same trend.

</details>


### [116] [Neural-HSS: Hierarchical Semi-Separable Neural PDE Solver](https://arxiv.org/abs/2602.18248)
*Pietro Sittoni,Emanuele Zangrando,Angelo A. Casulli,Nicola Guglielmi,Francesco Tudisco*

Main category: cs.LG

TL;DR: Neural-HSS：基于分层半可分矩阵结构的高效参数架构，用于解决PDE问题，在低数据量下具有数据高效性和理论保证


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在求解PDE方面表现出色，但大规模高质量数据集生成和模型训练的计算成本仍然很高，限制了关键应用的发展。需要一种在低数据量下仍然高效的方法。

Method: 受椭圆PDE格林函数结构研究启发，提出Neural-HSS架构，基于分层半可分矩阵结构，具有参数高效性。理论分析证明其在低数据量下的精确性，并探索其与傅里叶神经算子层和卷积层等架构原语的联系。

Result: 在200万网格点的三维泊松方程上实验验证了Neural-HSS的数据高效性，在低数据量下优于基线方法。同时展示了其在电磁学、流体动力学和生物学等多个领域PDE数据学习的能力。

Conclusion: Neural-HSS为广泛PDE类提供了一种数据高效的深度学习架构，具有理论保证和实际应用价值，能够有效解决大规模PDE模拟中的计算成本问题。

Abstract: Deep learning-based methods have shown remarkable effectiveness in solving PDEs, largely due to their ability to enable fast simulations once trained. However, despite the availability of high-performance computing infrastructure, many critical applications remain constrained by the substantial computational costs associated with generating large-scale, high-quality datasets and training models. In this work, inspired by studies on the structure of Green's functions for elliptic PDEs, we introduce Neural-HSS, a parameter-efficient architecture built upon the Hierarchical Semi-Separable (HSS) matrix structure that is provably data-efficient for a broad class of PDEs. We theoretically analyze the proposed architecture, proving that it satisfies exactness properties even in very low-data regimes. We also investigate its connections with other architectural primitives, such as the Fourier neural operator layer and convolutional layers. We experimentally validate the data efficiency of Neural-HSS on the three-dimensional Poisson equation over a grid of two million points, demonstrating its superior ability to learn from data generated by elliptic PDEs in the low-data regime while outperforming baseline methods. Finally, we demonstrate its capability to learn from data arising from a broad class of PDEs in diverse domains, including electromagnetism, fluid dynamics, and biology.

</details>


### [117] [Variational Distributional Neuron](https://arxiv.org/abs/2602.18250)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 提出变分分布神经元的证明概念：将神经元构建为VAE模块，包含先验、摊销后验和局部ELBO，使神经元从确定性标量变为分布，计算变为在约束下收缩可能性空间


<details>
  <summary>Details</summary>
Motivation: 解决结构张力：在序列生成中，因果性主要在符号空间组织，潜在变量常为辅助；而概率潜在模型捕获变化因素和不确定性，但不确定性通常由全局或参数机制承载，神经元仍传播标量。核心问题：如果不确定性是计算的内在属性，为何计算单元不显式承载它？

Method: 提出变分分布神经元：每个神经元参数化后验分布，传播重参数化样本，通过局部ELBO的KL项正则化。分析"崩溃"模式和"活神经元"条件，通过自回归先验在时间上扩展贡献

Result: 提出概念证明，展示神经元如何从确定性标量转变为分布单元，使"收缩"可通过局部约束测试并通过内部度量监控。单元携带的上下文信息量及其时间持续性可通过不同约束局部调整

Conclusion: 提出两个轴线：(i)概率约束的组合必须稳定、可解释和可控；(ii)粒度问题：如果推理是在约束下分布的协商，原始单元应保持确定性还是变为分布性？为分布计算单元提供了理论基础

Abstract: We propose a proof of concept for a variational distributional neuron: a compute unit formulated as a VAE brick, explicitly carrying a prior, an amortized posterior and a local ELBO. The unit is no longer a deterministic scalar but a distribution: computing is no longer about propagating values, but about contracting a continuous space of possibilities under constraints. Each neuron parameterizes a posterior, propagates a reparameterized sample and is regularized by the KL term of a local ELBO - hence, the activation is distributional. This "contraction" becomes testable through local constraints and can be monitored via internal measures. The amount of contextual information carried by the unit, as well as the temporal persistence of this information, are locally tuned by distinct constraints. This proposal addresses a structural tension: in sequential generation, causality is predominantly organized in the symbolic space and, even when latents exist, they often remain auxiliary, while the effective dynamics are carried by a largely deterministic decoder. In parallel, probabilistic latent models capture factors of variation and uncertainty, but that uncertainty typically remains borne by global or parametric mechanisms, while units continue to propagate scalars - hence the pivot question: if uncertainty is intrinsic to computation, why does the compute unit not carry it explicitly? We therefore draw two axes: (i) the composition of probabilistic constraints, which must be made stable, interpretable and controllable; and (ii) granularity: if inference is a negotiation of distributions under constraints, should the primitive unit remain deterministic or become distributional? We analyze "collapse" modes and the conditions for a "living neuron", then extend the contribution over time via autoregressive priors over the latent, per unit.

</details>


### [118] [MEG-to-MEG Transfer Learning and Cross-Task Speech/Silence Detection with Limited Data](https://arxiv.org/abs/2602.18253)
*Xabier de Zuazo,Vincenzo Verbeni,Eva Navas,Ibon Saratxaga,Mathieu Bourguignon,Nicola Molinaro*

Main category: cs.LG

TL;DR: 该研究首次展示了MEG语音模型的迁移学习和跨任务解码，通过在50小时单被试听力数据上预训练Conformer模型，然后在18名被试每人仅5分钟数据上微调，实现了感知与产生任务间的有效解码。


<details>
  <summary>Details</summary>
Motivation: 解决语音脑机接口中的数据效率问题，探索感知与产生任务间的神经表征共享机制，验证预训练模型能否在有限数据下实现跨任务解码。

Method: 使用Conformer架构，先在50小时单被试听力数据上预训练，然后在18名被试每人仅5分钟数据上进行微调，评估感知（被动听）与产生（语音产生）任务间的迁移学习和跨任务解码性能。

Result: 迁移学习带来一致改进：任务内准确率提升1-4%，跨任务准确率提升达5-6%。预训练不仅提升各任务性能，还实现了感知与产生任务间的可靠跨任务解码。关键发现：语音产生任务训练的模型能够解码被动听力数据，表明学习到的表征反映了共享神经过程而非任务特异性运动活动。

Conclusion: 该研究证明了MEG语音模型中迁移学习和跨任务解码的可行性，预训练显著提升数据效率，且学习到的神经表征反映了感知与产生任务间的共享机制，为高效语音脑机接口开发提供了重要基础。

Abstract: Data-efficient neural decoding is a central challenge for speech brain-computer interfaces. We present the first demonstration of transfer learning and cross-task decoding for MEG-based speech models spanning perception and production. We pre-train a Conformer-based model on 50 hours of single-subject listening data and fine-tune on just 5 minutes per subject across 18 participants. Transfer learning yields consistent improvements, with in-task accuracy gains of 1-4% and larger cross-task gains of up to 5-6%. Not only does pre-training improve performance within each task, but it also enables reliable cross-task decoding between perception and production. Critically, models trained on speech production decode passive listening above chance, confirming that learned representations reflect shared neural processes rather than task-specific motor activity.

</details>


### [119] [Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering](https://arxiv.org/abs/2602.18348)
*Matheus Camilo da Silva,Leonardo Arrighi,Ana Carolina Lorena,Sylvio Barbon Junior*

Main category: cs.LG

TL;DR: 该研究调查了AutoClustering中元模型的可解释性，通过分析22种现有方法的元特征，应用全局和局部可解释性技术来揭示元特征对聚类算法选择的影响，为更透明的AutoML设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 当前AutoClustering系统虽然性能良好，但其推荐结果难以解释：数据集元特征对算法和超参数选择的影响通常不透明，这限制了可靠性、偏差诊断和高效的元特征工程，需要提高无监督学习自动化的决策透明度。

Method: 1. 回顾22种现有方法并将其元特征组织成结构化分类法；2. 应用全局可解释性技术（决策谓词图）评估元模型中特征的重要性；3. 使用局部可解释性工具（如SHAP）分析特定的聚类决策。

Result: 研究发现元特征相关性存在一致模式，识别出当前元学习策略中的结构弱点（可能扭曲推荐结果），并为更可解释的AutoML设计提供了可操作的指导。

Conclusion: 该研究为提高无监督学习自动化中的决策透明度提供了实践基础，通过揭示元特征对聚类决策的影响机制，有助于构建更可靠、可解释的AutoClustering系统。

Abstract: AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.

</details>


### [120] [Assigning Confidence: K-partition Ensembles](https://arxiv.org/abs/2602.18435)
*Aggelos Semoglou,John Pavlopoulos*

Main category: cs.LG

TL;DR: CAKE框架通过聚类集成计算分配稳定性和局部几何拟合一致性，为每个点提供[0,1]置信度评分，识别模糊点和稳定核心成员


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法无法评估单个分配的可信度，诊断指标仅反映全局质量，而初始化敏感的算法（如k-means）存在分配级不稳定性，影响准确性和鲁棒性

Method: 提出CAKE框架，通过聚类集成计算两个互补统计量：分配稳定性（跨运行一致性）和局部几何拟合一致性（学习到的聚类结构支持），结合为[0,1]可解释评分

Result: 理论分析表明CAKE在噪声下仍有效，能区分稳定和不稳定点；合成和真实数据集实验显示CAKE能有效识别模糊点和稳定核心成员，提供置信度排序指导过滤或优先级设置

Conclusion: CAKE为聚类分配提供点级置信度量化，结合集成一致性和几何支持，提升聚类质量评估和决策支持能力

Abstract: Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [121] [When & How to Write for Personalized Demand-aware Query Rewriting in Video Search](https://arxiv.org/abs/2602.17667)
*Cheng cheng,Chenxing Wang,Aolin Li,Haijun Wu,Huiyun Hu,Juyuan Wang*

Main category: cs.IR

TL;DR: WeWrite是一个个性化需求感知查询重写框架，通过自动化挖掘策略、混合训练范式和并行架构解决视频搜索中用户历史行为利用的挑战，显著提升点击率和降低查询重构率。


<details>
  <summary>Details</summary>
Motivation: 传统方法利用隐式历史特征时存在信号稀释和延迟反馈问题，需要更有效地利用用户历史行为来识别搜索意图和解决歧义。

Method: 提出WeWrite框架，包含三个关键部分：1) 基于后验的自动化挖掘策略确定何时需要个性化重写；2) 结合监督微调和组相对策略优化的混合训练范式；3) 并行"假召回"架构确保低延迟部署。

Result: 在大规模视频平台上的在线A/B测试显示，WeWrite将点击率（VV>10s）提升了1.07%，查询重构率降低了2.97%。

Conclusion: WeWrite框架有效解决了视频搜索中个性化查询重写的关键挑战，通过系统化的方法显著提升了搜索效果和用户体验。

Abstract: In video search systems, user historical behaviors provide rich context for identifying search intent and resolving ambiguity. However, traditional methods utilizing implicit history features often suffer from signal dilution and delayed feedback. To address these challenges, we propose WeWrite, a novel Personalized Demand-aware Query Rewriting framework. Specifically, WeWrite tackles three key challenges: (1) When to Write: An automated posterior-based mining strategy extracts high-quality samples from user logs, identifying scenarios where personalization is strictly necessary; (2) How to Write: A hybrid training paradigm combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to align the LLM's output style with the retrieval system; (3) Deployment: A parallel "Fake Recall" architecture ensures low latency. Online A/B testing on a large-scale video platform demonstrates that WeWrite improves the Click-Through Video Volume (VV$>$10s) by 1.07% and reduces the Query Reformulation Rate by 2.97%.

</details>


### [122] [IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering](https://arxiv.org/abs/2602.17687)
*Connor Shorten,Augustas Skaburskas,Daniel M. Jones,Charles Pierse,Roberto Esposito,John Trengrove,Etienne Dilocker,Bob van Luijt*

Main category: cs.IR

TL;DR: IRPAPERS基准测试比较了基于图像和基于文本的文档检索与问答系统，发现两种模态具有互补性，多模态混合搜索优于单一模态方法。


<details>
  <summary>Details</summary>
Motivation: 虽然AI在文本和关系数据处理方面取得了显著成功，但视觉文档处理仍相对未被充分探索。传统系统需要OCR转录将视觉文档转换为文本和元数据，而多模态基础模型的发展使得直接从文档图像进行检索和生成成为可能。这引发了一个关键问题：基于图像的系统与成熟的基于文本方法相比如何？

Method: 引入IRPAPERS基准测试，包含166篇科学论文的3,230个页面，每个页面都有图像和OCR转录。使用180个"大海捞针"式问题，比较基于图像和基于文本的检索与问答系统。评估了多种检索方法（Arctic 2.0嵌入、BM25、混合文本搜索）和图像嵌入模型，并分析了效率-性能权衡。

Result: 文本检索达到46% Recall@1、78% Recall@5、91% Recall@20；图像检索达到43%、78%、93%。两种模态表现出互补的失败模式，多模态混合搜索优于任一单一模态（49% Recall@1、81% Recall@5、95% Recall@20）。Cohere Embed v4图像嵌入在所有测试模型中表现最佳（58% Recall@1、87% Recall@5、97% Recall@20）。在问答方面，基于文本的RAG系统比基于图像的系统具有更高的真实对齐度（0.82 vs. 0.71）。

Conclusion: 基于图像和基于文本的文档处理系统各有优势且具有互补性，多模态混合方法能够超越单一模态系统。研究识别了需要特定模态的问题类型，并提供了公开可用的数据集和实验代码，为视觉文档处理研究提供了重要基准。

Abstract: AI systems have achieved remarkable success in processing text and relational data, yet visual document processing remains relatively underexplored. Whereas traditional systems require OCR transcriptions to convert these visual documents into text and metadata, recent advances in multimodal foundation models offer retrieval and generation directly from document images. This raises a key question: How do image-based systems compare to established text-based methods? We introduce IRPAPERS, a benchmark of 3,230 pages from 166 scientific papers, with both an image and an OCR transcription for each page. Using 180 needle-in-the-haystack questions, we compare image- and text-based retrieval and question answering systems. Text retrieval using Arctic 2.0 embeddings, BM25, and hybrid text search achieved 46% Recall@1, 78% Recall@5, and 91% Recall@20, while image-based retrieval reaches 43%, 78%, and 93%, respectively. The two modalities exhibit complementary failures, enabling multimodal hybrid search to outperform either alone, achieving 49% Recall@1, 81% Recall@5, and 95% Recall@20. We further evaluate efficiency-performance tradeoffs with MUVERA and assess multiple multi-vector image embedding models. Among closed-source models, Cohere Embed v4 page image embeddings outperform Voyage 3 Large text embeddings and all tested open-source models, achieving 58% Recall@1, 87% Recall@5, and 97% Recall@20. For question answering, text-based RAG systems achieved higher ground-truth alignment than image-based systems (0.82 vs. 0.71), and both benefit substantially from increased retrieval depth, with multi-document retrieval outperforming oracle single-document retrieval. We analyze the complementary limitations of unimodal text and image representations and identify question types that require one modality over the other. The IRPAPERS dataset and all experimental code are publicly available.

</details>


### [123] [Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems](https://arxiv.org/abs/2602.17856)
*Hamideh Ghanadian,Amin Kamali,Mohammad Hossein Tekieh*

Main category: cs.IR

TL;DR: 该研究通过检索增强生成技术改进科学文献聊天机器人，重点评估向量和图检索系统，开发了结合结构化图数据库和非结构化向量数据库的混合系统，并在单文档和大规模语料库两种场景下进行性能评估。


<details>
  <summary>Details</summary>
Motivation: 提高科学文献聊天机器人的性能，通过检索增强生成技术更好地访问科学文章和灰色文献，实现根据研究目标高效筛选资源，改善科学知识的可访问性并支持循证决策。

Method: 提出结合结构化图数据库和非结构化向量数据库的混合检索增强生成系统，使用GPT模型生成基准测试集并进行人工标注，在单文档上传和大规模语料库检索两种场景下评估向量和图检索方法的性能。

Result: 研究比较了向量和图检索系统的检索准确性和响应相关性，展示了混合RAG系统的潜力，能够有效提高科学知识的可访问性并支持循证决策。

Conclusion: 混合检索增强生成系统在科学文献聊天机器人中具有显著优势，结合向量和图检索方法能够更好地支持科学研究和证据收集，为改进科学知识访问工具提供了有价值的见解。

Abstract: This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.

</details>


### [124] [SuiteEval: Simplifying Retrieval Benchmarks](https://arxiv.org/abs/2602.18107)
*Andrew Parry,Debasis Ganguly,Sean MacAvaney*

Main category: cs.IR

TL;DR: SuiteEval是一个统一的信息检索评估框架，提供端到端自动评估、动态索引重用和主流基准测试支持，旨在解决评估实践碎片化问题，提高可复现性和可比性。


<details>
  <summary>Details</summary>
Motivation: 信息检索评估存在碎片化实践问题，包括不同的数据集子集、聚合方法和管道配置，这损害了可复现性和可比性，特别是对于需要强大跨域性能的基础嵌入模型。

Method: 引入SuiteEval统一框架，提供自动端到端评估、动态索引重用以减少磁盘使用，并内置支持BEIR、LoTTE、MS MARCO、NanoBEIR和BRIGHT等主要基准测试。用户只需提供管道生成器，框架处理数据加载、索引、排序、指标计算和结果聚合。

Result: SuiteEval减少了样板代码并标准化了评估流程，促进了可复现的信息检索研究，特别是在需要更广泛基准测试集的情况下。

Conclusion: SuiteEval通过统一框架解决了信息检索评估的碎片化问题，简化了评估流程，提高了研究的可复现性和可比性，为更全面的基准测试需求提供了支持。

Abstract: Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.

</details>


### [125] [A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18206)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Ronghua Li,Guoren Wang*

Main category: cs.IR

TL;DR: PSP-NS是一个用于隐式协同过滤的负采样插件，通过增强正样本监督信号来提升推荐质量，特别关注不活跃用户的学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有隐式协同过滤模型主要关注高质量的负样本设计，但忽视了正样本的探索。现有的去噪推荐方法虽然可以应用于隐式CF，但往往会稀疏化正样本监督，并且普遍忽视了训练过程中的用户活跃度偏差，导致不活跃用户学习不足。

Method: PSP-NS构建用户-物品二分图，边权重表示基于全局和局部模式推断的交互置信度；通过基于复制的重加权生成正样本对以增强正信号；采用活动感知的加权方案来有效学习不活跃用户的偏好。

Result: 在四个真实世界数据集上的实验表明PSP-NS的优越性。例如，在Yelp数据集上，PSP-NS将Recall@30和Precision@30分别提升了32.11%和22.90%。该插件可以与各种隐式CF推荐器或负采样方法集成以提升性能。

Conclusion: PSP-NS是一个简单而有效的负采样插件，通过增强正样本监督信号，从边际改进的角度提升排名质量，特别改善了不活跃用户的学习效果。

Abstract: Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.

</details>


### [126] [The Economical-Ecological Benefits of Matching Non-matching Socks](https://arxiv.org/abs/2602.18221)
*Teddy Lazebnik*

Main category: cs.IR

TL;DR: 研究量化了配对不匹配的"孤儿"袜子的经济生态价值，发现容忍一定的不匹配可以减少浪费并维持袜子使用服务


<details>
  <summary>Details</summary>
Motivation: 袜子大规模生产和更换，但配对使用使其特别容易浪费，因为丢失一只袜子会浪费可用穿着容量并导致过早更换。研究旨在量化配对不匹配袜子的价值以及阻碍这种行为的社会成本。

Method: 将袜子所有权形式化为不确定性下的序列决策问题，袜子在使用和洗涤过程中会随机磨损和消失，而公众曝光会引入个人特定的不匹配惩罚。通过面对面研究估计不匹配敏感性和多样性偏好，将行为异质性与最优配对策略联系起来。使用计算机模拟评估可解释的配对策略。

Result: 严格匹配看似节约资源主要是因为产生了许多无袜可穿的日子，而控制容忍不匹配可以维持服务并减少各种丢失情况下的闲置容量。研究建立了配对不匹配袜子的可行性。

Conclusion: 研究表明容忍一定的不匹配可以减少袜子浪费，同时维持穿着服务。研究确立了配对不匹配袜子的可行性，但也指出了其局限性和挑战。

Abstract: Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.

</details>


### [127] [Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18249)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.IR

TL;DR: 提出了一种无需文本信息和微调的双树LLM增强负采样方法，通过离线假负例识别和多视图硬负例采样模块，在隐式协同过滤推荐中提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的负采样方法过度依赖文本信息和任务特定微调，限制了实际应用。需要开发一种无需文本和微调的LLM增强负采样方法。

Method: 提出DTL-NS方法，包含两个模块：1）离线假负例识别模块，利用层次索引树将协同结构和潜在语义信息转换为结构化项目ID编码供LLM推理；2）多视图硬负例采样模块，结合用户-项目偏好分数和项目-项目层次相似性来挖掘高质量硬负例。

Result: 在Amazon-sports数据集上，DTL-NS在Recall@20和NDDCG@20指标上分别比最强基线提升10.64%和19.12%。该方法可集成到各种隐式CF模型和负采样方法中，持续提升性能。

Conclusion: DTL-NS是一种有效且实用的LLM增强负采样方法，无需文本信息和微调，能够准确识别假负例并挖掘高质量硬负例，显著提升推荐系统性能。

Abstract: Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.
  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.
  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.
  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).
  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.
  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.
  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [128] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: 该研究探索使用形式化领域本体（OpenMath）通过检索增强生成来提升语言模型在数学推理中的可靠性，发现相关上下文能改善性能但无关上下文会降低性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在幻觉、脆弱性和缺乏形式化基础等根本性限制，这些在高风险专业领域（如需要可验证推理的数学）中尤为成问题。研究者旨在探索形式化领域本体是否能通过检索增强生成提升语言模型的可靠性。

Method: 使用数学作为概念验证，实现了一个神经符号管道，利用OpenMath本体结合混合检索和交叉编码器重排序技术，将相关定义注入模型提示中。在MATH基准上评估了三个开源模型。

Result: 评估结果显示，当检索质量高时，本体引导的上下文能改善模型性能，但无关的上下文会主动降低性能。这突显了神经符号方法的潜力和挑战。

Conclusion: 形式化领域本体在提升语言模型可靠性方面具有潜力，但检索质量至关重要。无关上下文会损害性能，这揭示了神经符号方法需要解决的挑战。

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [129] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: TTG是一个基于编程谜题对决的评估框架，模型通过相互出题挑战来测试推理能力，无需人工出题，能有效评估模型的创造性和问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型推理能力面临挑战：人工出题成本高，特别是需要博士级领域知识的难题；存在训练数据泄露风险，难以区分模型是真正推理还是见过类似问题。需要一种无法被设计饱和的评估范式。

Method: 受16世纪数学对决启发，设计TTG框架：模型相互挑战，创建编程谜题（给定返回布尔值的Python函数，找到使函数返回True的输入）。通过两两对决计算Elo评分，比较模型相对能力。评估了10个前沿模型。

Result: TTG的模型排名与现有基准（如Humanity's Last Exam）高度匹配，且无需人工出题。发现创建优质谜题对当前模型仍是极具挑战的任务，这是先前基准未测量的能力。

Conclusion: TTG提出了一种新的推理评估范式，无法被设计饱和，能够同时测试模型的问题解决、创造性和任务创建能力，为模型评估开辟了新方向。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [130] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: WorkflowPerturb是一个用于评估工作流评估指标的基准测试，通过向黄金工作流应用受控扰动来研究指标性能


<details>
  <summary>Details</summary>
Motivation: LLM生成的结构化工作流评估困难，因为指标分数通常未校准，且分数变化不能直接反映工作流退化的严重程度

Method: 提出WorkflowPerturb基准，对黄金工作流应用三种类型的受控扰动（缺失步骤、压缩步骤、描述变化），每种类型在10%、30%、50%的严重级别上应用，包含4,973个黄金工作流和44,757个扰动变体

Result: 通过预期分数轨迹和残差分析多个指标家族的敏感性和校准性，揭示了不同指标家族的系统性差异，支持基于严重程度的工作流评估分数解释

Conclusion: WorkflowPerturb为工作流评估指标提供了受控基准，有助于理解指标性能并实现严重程度感知的评估分数解释

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [131] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 该研究将离线强化学习与跨具身学习相结合，通过分析16种机器人平台的运动数据集，发现该方法在包含大量次优轨迹的数据集上优于纯行为克隆，但存在跨形态梯度冲突问题，提出了基于形态相似性的分组策略来解决冲突。


<details>
  <summary>Details</summary>
Motivation: 解决机器人策略预训练中高质量演示数据收集成本高的问题，通过结合离线强化学习和跨具身学习来利用专家数据和丰富的次优数据，同时聚合不同形态机器人的轨迹来获取通用控制先验。

Method: 采用离线强化学习与跨具身学习相结合的方法，构建了包含16种不同机器人平台的运动数据集。针对跨形态梯度冲突问题，提出了基于形态相似性的分组策略，将机器人按形态相似性聚类，并使用组梯度更新模型。

Result: 实验证实该方法在包含丰富次优轨迹的数据集上优于纯行为克隆。但随着次优数据比例和机器人类型数量的增加，跨形态的梯度冲突会阻碍学习。提出的分组策略能显著减少机器人间的冲突，并优于现有的冲突解决方法。

Conclusion: 离线强化学习与跨具身学习的结合为机器人策略预训练提供了有效途径，但需要解决跨形态梯度冲突问题。基于形态相似性的分组策略是一个简单有效的解决方案，能够提升学习效果。

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [132] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: 研究发现，即使训练时排除敏感属性，无监督表示仍会编码这些属性，公平性通过无知在表示层面失效


<details>
  <summary>Details</summary>
Motivation: 挑战"公平性通过无知"的假设，即认为在训练中排除敏感属性就能获得中性表示。研究者发现即使明确排除敏感属性，无监督表示仍会编码这些属性

Method: 使用SOMtime（基于高容量自组织映射的拓扑保持表示方法），在两个大规模真实数据集（世界价值观调查和人口普查收入数据集）上测试，比较PCA、UMAP、t-SNE和自编码器等方法

Result: SOMtime恢复了与排除的敏感属性（如年龄、收入）对齐的单调排序，斯皮尔曼相关系数高达0.85，而其他方法通常低于0.23。无监督分割SOMtime嵌入会产生人口统计学偏斜的聚类

Conclusion: 公平性通过无知在表示层面对序数敏感属性失效，公平性审计必须扩展到机器学习管道的无监督组件

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [133] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: OMAD：首个在线多智能体强化学习框架，使用扩散策略协调智能体，通过松弛策略目标最大化联合熵实现高效探索，在MPE和MAMuJoCo任务上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成和离线设置中表现出卓越的表达能力和多模态表示能力，但在在线多智能体强化学习中的应用尚未充分探索。主要障碍是扩散模型的不可处理似然性阻碍了基于熵的探索和协调。

Method: 提出OMAD框架：1）松弛策略目标最大化缩放联合熵，实现无需可处理似然的探索；2）在CTDE范式下使用联合分布价值函数优化分散扩散策略；3）利用可处理的熵增强目标指导扩散策略同步更新，确保稳定协调。

Result: 在MPE和MAMuJoCo的10个多样化任务上建立新的SOTA，样本效率提高了2.5倍到5倍。

Conclusion: OMAD成功将扩散策略应用于在线多智能体强化学习，通过创新的松弛目标解决了扩散模型不可处理似然的问题，实现了高效的探索和协调，显著提升了样本效率。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [134] [Hilbert's Nullstellensatz is in the Counting Hierarchy](https://arxiv.org/abs/2602.17904)
*Robert Andrews,Abhibhav Garg,Éric Schost*

Main category: cs.CC

TL;DR: 希尔伯特零点定理的判定问题属于计数层次结构，多项式方程组的解数可在多项式时间内通过计数层次结构预言机计算


<details>
  <summary>Details</summary>
Motivation: 研究希尔伯特零点定理的判定问题（即判断多元多项式方程组在代数闭包中是否有解）的计算复杂性，以及计算方程组解数的问题。之前已知的最好复杂度界限是PSPACE和FPSPACE，需要探索更精确的复杂度分类。

Method: 主要技术贡献是构建了一个计算多元结式的均匀常数深度算术电路族。通过构造这种特殊电路，将希尔伯特零点定理的判定问题归约到计数层次结构中。

Result: 证明希尔伯特零点定理的判定问题属于计数层次结构（counting hierarchy）。更一般地，多项式方程组的解数可以在多项式时间内通过计数层次结构预言机计算。这些结果特别适用于有理数系数或有限域系数的多项式。

Conclusion: 希尔伯特零点定理的判定问题比之前认为的PSPACE更简单，实际上属于计数层次结构。这为代数几何中的基本计算问题提供了更精确的复杂度分类，并展示了常数深度算术电路在解决这类问题中的重要作用。

Abstract: We show that Hilbert's Nullstellensatz, the problem of deciding if a system of multivariate polynomial equations has a solution in the algebraic closure of the underlying field, lies in the counting hierarchy. More generally, we show that the number of solutions to a system of equations can be computed in polynomial time with oracle access to the counting hierarchy. Our results hold in particular for polynomials with coefficients in either the rational numbers or a finite field. Previously, the best-known bounds on the complexities of these problems were PSPACE and FPSPACE, respectively. Our main technical contribution is the construction of a uniform family of constant-depth arithmetic circuits that compute the multivariate resultant.

</details>


### [135] [Complexity lower bounds for succinct binary structures of bounded clique-width with restrictions](https://arxiv.org/abs/2602.18240)
*Colin Geniet,Aliénor Goubault-Larrecq,Kévin Perrot*

Main category: cs.CC

TL;DR: 该论文证明了在电路编码的二元结构上，任何MSO可定义问题都存在类似Rice定理的复杂度下界，扩展了先前关于电路编码图的研究框架。


<details>
  <summary>Details</summary>
Motivation: 扩展先前针对电路编码图的Courcelle定理反例框架，研究MSO可定义问题在更一般二元结构上的复杂度下界，特别是允许多重二元关系和限制新符号解释的情况。

Method: 通过允许多重二元关系和限制新符号解释来扩展框架，分析MSO问题ψ和MSO限制χ的组合，证明在满足χ且具有有界团宽度的结构上，只要ψ是非平凡的，问题就是NP-hard、coNP-hard或P-hard。

Result: 证明了在扩展上下文中存在P完全问题（针对对数空间归约），并强化了先前关于非平凡性概念必须参数化的结果，支持选择团宽度作为参数。

Conclusion: 该研究为电路编码二元结构上的MSO可定义问题建立了类似Rice定理的复杂度下界，扩展了Courcelle定理反例框架，并验证了团宽度作为参数的必要性。

Abstract: We present a Rice-like complexity lower bound for any MSO-definable problem on binary structures succinctly encoded by circuits. This work extends the framework recently developed as a counterpoint to Courcelle's theorem for graphs encoded by circuits, in two interplaying directions: (1) by allowing multiple binary relations, and (2) by restricting the interpretation of new symbols. Depending on the pair of an MSO problem $ψ$ and an MSO restriction $χ$, the problem is proven to be NP-hard or coNP-hard or P-hard, as long as $ψ$ is non-trivial on structures satisfying $χ$ with bounded clique-width. Indeed, there are P-complete problems (for logspace reductions) in our extended context. Finally, we strengthen a previous result on the necessity to parameterize the notion of non-triviality, hence supporting the choice of clique-width.

</details>


### [136] [Convergent Gate Elimination and Constructive Circuit Lower Bounds](https://arxiv.org/abs/2602.17942)
*Marco Carmosino,Ngu Dang,Tim Jackman*

Main category: cs.CC

TL;DR: 论文形式化电路简化作为收敛的项图重写系统，并利用该系统给出了构造性的电路下界证明，首次通过门消除方法实现了构造性下界。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解门消除方法（目前唯一能证明显式函数对无限制布尔电路复杂度下界的方法），本文旨在形式化电路简化过程并探索构造性下界证明。

Method: 1. 将电路简化形式化为收敛的项图重写系统，定义基于布尔恒等式的局部重写规则；2. 在DeMorgan和{∧,∨,⊕}基上证明收敛性，但在U₂和B₂基上无类似收敛形式化；3. 利用该简化系统给出构造性电路下界证明，推广Schnorr的经典结果。

Result: 1. 成功形式化电路简化为收敛的项图重写系统，确保所有简化序列产生相同最终结果；2. 首次通过门消除方法实现了构造性电路下界证明；3. 证明了XOR函数在DeMorgan基上需要3(n-1)个门的构造性下界。

Conclusion: 收敛的简化系统为电路下界证明提供了更严谨、模块化的框架，首次实现了通过门消除方法的构造性下界证明，为复杂理论中的构造性问题提供了新工具。

Abstract: Towards better understanding of gate elimination, the only method known that can prove complexity lower bounds for explicit functions against unrestricted Boolean circuits, this work contributes: (1) formalizing circuit simplifications as a convergent term graph rewriting system and (2) giving a simple and constructive proof of a classical lower bound using this system.
  First, we show that circuit simplification is a convergent term graph rewriting system over the DeMorgan and $\{\land, \lor, \oplus\}$ bases. We define local rewriting rules from Boolean identities such that every simplification sequence yields an identical final result (up to circuit isomorphism or bisimulation). Convergence enables rigorous reasoning about structural properties of simplified circuits without dependence on the order of simplification. Then, we show that there is \emph{no similar} convergent formalization of circuit simplification over the $U_2$ and $B_2$ bases.
  Then, we use our simplification system to give a constructive circuit lower bound, generalizing Schnorr's classical result that the XOR function requires $3(n - 1)$ gates to compute in the DeMorgan basis. A constructive lower bound $f \not\in C$ gives an algorithm (called a "refuter") that efficiently finds counter-examples for every $C$-circuit trying to compute the function $f$. Chen, Jin, Santhanam, and Williams showed that constructivity plays a central role in many longstanding open problems about complexity theory (FOCS 2021), so it is natural to ask for constructive circuit lower bounds from gate elimination arguments. This demonstrates how using convergent simplification can lead to shorter and more modular proofs of circuit lower bounds. Furthermore, until this work, no constructive lower bound had been proved via gate elimination.

</details>


### [137] [The Complexity of Sparse Win-Lose Bimatrix Games](https://arxiv.org/abs/2602.18380)
*Eleni Batziou,John Fearnley,Abheek Ghosh,Rahul Savani*

Main category: cs.CC

TL;DR: 证明了计算具有常数稀疏度的赢-输双矩阵博弈的ε近似纳什均衡在逆多项式ε下是PPAD难的，该结果对于3稀疏博弈成立，而2稀疏博弈可在多项式时间内求解


<details>
  <summary>Details</summary>
Motivation: 研究稀疏赢-输双矩阵博弈中计算近似纳什均衡的计算复杂性，探索稀疏度对问题难易程度的影响边界

Method: 通过理论证明和复杂性分析，建立从已知的PPAD难问题到3稀疏赢-输双矩阵博弈的归约

Result: 证明了计算3稀疏赢-输双矩阵博弈的逆多项式精度ε近似纳什均衡是PPAD难的，而2稀疏博弈可在多项式时间内求解，确定了稀疏度的临界阈值

Conclusion: 稀疏度是影响赢-输双矩阵博弈计算复杂性的关键因素，3稀疏度是计算近似纳什均衡从易到难的临界点

Abstract: We prove that computing an $ε$-approximate Nash equilibrium of a win-lose bimatrix game with constant sparsity is PPAD-hard for inverse-polynomial $ε$. Our result holds for 3-sparse games, which is tight given that 2-sparse win-lose bimatrix games can be solved in polynomial time.

</details>
